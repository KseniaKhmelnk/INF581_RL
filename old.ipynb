{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "import imageio\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение класса Transition для хранения переходов\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, action_bound):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "        self.action_bound = action_bound\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Преобразование входных данных в плоский формат\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x)) * self.action_bound\n",
    "        return x\n",
    "\n",
    "# Определение класса Critic\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        # Преобразование тензора действия к нужной размерности\n",
    "        #print(state.shape, action.shape)\n",
    "        height, width = 96, 96\n",
    "        #action = action.unsqueeze(1).unsqueeze(2).expand(state.size(0), height, width, -1)\n",
    "        state = state.view(state.size(0), -1)\n",
    "\n",
    "        #print(state.shape, action.shape)\n",
    "        x = torch.cat([state, action], dim=1)\n",
    "        #print(x.shape)\n",
    "\n",
    "        #batch_size = x.size(0)\n",
    "        #num_features = x.size(1) * x.size(2) * x.size(3)\n",
    "        #x = x.view(num_features, batch_size)\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Определение буфера воспроизведения для хранения опыта\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, transition):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(transition)\n",
    "        else:\n",
    "            self.memory[self.position] = transition\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.memory), batch_size, replace=False)\n",
    "        return [self.memory[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание экземпляра окружения\n",
    "env = gym.make('CarRacing-v2', render_mode = 'rgb_array')\n",
    "\n",
    "# Определение параметров\n",
    "state_dim = 96 * 96 * 3\n",
    "action_dim = 3\n",
    "action_bound = 1.0\n",
    "batch_size = 5\n",
    "gamma = 0.99\n",
    "tau = 0.001\n",
    "\n",
    "# Определение экземпляров сетей Actor и Critic\n",
    "actor = Actor(state_dim, action_dim, action_bound)\n",
    "critic = Critic(state_dim, action_dim)\n",
    "\n",
    "# Создание целевой модели актора и копирование весов из основной модели\n",
    "target_actor = Actor(state_dim, action_dim, action_bound)\n",
    "target_actor.load_state_dict(actor.state_dict())  # Инициализация весов как у основной модели актора\n",
    "target_actor.eval()\n",
    "\n",
    "target_critic = Critic(state_dim, action_dim)\n",
    "target_critic.load_state_dict(critic.state_dict())  # Инициализация весов как у основной модели критика\n",
    "target_critic.eval()\n",
    "\n",
    "# Определение оптимизаторов\n",
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr=0.001)\n",
    "critic_optimizer = torch.optim.Adam(critic.parameters(), lr=0.001)\n",
    "\n",
    "# Определение буфера воспроизведения\n",
    "replay_buffer = ReplayBuffer(capacity=10000)\n",
    "\n",
    "# Обучение\n",
    "num_episodes = 100\n",
    "max_steps_per_episode = 50  # Максимальное количество шагов в эпизоде\n",
    "init_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2021/polina.ovsiannikova/.local/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "Step: 0, Episode: 0\n",
      "Original action: tensor([-0.8603,  0.9792, -0.5171], device='cuda:0')\n",
      "Action: [-0.7679928   1.         -0.42473304], Reward: 0, Done: False\n",
      "====================================\n",
      "Step: 1, Episode: 0\n",
      "Original action: tensor([-0.9055,  0.9792, -0.8772], device='cuda:0')\n",
      "Action: [-0.8340193   1.         -0.80574596], Reward: -0.10000000000000009, Done: False\n",
      "====================================\n",
      "Step: 2, Episode: 0\n",
      "Original action: tensor([-0.8920,  0.9501, -0.8941], device='cuda:0')\n",
      "Action: [-0.796273   1.        -0.7983603], Reward: -0.20000000000000018, Done: False\n",
      "====================================\n",
      "Step: 3, Episode: 0\n",
      "Original action: tensor([-0.8460,  0.9769, -0.7818], device='cuda:0')\n",
      "Action: [-0.8780932   0.94487315 -0.81387943], Reward: -0.30000000000000027, Done: False\n",
      "====================================\n",
      "Step: 4, Episode: 0\n",
      "Original action: tensor([-0.8956,  0.9658, -0.6653], device='cuda:0')\n",
      "Action: [-0.9495202   0.91188717 -0.71927047], Reward: -0.40000000000000036, Done: False\n",
      "====================================\n",
      "Step: 5, Episode: 0\n",
      "Original action: tensor([-0.9776,  0.9270, -0.6092], device='cuda:0')\n",
      "Action: [-1.          0.8100283  -0.72619486], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 17.81568145751953, Step: 5, Episode: 0\n",
      "====================================\n",
      "Step: 6, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91340494  1.          1.        ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 304338.09375, Step: 6, Episode: 0\n",
      "====================================\n",
      "Step: 7, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8603927  0.8603927], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 42851.93359375, Step: 7, Episode: 0\n",
      "====================================\n",
      "Step: 8, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8038241  0.8038241], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 42805.34375, Step: 8, Episode: 0\n",
      "====================================\n",
      "Step: 9, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96883416  1.          1.        ], Reward: -0.9000000000000007, Done: False\n",
      "Critic loss: 2240.810546875, Step: 9, Episode: 0\n",
      "====================================\n",
      "Step: 10, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85583586  0.85583586], Reward: -1.0000000000000007, Done: False\n",
      "Critic loss: 22845.427734375, Step: 10, Episode: 0\n",
      "====================================\n",
      "Step: 11, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9679682  1.         1.       ], Reward: -1.1000000000000005, Done: False\n",
      "Critic loss: 10805.1904296875, Step: 11, Episode: 0\n",
      "====================================\n",
      "Step: 12, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9854433  0.9854433], Reward: -1.2000000000000006, Done: False\n",
      "Critic loss: 1966.7640380859375, Step: 12, Episode: 0\n",
      "====================================\n",
      "Step: 13, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9316006  1.         1.       ], Reward: -1.3000000000000007, Done: False\n",
      "Critic loss: 12331.744140625, Step: 13, Episode: 0\n",
      "====================================\n",
      "Step: 14, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8413361  0.8413361], Reward: -1.4000000000000008, Done: False\n",
      "Critic loss: 8350.98828125, Step: 14, Episode: 0\n",
      "====================================\n",
      "Step: 15, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9553139  0.9553139], Reward: -1.5000000000000009, Done: False\n",
      "Critic loss: 1840.31640625, Step: 15, Episode: 0\n",
      "====================================\n",
      "Step: 16, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96087056  0.96087056], Reward: -1.600000000000001, Done: False\n",
      "Critic loss: 279.12066650390625, Step: 16, Episode: 0\n",
      "====================================\n",
      "Step: 17, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99826694  1.          1.        ], Reward: -1.700000000000001, Done: False\n",
      "Critic loss: 3716.14453125, Step: 17, Episode: 0\n",
      "====================================\n",
      "Step: 18, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7304193  0.7304193], Reward: -1.8000000000000012, Done: False\n",
      "Critic loss: 3948.782470703125, Step: 18, Episode: 0\n",
      "====================================\n",
      "Step: 19, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8723268  1.         1.       ], Reward: -1.9000000000000012, Done: False\n",
      "Critic loss: 808.9835815429688, Step: 19, Episode: 0\n",
      "====================================\n",
      "Step: 20, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9152099  0.9152099], Reward: -2.0000000000000013, Done: False\n",
      "Critic loss: 754.9793090820312, Step: 20, Episode: 0\n",
      "====================================\n",
      "Step: 21, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95368326  1.          1.        ], Reward: -2.1000000000000014, Done: False\n",
      "Critic loss: 3349.956298828125, Step: 21, Episode: 0\n",
      "====================================\n",
      "Step: 22, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91438895  0.91438895], Reward: -2.2000000000000015, Done: False\n",
      "Critic loss: 1406.1405029296875, Step: 22, Episode: 0\n",
      "====================================\n",
      "Step: 23, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8802624  1.         1.       ], Reward: -2.3000000000000016, Done: False\n",
      "Critic loss: 89.8995590209961, Step: 23, Episode: 0\n",
      "====================================\n",
      "Step: 24, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9283877  1.         1.       ], Reward: -2.4000000000000017, Done: False\n",
      "Critic loss: 1369.3076171875, Step: 24, Episode: 0\n",
      "====================================\n",
      "Step: 25, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9892239  1.         1.       ], Reward: -2.5000000000000018, Done: False\n",
      "Critic loss: 1507.0545654296875, Step: 25, Episode: 0\n",
      "====================================\n",
      "Step: 26, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91038465  0.91038465], Reward: -2.600000000000002, Done: False\n",
      "Critic loss: 730.9100952148438, Step: 26, Episode: 0\n",
      "====================================\n",
      "Step: 27, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96960515  0.96960515], Reward: -2.700000000000002, Done: False\n",
      "Critic loss: 28.0082950592041, Step: 27, Episode: 0\n",
      "====================================\n",
      "Step: 28, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9619849  0.9619849], Reward: -2.800000000000002, Done: False\n",
      "Critic loss: 888.11083984375, Step: 28, Episode: 0\n",
      "====================================\n",
      "Step: 29, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8510796  0.8510796], Reward: -2.900000000000002, Done: False\n",
      "Critic loss: 1214.7049560546875, Step: 29, Episode: 0\n",
      "====================================\n",
      "Step: 30, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90922314  0.90922314], Reward: -3.000000000000002, Done: False\n",
      "Critic loss: 328.9258728027344, Step: 30, Episode: 0\n",
      "====================================\n",
      "Step: 31, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9410145  1.         1.       ], Reward: -3.1000000000000023, Done: False\n",
      "Critic loss: 63.190223693847656, Step: 31, Episode: 0\n",
      "====================================\n",
      "Step: 32, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91910195  0.91910195], Reward: -3.2000000000000024, Done: False\n",
      "Critic loss: 669.2269897460938, Step: 32, Episode: 0\n",
      "====================================\n",
      "Step: 33, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8133776  1.         1.       ], Reward: -3.3000000000000025, Done: False\n",
      "Critic loss: 510.4645080566406, Step: 33, Episode: 0\n",
      "====================================\n",
      "Step: 34, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8886183  1.         1.       ], Reward: -3.4000000000000026, Done: False\n",
      "Critic loss: 125.3623275756836, Step: 34, Episode: 0\n",
      "====================================\n",
      "Step: 35, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9336981  1.         1.       ], Reward: -3.5000000000000027, Done: False\n",
      "Critic loss: 75.02054595947266, Step: 35, Episode: 0\n",
      "====================================\n",
      "Step: 36, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.83966005  0.83966005], Reward: -3.6000000000000028, Done: False\n",
      "Critic loss: 355.7093811035156, Step: 36, Episode: 0\n",
      "====================================\n",
      "Step: 37, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9507611  1.         1.       ], Reward: -3.700000000000003, Done: False\n",
      "Critic loss: 437.2494201660156, Step: 37, Episode: 0\n",
      "====================================\n",
      "Step: 38, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92865384  0.92865384], Reward: -3.800000000000003, Done: False\n",
      "Critic loss: 37.41246795654297, Step: 38, Episode: 0\n",
      "====================================\n",
      "Step: 39, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8869536  1.         1.       ], Reward: -3.900000000000003, Done: False\n",
      "Critic loss: 120.839111328125, Step: 39, Episode: 0\n",
      "====================================\n",
      "Step: 40, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.997913  0.997913], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 364.6900939941406, Step: 40, Episode: 0\n",
      "====================================\n",
      "Step: 41, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9879778  1.         1.       ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 164.6685791015625, Step: 41, Episode: 0\n",
      "====================================\n",
      "Step: 42, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9788976  0.9788976], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 4.0811262130737305, Step: 42, Episode: 0\n",
      "====================================\n",
      "Step: 43, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.      0.8669  0.8669], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 189.69512939453125, Step: 43, Episode: 0\n",
      "====================================\n",
      "Step: 44, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9716796  0.9716796], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 216.60069274902344, Step: 44, Episode: 0\n",
      "====================================\n",
      "Step: 45, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9843369  0.9843369], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 22.713613510131836, Step: 45, Episode: 0\n",
      "====================================\n",
      "Step: 46, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9518849  1.         1.       ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 62.10527420043945, Step: 46, Episode: 0\n",
      "====================================\n",
      "Step: 47, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8993643  0.8993643], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 196.92222595214844, Step: 47, Episode: 0\n",
      "====================================\n",
      "Step: 48, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87949395  0.87949395], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 65.22785186767578, Step: 48, Episode: 0\n",
      "====================================\n",
      "Step: 49, Episode: 0\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88344127  1.          1.        ], Reward: -4.9, Done: False\n",
      "Critic loss: 8.980798721313477, Step: 49, Episode: 0\n",
      "====================================\n",
      "Step: 0, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9256237  0.9256237], Reward: 0, Done: False\n",
      "Critic loss: 183.4007110595703, Step: 0, Episode: 1\n",
      "====================================\n",
      "Step: 1, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8972434  1.         1.       ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 136.61106872558594, Step: 1, Episode: 1\n",
      "====================================\n",
      "Step: 2, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91124374  0.91124374], Reward: -0.20000000000000007, Done: False\n",
      "Critic loss: 10.418020248413086, Step: 2, Episode: 1\n",
      "====================================\n",
      "Step: 3, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9594361  0.9594361], Reward: -0.30000000000000004, Done: False\n",
      "Critic loss: 51.897552490234375, Step: 3, Episode: 1\n",
      "====================================\n",
      "Step: 4, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91495216  0.91495216], Reward: -0.4, Done: False\n",
      "Critic loss: 113.2076644897461, Step: 4, Episode: 1\n",
      "====================================\n",
      "Step: 5, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.988634  1.        1.      ], Reward: -0.5, Done: False\n",
      "Critic loss: 25.768234252929688, Step: 5, Episode: 1\n",
      "====================================\n",
      "Step: 6, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7811139  1.         1.       ], Reward: -0.6, Done: False\n",
      "Critic loss: 15.204302787780762, Step: 6, Episode: 1\n",
      "====================================\n",
      "Step: 7, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.965447  1.        1.      ], Reward: -0.7, Done: False\n",
      "Critic loss: 78.69451141357422, Step: 7, Episode: 1\n",
      "====================================\n",
      "Step: 8, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8821747  1.         1.       ], Reward: -0.7999999999999999, Done: False\n",
      "Critic loss: 33.9073371887207, Step: 8, Episode: 1\n",
      "====================================\n",
      "Step: 9, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9399601  1.         1.       ], Reward: -0.8999999999999999, Done: False\n",
      "Critic loss: 2.6645190715789795, Step: 9, Episode: 1\n",
      "====================================\n",
      "Step: 10, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9709975  0.9709975], Reward: -0.9999999999999999, Done: False\n",
      "Critic loss: 44.885833740234375, Step: 10, Episode: 1\n",
      "====================================\n",
      "Step: 11, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9382216  0.9382216], Reward: -1.0999999999999999, Done: False\n",
      "Critic loss: 37.336700439453125, Step: 11, Episode: 1\n",
      "====================================\n",
      "Step: 12, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9364054  1.         1.       ], Reward: -1.2, Done: False\n",
      "Critic loss: 0.09212581813335419, Step: 12, Episode: 1\n",
      "====================================\n",
      "Step: 13, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95857865  1.          1.        ], Reward: -1.3, Done: False\n",
      "Critic loss: 25.576644897460938, Step: 13, Episode: 1\n",
      "====================================\n",
      "Step: 14, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88863814  1.          1.        ], Reward: -1.4000000000000001, Done: False\n",
      "Critic loss: 36.73732376098633, Step: 14, Episode: 1\n",
      "====================================\n",
      "Step: 15, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8882191  0.8882191], Reward: -1.5000000000000002, Done: False\n",
      "Critic loss: 49.78606414794922, Step: 15, Episode: 1\n",
      "====================================\n",
      "Step: 16, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99714124  0.99714124], Reward: -1.6, Done: False\n",
      "Critic loss: 21.135610580444336, Step: 16, Episode: 1\n",
      "====================================\n",
      "Step: 17, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8101488  1.         1.       ], Reward: -1.7000000000000002, Done: False\n",
      "Critic loss: 32.334136962890625, Step: 17, Episode: 1\n",
      "====================================\n",
      "Step: 18, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97170526  1.          1.        ], Reward: -1.8000000000000003, Done: False\n",
      "Critic loss: 1.3141921758651733, Step: 18, Episode: 1\n",
      "====================================\n",
      "Step: 19, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.75463694  0.75463694], Reward: -1.9000000000000004, Done: False\n",
      "Critic loss: 13.124262809753418, Step: 19, Episode: 1\n",
      "====================================\n",
      "Step: 20, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9765437  1.         1.       ], Reward: -2.0000000000000004, Done: False\n",
      "Critic loss: 26.398996353149414, Step: 20, Episode: 1\n",
      "====================================\n",
      "Step: 21, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95741487  1.          1.        ], Reward: -2.1000000000000005, Done: False\n",
      "Critic loss: 4.3327460289001465, Step: 21, Episode: 1\n",
      "====================================\n",
      "Step: 22, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.938206  0.938206], Reward: -2.2000000000000006, Done: False\n",
      "Critic loss: 7.405804634094238, Step: 22, Episode: 1\n",
      "====================================\n",
      "Step: 23, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95252484  1.          1.        ], Reward: -2.3000000000000007, Done: False\n",
      "Critic loss: 17.080204010009766, Step: 23, Episode: 1\n",
      "====================================\n",
      "Step: 24, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9509875  0.9509875], Reward: -2.400000000000001, Done: False\n",
      "Critic loss: 3.2712349891662598, Step: 24, Episode: 1\n",
      "====================================\n",
      "Step: 25, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92935705  0.92935705], Reward: -2.500000000000001, Done: False\n",
      "Critic loss: 2.9762518405914307, Step: 25, Episode: 1\n",
      "====================================\n",
      "Step: 26, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99006224  0.99006224], Reward: -2.600000000000001, Done: False\n",
      "Critic loss: 15.005500793457031, Step: 26, Episode: 1\n",
      "====================================\n",
      "Step: 27, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9449674  1.         1.       ], Reward: -2.700000000000001, Done: False\n",
      "Critic loss: 2.817431688308716, Step: 27, Episode: 1\n",
      "====================================\n",
      "Step: 28, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90546936  0.90546936], Reward: -2.800000000000001, Done: False\n",
      "Critic loss: 78.5768051147461, Step: 28, Episode: 1\n",
      "====================================\n",
      "Step: 29, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95657927  0.95657927], Reward: -2.9000000000000012, Done: False\n",
      "Critic loss: 7.467555999755859, Step: 29, Episode: 1\n",
      "====================================\n",
      "Step: 30, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.88427746  0.88427746], Reward: -3.0000000000000013, Done: False\n",
      "Critic loss: 0.26327160000801086, Step: 30, Episode: 1\n",
      "====================================\n",
      "Step: 31, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95083606  0.95083606], Reward: -3.1000000000000014, Done: False\n",
      "Critic loss: 3.1926159858703613, Step: 31, Episode: 1\n",
      "====================================\n",
      "Step: 32, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96268374  0.96268374], Reward: -3.200000000000001, Done: False\n",
      "Critic loss: 3.470532178878784, Step: 32, Episode: 1\n",
      "====================================\n",
      "Step: 33, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9828582  1.         1.       ], Reward: -3.300000000000001, Done: False\n",
      "Critic loss: 0.6395590305328369, Step: 33, Episode: 1\n",
      "====================================\n",
      "Step: 34, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9219951  1.         1.       ], Reward: -3.4000000000000012, Done: False\n",
      "Critic loss: 2.4896466732025146, Step: 34, Episode: 1\n",
      "====================================\n",
      "Step: 35, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8845123  1.         1.       ], Reward: -3.5000000000000013, Done: False\n",
      "Critic loss: 2.301199436187744, Step: 35, Episode: 1\n",
      "====================================\n",
      "Step: 36, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9983295  0.9983295], Reward: -3.6000000000000014, Done: False\n",
      "Critic loss: 0.13859938085079193, Step: 36, Episode: 1\n",
      "====================================\n",
      "Step: 37, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9721165  0.9721165], Reward: -3.7000000000000015, Done: False\n",
      "Critic loss: 0.7574699521064758, Step: 37, Episode: 1\n",
      "====================================\n",
      "Step: 38, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9408355  0.9408355], Reward: -3.8000000000000016, Done: False\n",
      "Critic loss: 1.0809353590011597, Step: 38, Episode: 1\n",
      "====================================\n",
      "Step: 39, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.85029733  1.          1.        ], Reward: -3.9000000000000017, Done: False\n",
      "Critic loss: 0.309420645236969, Step: 39, Episode: 1\n",
      "====================================\n",
      "Step: 40, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8923413  1.         1.       ], Reward: -4.000000000000002, Done: False\n",
      "Critic loss: 0.789520800113678, Step: 40, Episode: 1\n",
      "====================================\n",
      "Step: 41, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9773867  1.         1.       ], Reward: -4.100000000000001, Done: False\n",
      "Critic loss: 74.55011749267578, Step: 41, Episode: 1\n",
      "====================================\n",
      "Step: 42, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87788606  0.87788606], Reward: -4.200000000000001, Done: False\n",
      "Critic loss: 57.80237579345703, Step: 42, Episode: 1\n",
      "====================================\n",
      "Step: 43, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9211162  0.9211162], Reward: -4.300000000000001, Done: False\n",
      "Critic loss: 19.153175354003906, Step: 43, Episode: 1\n",
      "====================================\n",
      "Step: 44, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9919332  0.9919332], Reward: -4.4, Done: False\n",
      "Critic loss: 17.76540184020996, Step: 44, Episode: 1\n",
      "====================================\n",
      "Step: 45, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9062307  1.         1.       ], Reward: -4.5, Done: False\n",
      "Critic loss: 0.46767789125442505, Step: 45, Episode: 1\n",
      "====================================\n",
      "Step: 46, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9943617  0.9943617], Reward: -4.6, Done: False\n",
      "Critic loss: 22.681503295898438, Step: 46, Episode: 1\n",
      "====================================\n",
      "Step: 47, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9568002  1.         1.       ], Reward: -4.699999999999999, Done: False\n",
      "Critic loss: 9.05042552947998, Step: 47, Episode: 1\n",
      "====================================\n",
      "Step: 48, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.961738  1.        1.      ], Reward: -4.799999999999999, Done: False\n",
      "Critic loss: 4.995416164398193, Step: 48, Episode: 1\n",
      "====================================\n",
      "Step: 49, Episode: 1\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94050306  0.94050306], Reward: -4.899999999999999, Done: False\n",
      "Critic loss: 16.985807418823242, Step: 49, Episode: 1\n",
      "====================================\n",
      "Step: 0, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.83184075  1.          1.        ], Reward: 0, Done: False\n",
      "Critic loss: 1.957869529724121, Step: 0, Episode: 2\n",
      "====================================\n",
      "Step: 1, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7976545  1.         1.       ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 265.8392639160156, Step: 1, Episode: 2\n",
      "====================================\n",
      "Step: 2, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9360105  1.         1.       ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 4.562558650970459, Step: 2, Episode: 2\n",
      "====================================\n",
      "Step: 3, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8490106  1.         1.       ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.6361531615257263, Step: 3, Episode: 2\n",
      "====================================\n",
      "Step: 4, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.86760676  1.          1.        ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 5.725109100341797, Step: 4, Episode: 2\n",
      "====================================\n",
      "Step: 5, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8478188  1.         1.       ], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 72.29400634765625, Step: 5, Episode: 2\n",
      "====================================\n",
      "Step: 6, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9871787  1.         1.       ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.21991626918315887, Step: 6, Episode: 2\n",
      "====================================\n",
      "Step: 7, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8927224  1.         1.       ], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 18.82638931274414, Step: 7, Episode: 2\n",
      "====================================\n",
      "Step: 8, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9631598  1.         1.       ], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.21593523025512695, Step: 8, Episode: 2\n",
      "====================================\n",
      "Step: 9, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95862204  0.95862204], Reward: -0.9000000000000007, Done: False\n",
      "Critic loss: 0.7224833369255066, Step: 9, Episode: 2\n",
      "====================================\n",
      "Step: 10, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92985445  0.92985445], Reward: -1.0000000000000007, Done: False\n",
      "Critic loss: 4.785336017608643, Step: 10, Episode: 2\n",
      "====================================\n",
      "Step: 11, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.82098174  1.          1.        ], Reward: -1.1000000000000005, Done: False\n",
      "Critic loss: 4641.13525390625, Step: 11, Episode: 2\n",
      "====================================\n",
      "Step: 12, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.982293  0.982293], Reward: -1.2000000000000006, Done: False\n",
      "Critic loss: 5759.34912109375, Step: 12, Episode: 2\n",
      "====================================\n",
      "Step: 13, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95331174  0.95331174], Reward: -1.3000000000000007, Done: False\n",
      "Critic loss: 3411.889404296875, Step: 13, Episode: 2\n",
      "====================================\n",
      "Step: 14, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.83011985  1.          1.        ], Reward: -1.4000000000000008, Done: False\n",
      "Critic loss: 330.9917907714844, Step: 14, Episode: 2\n",
      "====================================\n",
      "Step: 15, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9956079  0.9956079], Reward: -1.5000000000000009, Done: False\n",
      "Critic loss: 4637.71044921875, Step: 15, Episode: 2\n",
      "====================================\n",
      "Step: 16, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88802075  1.          1.        ], Reward: -1.600000000000001, Done: False\n",
      "Critic loss: 1758.5872802734375, Step: 16, Episode: 2\n",
      "====================================\n",
      "Step: 17, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9910311  1.         1.       ], Reward: -1.700000000000001, Done: False\n",
      "Critic loss: 462.73291015625, Step: 17, Episode: 2\n",
      "====================================\n",
      "Step: 18, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.89582634  0.89582634], Reward: -1.8000000000000012, Done: False\n",
      "Critic loss: 3893.585693359375, Step: 18, Episode: 2\n",
      "====================================\n",
      "Step: 19, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97919244  0.97919244], Reward: -1.9000000000000012, Done: False\n",
      "Critic loss: 1289.5562744140625, Step: 19, Episode: 2\n",
      "====================================\n",
      "Step: 20, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9479646  1.         1.       ], Reward: -2.0000000000000013, Done: False\n",
      "Critic loss: 248.3076629638672, Step: 20, Episode: 2\n",
      "====================================\n",
      "Step: 21, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.84163815  1.          1.        ], Reward: -2.1000000000000014, Done: False\n",
      "Critic loss: 2265.34765625, Step: 21, Episode: 2\n",
      "====================================\n",
      "Step: 22, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9938605  0.9938605], Reward: -2.2000000000000015, Done: False\n",
      "Critic loss: 933.8644409179688, Step: 22, Episode: 2\n",
      "====================================\n",
      "Step: 23, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9543654  0.9543654], Reward: -2.3000000000000016, Done: False\n",
      "Critic loss: 144.61093139648438, Step: 23, Episode: 2\n",
      "====================================\n",
      "Step: 24, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90024847  1.          1.        ], Reward: -2.4000000000000017, Done: False\n",
      "Critic loss: 1568.9420166015625, Step: 24, Episode: 2\n",
      "====================================\n",
      "Step: 25, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.823515  0.823515], Reward: -2.5000000000000018, Done: False\n",
      "Critic loss: 808.631103515625, Step: 25, Episode: 2\n",
      "====================================\n",
      "Step: 26, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9215783  0.9215783], Reward: -2.600000000000002, Done: False\n",
      "Critic loss: 54.17082595825195, Step: 26, Episode: 2\n",
      "====================================\n",
      "Step: 27, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9350918  1.         1.       ], Reward: -2.700000000000002, Done: False\n",
      "Critic loss: 1071.3226318359375, Step: 27, Episode: 2\n",
      "====================================\n",
      "Step: 28, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96661454  1.          1.        ], Reward: -2.800000000000002, Done: False\n",
      "Critic loss: 691.3727416992188, Step: 28, Episode: 2\n",
      "====================================\n",
      "Step: 29, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9528015  0.9528015], Reward: -2.900000000000002, Done: False\n",
      "Critic loss: 4.7012248039245605, Step: 29, Episode: 2\n",
      "====================================\n",
      "Step: 30, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9294668  1.         1.       ], Reward: -3.000000000000002, Done: False\n",
      "Critic loss: 658.68701171875, Step: 30, Episode: 2\n",
      "====================================\n",
      "Step: 31, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97487205  0.97487205], Reward: -3.1000000000000023, Done: False\n",
      "Critic loss: 501.11236572265625, Step: 31, Episode: 2\n",
      "====================================\n",
      "Step: 32, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98698014  0.98698014], Reward: -3.2000000000000024, Done: False\n",
      "Critic loss: 45.81869125366211, Step: 32, Episode: 2\n",
      "====================================\n",
      "Step: 33, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.82968885  0.82968885], Reward: -3.3000000000000025, Done: False\n",
      "Critic loss: 192.5470428466797, Step: 33, Episode: 2\n",
      "====================================\n",
      "Step: 34, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9842285  1.         1.       ], Reward: -3.4000000000000026, Done: False\n",
      "Critic loss: 479.2178649902344, Step: 34, Episode: 2\n",
      "====================================\n",
      "Step: 35, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9406728  1.         1.       ], Reward: -3.5000000000000027, Done: False\n",
      "Critic loss: 256.9779968261719, Step: 35, Episode: 2\n",
      "====================================\n",
      "Step: 36, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9311003  1.         1.       ], Reward: -3.6000000000000028, Done: False\n",
      "Critic loss: 121.26566314697266, Step: 36, Episode: 2\n",
      "====================================\n",
      "Step: 37, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.82797253  1.          1.        ], Reward: -3.700000000000003, Done: False\n",
      "Critic loss: 456.0890808105469, Step: 37, Episode: 2\n",
      "====================================\n",
      "Step: 38, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99445575  0.99445575], Reward: -3.800000000000003, Done: False\n",
      "Critic loss: 352.1692199707031, Step: 38, Episode: 2\n",
      "====================================\n",
      "Step: 39, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9314787  0.9314787], Reward: -3.900000000000003, Done: False\n",
      "Critic loss: 0.3201732337474823, Step: 39, Episode: 2\n",
      "====================================\n",
      "Step: 40, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91522956  0.91522956], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 227.40196228027344, Step: 40, Episode: 2\n",
      "====================================\n",
      "Step: 41, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8421571  1.         1.       ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 437.8857421875, Step: 41, Episode: 2\n",
      "====================================\n",
      "Step: 42, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.847076  1.        1.      ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 48.044246673583984, Step: 42, Episode: 2\n",
      "====================================\n",
      "Step: 43, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8312822  0.8312822], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 125.11226654052734, Step: 43, Episode: 2\n",
      "====================================\n",
      "Step: 44, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.89666927  1.          1.        ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 335.8335876464844, Step: 44, Episode: 2\n",
      "====================================\n",
      "Step: 45, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9708129  0.9708129], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 94.95309448242188, Step: 45, Episode: 2\n",
      "====================================\n",
      "Step: 46, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.77687836  1.          1.        ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 32.35061264038086, Step: 46, Episode: 2\n",
      "====================================\n",
      "Step: 47, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9839572  1.         1.       ], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 224.5226593017578, Step: 47, Episode: 2\n",
      "====================================\n",
      "Step: 48, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.917652  0.917652], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 132.0062713623047, Step: 48, Episode: 2\n",
      "====================================\n",
      "Step: 49, Episode: 2\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8677972  1.         1.       ], Reward: -4.9, Done: False\n",
      "Critic loss: 1.5492346286773682, Step: 49, Episode: 2\n",
      "====================================\n",
      "Step: 0, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9978719  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 144.55746459960938, Step: 0, Episode: 3\n",
      "====================================\n",
      "Step: 1, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96621925  1.          1.        ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 142.64138793945312, Step: 1, Episode: 3\n",
      "====================================\n",
      "Step: 2, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93123484  0.93123484], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 5.602785587310791, Step: 2, Episode: 3\n",
      "====================================\n",
      "Step: 3, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.85676926  1.          1.        ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 93.20980072021484, Step: 3, Episode: 3\n",
      "====================================\n",
      "Step: 4, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.83927673  0.83927673], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 127.46453094482422, Step: 4, Episode: 3\n",
      "====================================\n",
      "Step: 5, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8723483  1.         1.       ], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 11.91948413848877, Step: 5, Episode: 3\n",
      "====================================\n",
      "Step: 6, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.74703526  0.74703526], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 42.442909240722656, Step: 6, Episode: 3\n",
      "====================================\n",
      "Step: 7, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9193654  0.9193654], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 92.06928253173828, Step: 7, Episode: 3\n",
      "====================================\n",
      "Step: 8, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93528247  1.          1.        ], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 20.08376121520996, Step: 8, Episode: 3\n",
      "====================================\n",
      "Step: 9, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.89983827  1.          1.        ], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 17.98227882385254, Step: 9, Episode: 3\n",
      "====================================\n",
      "Step: 10, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.86839294  1.          1.        ], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 67.02581024169922, Step: 10, Episode: 3\n",
      "====================================\n",
      "Step: 11, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.80854654  1.          1.        ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 22.559446334838867, Step: 11, Episode: 3\n",
      "====================================\n",
      "Step: 12, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99199694  1.          1.        ], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 4.295703411102295, Step: 12, Episode: 3\n",
      "====================================\n",
      "Step: 13, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8380787  0.8380787], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 45.99105453491211, Step: 13, Episode: 3\n",
      "====================================\n",
      "Step: 14, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87308186  0.87308186], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 394.9335632324219, Step: 14, Episode: 3\n",
      "====================================\n",
      "Step: 15, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87009513  1.          1.        ], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 1.2211642265319824, Step: 15, Episode: 3\n",
      "====================================\n",
      "Step: 16, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8663516  1.         1.       ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 199.4274444580078, Step: 16, Episode: 3\n",
      "====================================\n",
      "Step: 17, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8551564  1.         1.       ], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 55.2332763671875, Step: 17, Episode: 3\n",
      "====================================\n",
      "Step: 18, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.81135976  1.          1.        ], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 4.0381059646606445, Step: 18, Episode: 3\n",
      "====================================\n",
      "Step: 19, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99952203  0.99952203], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 22.290353775024414, Step: 19, Episode: 3\n",
      "====================================\n",
      "Step: 20, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88573974  1.          1.        ], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 50.164093017578125, Step: 20, Episode: 3\n",
      "====================================\n",
      "Step: 21, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.993233  1.        1.      ], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 8.129193305969238, Step: 21, Episode: 3\n",
      "====================================\n",
      "Step: 22, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9267986  0.9267986], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 11.711212158203125, Step: 22, Episode: 3\n",
      "====================================\n",
      "Step: 23, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9353895  0.9353895], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 43.66201400756836, Step: 23, Episode: 3\n",
      "====================================\n",
      "Step: 24, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9175037  1.         1.       ], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 11.585626602172852, Step: 24, Episode: 3\n",
      "====================================\n",
      "Step: 25, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9982079  1.         1.       ], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 12.855644226074219, Step: 25, Episode: 3\n",
      "====================================\n",
      "Step: 26, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.       0.94892  0.94892], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 34.18964767456055, Step: 26, Episode: 3\n",
      "====================================\n",
      "Step: 27, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97808826  1.          1.        ], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 24.051301956176758, Step: 27, Episode: 3\n",
      "====================================\n",
      "Step: 28, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98217684  0.98217684], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.6112545132637024, Step: 28, Episode: 3\n",
      "====================================\n",
      "Step: 29, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99813133  0.99813133], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 15.256235122680664, Step: 29, Episode: 3\n",
      "====================================\n",
      "Step: 30, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8859403  0.8859403], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 9.579034805297852, Step: 30, Episode: 3\n",
      "====================================\n",
      "Step: 31, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8132391  1.         1.       ], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.4408278465270996, Step: 31, Episode: 3\n",
      "====================================\n",
      "Step: 32, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9516438  1.         1.       ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 9.98049545288086, Step: 32, Episode: 3\n",
      "====================================\n",
      "Step: 33, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8972708  0.8972708], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 7.22829008102417, Step: 33, Episode: 3\n",
      "====================================\n",
      "Step: 34, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91645914  0.91645914], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.25744208693504333, Step: 34, Episode: 3\n",
      "====================================\n",
      "Step: 35, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96980166  1.          1.        ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 28.426584243774414, Step: 35, Episode: 3\n",
      "====================================\n",
      "Step: 36, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9108333  1.         1.       ], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 9.229581832885742, Step: 36, Episode: 3\n",
      "====================================\n",
      "Step: 37, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9529652  1.         1.       ], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.7991149425506592, Step: 37, Episode: 3\n",
      "====================================\n",
      "Step: 38, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9381962  1.         1.       ], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 4.239980220794678, Step: 38, Episode: 3\n",
      "====================================\n",
      "Step: 39, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90598935  0.90598935], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 10.495471000671387, Step: 39, Episode: 3\n",
      "====================================\n",
      "Step: 40, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86725175  0.86725175], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.7109919786453247, Step: 40, Episode: 3\n",
      "====================================\n",
      "Step: 41, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96208024  1.          1.        ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 3.456263303756714, Step: 41, Episode: 3\n",
      "====================================\n",
      "Step: 42, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95618653  0.95618653], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 9.092612266540527, Step: 42, Episode: 3\n",
      "====================================\n",
      "Step: 43, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9323442  0.9323442], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.005272999871522188, Step: 43, Episode: 3\n",
      "====================================\n",
      "Step: 44, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9227219  1.         1.       ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.8355647921562195, Step: 44, Episode: 3\n",
      "====================================\n",
      "Step: 45, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.83553517  0.83553517], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 3.406684160232544, Step: 45, Episode: 3\n",
      "====================================\n",
      "Step: 46, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9883146  1.         1.       ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 3.2645764350891113, Step: 46, Episode: 3\n",
      "====================================\n",
      "Step: 47, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9799268  0.9799268], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.7348979115486145, Step: 47, Episode: 3\n",
      "====================================\n",
      "Step: 48, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.857277  1.        1.      ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 4.106349468231201, Step: 48, Episode: 3\n",
      "====================================\n",
      "Step: 49, Episode: 3\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9625102  1.         1.       ], Reward: -4.9, Done: False\n",
      "Critic loss: 6.959888458251953, Step: 49, Episode: 3\n",
      "====================================\n",
      "Step: 0, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8843833  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 0.6905556321144104, Step: 0, Episode: 4\n",
      "====================================\n",
      "Step: 1, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7980077  1.         1.       ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 4.130477428436279, Step: 1, Episode: 4\n",
      "====================================\n",
      "Step: 2, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9295423  1.         1.       ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 5.151828765869141, Step: 2, Episode: 4\n",
      "====================================\n",
      "Step: 3, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.86520857  1.          1.        ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 111.52290344238281, Step: 3, Episode: 4\n",
      "====================================\n",
      "Step: 4, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.933555  1.        1.      ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 1.1115083694458008, Step: 4, Episode: 4\n",
      "====================================\n",
      "Step: 5, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9611717  0.9611717], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 1.4845877885818481, Step: 5, Episode: 4\n",
      "====================================\n",
      "Step: 6, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.943134  0.943134], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.06987512856721878, Step: 6, Episode: 4\n",
      "====================================\n",
      "Step: 7, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8260096  0.8260096], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.3056001365184784, Step: 7, Episode: 4\n",
      "====================================\n",
      "Step: 8, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93643683  0.93643683], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 2.6845204830169678, Step: 8, Episode: 4\n",
      "====================================\n",
      "Step: 9, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96614385  0.96614385], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.509487509727478, Step: 9, Episode: 4\n",
      "====================================\n",
      "Step: 10, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87503004  0.87503004], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.9581893086433411, Step: 10, Episode: 4\n",
      "====================================\n",
      "Step: 11, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86298394  0.86298394], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.767802357673645, Step: 11, Episode: 4\n",
      "====================================\n",
      "Step: 12, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8598621  0.8598621], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 8.157674789428711, Step: 12, Episode: 4\n",
      "====================================\n",
      "Step: 13, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93131596  0.93131596], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 2.491960287094116, Step: 13, Episode: 4\n",
      "====================================\n",
      "Step: 14, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9905006  0.9905006], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.6611272692680359, Step: 14, Episode: 4\n",
      "====================================\n",
      "Step: 15, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9398418  0.9398418], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 4.265053749084473, Step: 15, Episode: 4\n",
      "====================================\n",
      "Step: 16, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96990484  1.          1.        ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 2187.13525390625, Step: 16, Episode: 4\n",
      "====================================\n",
      "Step: 17, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9649868  0.9649868], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 1422.6602783203125, Step: 17, Episode: 4\n",
      "====================================\n",
      "Step: 18, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91102004  0.91102004], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 2219.786376953125, Step: 18, Episode: 4\n",
      "====================================\n",
      "Step: 19, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8817909  0.8817909], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 34.433040618896484, Step: 19, Episode: 4\n",
      "====================================\n",
      "Step: 20, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92640346  0.92640346], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 1371.1910400390625, Step: 20, Episode: 4\n",
      "====================================\n",
      "Step: 21, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9855456  0.9855456], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 1675.489501953125, Step: 21, Episode: 4\n",
      "====================================\n",
      "Step: 22, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98212713  1.          1.        ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 7.3248443603515625, Step: 22, Episode: 4\n",
      "====================================\n",
      "Step: 23, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9649009  0.9649009], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 1132.4459228515625, Step: 23, Episode: 4\n",
      "====================================\n",
      "Step: 24, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9873533  0.9873533], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 1130.9886474609375, Step: 24, Episode: 4\n",
      "====================================\n",
      "Step: 25, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9675775  0.9675775], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 2.386256694793701, Step: 25, Episode: 4\n",
      "====================================\n",
      "Step: 26, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9702709  0.9702709], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 822.5615234375, Step: 26, Episode: 4\n",
      "====================================\n",
      "Step: 27, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8990333  1.         1.       ], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 847.46826171875, Step: 27, Episode: 4\n",
      "====================================\n",
      "Step: 28, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9133625  0.9133625], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 136.51490783691406, Step: 28, Episode: 4\n",
      "====================================\n",
      "Step: 29, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9533049  1.         1.       ], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 705.0604248046875, Step: 29, Episode: 4\n",
      "====================================\n",
      "Step: 30, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90103847  1.          1.        ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 654.5681762695312, Step: 30, Episode: 4\n",
      "====================================\n",
      "Step: 31, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9749423  0.9749423], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 1.4141792058944702, Step: 31, Episode: 4\n",
      "====================================\n",
      "Step: 32, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9506212  0.9506212], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 489.78759765625, Step: 32, Episode: 4\n",
      "====================================\n",
      "Step: 33, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9891907  0.9891907], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 496.3594665527344, Step: 33, Episode: 4\n",
      "====================================\n",
      "Step: 34, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91509926  1.          1.        ], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 4.4735026359558105, Step: 34, Episode: 4\n",
      "====================================\n",
      "Step: 35, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9853068  1.         1.       ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 308.4972839355469, Step: 35, Episode: 4\n",
      "====================================\n",
      "Step: 36, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.841825  1.        1.      ], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 391.815673828125, Step: 36, Episode: 4\n",
      "====================================\n",
      "Step: 37, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9963598  1.         1.       ], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 15.882379531860352, Step: 37, Episode: 4\n",
      "====================================\n",
      "Step: 38, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9826104  1.         1.       ], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 225.4210968017578, Step: 38, Episode: 4\n",
      "====================================\n",
      "Step: 39, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9294369  0.9294369], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 298.39361572265625, Step: 39, Episode: 4\n",
      "====================================\n",
      "Step: 40, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9499662  0.9499662], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 19.398014068603516, Step: 40, Episode: 4\n",
      "====================================\n",
      "Step: 41, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9741613  0.9741613], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 105.3832778930664, Step: 41, Episode: 4\n",
      "====================================\n",
      "Step: 42, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9867281  0.9867281], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 208.7726593017578, Step: 42, Episode: 4\n",
      "====================================\n",
      "Step: 43, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99978966  1.          1.        ], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 34.047760009765625, Step: 43, Episode: 4\n",
      "====================================\n",
      "Step: 44, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98332155  1.          1.        ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 49.46149826049805, Step: 44, Episode: 4\n",
      "====================================\n",
      "Step: 45, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8685828  0.8685828], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 147.99302673339844, Step: 45, Episode: 4\n",
      "====================================\n",
      "Step: 46, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8703882  0.8703882], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 43.46065902709961, Step: 46, Episode: 4\n",
      "====================================\n",
      "Step: 47, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95996225  1.          1.        ], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 14.845977783203125, Step: 47, Episode: 4\n",
      "====================================\n",
      "Step: 48, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9817987  0.9817987], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 107.0588607788086, Step: 48, Episode: 4\n",
      "====================================\n",
      "Step: 49, Episode: 4\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97445583  1.          1.        ], Reward: -4.9, Done: False\n",
      "Critic loss: 49.363094329833984, Step: 49, Episode: 4\n",
      "====================================\n",
      "Step: 0, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8933319  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 4.8757853507995605, Step: 0, Episode: 5\n",
      "====================================\n",
      "Step: 1, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93018407  1.          1.        ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 63.72771072387695, Step: 1, Episode: 5\n",
      "====================================\n",
      "Step: 2, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9605604  0.9605604], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 51.529964447021484, Step: 2, Episode: 5\n",
      "====================================\n",
      "Step: 3, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.83914745  0.83914745], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.21386003494262695, Step: 3, Episode: 5\n",
      "====================================\n",
      "Step: 4, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96115744  1.          1.        ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 36.646541595458984, Step: 4, Episode: 5\n",
      "====================================\n",
      "Step: 5, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91859245  0.91859245], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 62.4435920715332, Step: 5, Episode: 5\n",
      "====================================\n",
      "Step: 6, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96550494  1.          1.        ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 5.694247722625732, Step: 6, Episode: 5\n",
      "====================================\n",
      "Step: 7, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96552557  1.          1.        ], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 23.986663818359375, Step: 7, Episode: 5\n",
      "====================================\n",
      "Step: 8, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95734435  0.95734435], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 37.41797637939453, Step: 8, Episode: 5\n",
      "====================================\n",
      "Step: 9, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8822637  1.         1.       ], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 12.69113826751709, Step: 9, Episode: 5\n",
      "====================================\n",
      "Step: 10, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7635845  1.         1.       ], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 9.299351692199707, Step: 10, Episode: 5\n",
      "====================================\n",
      "Step: 11, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98311234  1.          1.        ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 33.65147018432617, Step: 11, Episode: 5\n",
      "====================================\n",
      "Step: 12, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9094764  0.9094764], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 21.600095748901367, Step: 12, Episode: 5\n",
      "====================================\n",
      "Step: 13, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9093385  1.         1.       ], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 1.349910020828247, Step: 13, Episode: 5\n",
      "====================================\n",
      "Step: 14, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99813545  1.          1.        ], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 26.116437911987305, Step: 14, Episode: 5\n",
      "====================================\n",
      "Step: 15, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8978826  0.8978826], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 22.409420013427734, Step: 15, Episode: 5\n",
      "====================================\n",
      "Step: 16, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8304497  1.         1.       ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.11020519584417343, Step: 16, Episode: 5\n",
      "====================================\n",
      "Step: 17, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9796262  0.9796262], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 19.20428466796875, Step: 17, Episode: 5\n",
      "====================================\n",
      "Step: 18, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9548244  0.9548244], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 21.392637252807617, Step: 18, Episode: 5\n",
      "====================================\n",
      "Step: 19, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95119756  0.95119756], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.9319389462471008, Step: 19, Episode: 5\n",
      "====================================\n",
      "Step: 20, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92693245  0.92693245], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 8.853652954101562, Step: 20, Episode: 5\n",
      "====================================\n",
      "Step: 21, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93788856  1.          1.        ], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 18.193525314331055, Step: 21, Episode: 5\n",
      "====================================\n",
      "Step: 22, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93231416  1.          1.        ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 3.0284669399261475, Step: 22, Episode: 5\n",
      "====================================\n",
      "Step: 23, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97442764  0.97442764], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 6.460940837860107, Step: 23, Episode: 5\n",
      "====================================\n",
      "Step: 24, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9987256  0.9987256], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 14.200861930847168, Step: 24, Episode: 5\n",
      "====================================\n",
      "Step: 25, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9180299  0.9180299], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 2.6679558753967285, Step: 25, Episode: 5\n",
      "====================================\n",
      "Step: 26, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.84433305  1.          1.        ], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 2.788407564163208, Step: 26, Episode: 5\n",
      "====================================\n",
      "Step: 27, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85503834  0.85503834], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 11.926809310913086, Step: 27, Episode: 5\n",
      "====================================\n",
      "Step: 28, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.83174795  1.          1.        ], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 1.4718983173370361, Step: 28, Episode: 5\n",
      "====================================\n",
      "Step: 29, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97310305  1.          1.        ], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 1.4709970951080322, Step: 29, Episode: 5\n",
      "====================================\n",
      "Step: 30, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95039725  1.          1.        ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 5.987677097320557, Step: 30, Episode: 5\n",
      "====================================\n",
      "Step: 31, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9870634  1.         1.       ], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 1.1393083333969116, Step: 31, Episode: 5\n",
      "====================================\n",
      "Step: 32, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8057993  0.8057993], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.2507959306240082, Step: 32, Episode: 5\n",
      "====================================\n",
      "Step: 33, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91356707  1.          1.        ], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 3.007432222366333, Step: 33, Episode: 5\n",
      "====================================\n",
      "Step: 34, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9551094  0.9551094], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 2.694185733795166, Step: 34, Episode: 5\n",
      "====================================\n",
      "Step: 35, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9750737  1.         1.       ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.05918772891163826, Step: 35, Episode: 5\n",
      "====================================\n",
      "Step: 36, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84969974  0.84969974], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 2.696420431137085, Step: 36, Episode: 5\n",
      "====================================\n",
      "Step: 37, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.935037  1.        1.      ], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 1.3888049125671387, Step: 37, Episode: 5\n",
      "====================================\n",
      "Step: 38, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99022317  1.          1.        ], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 46.1624755859375, Step: 38, Episode: 5\n",
      "====================================\n",
      "Step: 39, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9857526  0.9857526], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.5846714377403259, Step: 39, Episode: 5\n",
      "====================================\n",
      "Step: 40, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95950615  0.95950615], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.5784350633621216, Step: 40, Episode: 5\n",
      "====================================\n",
      "Step: 41, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9198636  1.         1.       ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.3042444884777069, Step: 41, Episode: 5\n",
      "====================================\n",
      "Step: 42, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9854182  0.9854182], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.22228609025478363, Step: 42, Episode: 5\n",
      "====================================\n",
      "Step: 43, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8920371  0.8920371], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.04037199169397354, Step: 43, Episode: 5\n",
      "====================================\n",
      "Step: 44, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.924547  1.        1.      ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.9949747323989868, Step: 44, Episode: 5\n",
      "====================================\n",
      "Step: 45, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87420404  0.87420404], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.5787610411643982, Step: 45, Episode: 5\n",
      "====================================\n",
      "Step: 46, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91385525  1.          1.        ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.6701399683952332, Step: 46, Episode: 5\n",
      "====================================\n",
      "Step: 47, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92199713  0.92199713], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.3751222789287567, Step: 47, Episode: 5\n",
      "====================================\n",
      "Step: 48, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9721219  0.9721219], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.23096142709255219, Step: 48, Episode: 5\n",
      "====================================\n",
      "Step: 49, Episode: 5\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8390229  0.8390229], Reward: -4.9, Done: False\n",
      "Critic loss: 0.43144187331199646, Step: 49, Episode: 5\n",
      "====================================\n",
      "Step: 0, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9496318  0.9496318], Reward: 0, Done: False\n",
      "Critic loss: 0.41009458899497986, Step: 0, Episode: 6\n",
      "====================================\n",
      "Step: 1, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9747073  1.         1.       ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.29132288694381714, Step: 1, Episode: 6\n",
      "====================================\n",
      "Step: 2, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8648905  0.8648905], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 1001.8609619140625, Step: 2, Episode: 6\n",
      "====================================\n",
      "Step: 3, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88521105  1.          1.        ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 1.819016456604004, Step: 3, Episode: 6\n",
      "====================================\n",
      "Step: 4, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98442215  1.          1.        ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 2.119515895843506, Step: 4, Episode: 6\n",
      "====================================\n",
      "Step: 5, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8899821  0.8899821], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.2142774909734726, Step: 5, Episode: 6\n",
      "====================================\n",
      "Step: 6, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8589348  0.8589348], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 1.0378679037094116, Step: 6, Episode: 6\n",
      "====================================\n",
      "Step: 7, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9125796  0.9125796], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 1.17239511013031, Step: 7, Episode: 6\n",
      "====================================\n",
      "Step: 8, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95614636  1.          1.        ], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.4189334809780121, Step: 8, Episode: 6\n",
      "====================================\n",
      "Step: 9, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97756624  1.          1.        ], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.606394350528717, Step: 9, Episode: 6\n",
      "====================================\n",
      "Step: 10, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9993606  1.         1.       ], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 60.03877639770508, Step: 10, Episode: 6\n",
      "====================================\n",
      "Step: 11, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90682137  1.          1.        ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.3700445294380188, Step: 11, Episode: 6\n",
      "====================================\n",
      "Step: 12, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7466303  1.         1.       ], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 1.222703218460083, Step: 12, Episode: 6\n",
      "====================================\n",
      "Step: 13, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85188603  0.85188603], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 1.5279077291488647, Step: 13, Episode: 6\n",
      "====================================\n",
      "Step: 14, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.823151  1.        1.      ], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.1402367800474167, Step: 14, Episode: 6\n",
      "====================================\n",
      "Step: 15, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87366915  0.87366915], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 1.852885127067566, Step: 15, Episode: 6\n",
      "====================================\n",
      "Step: 16, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9075823  0.9075823], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.2824990451335907, Step: 16, Episode: 6\n",
      "====================================\n",
      "Step: 17, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9061657  0.9061657], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.8485910296440125, Step: 17, Episode: 6\n",
      "====================================\n",
      "Step: 18, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9246597  0.9246597], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 55.50455856323242, Step: 18, Episode: 6\n",
      "====================================\n",
      "Step: 19, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9094207  1.         1.       ], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 1.5735059976577759, Step: 19, Episode: 6\n",
      "====================================\n",
      "Step: 20, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9363607  1.         1.       ], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.563250720500946, Step: 20, Episode: 6\n",
      "====================================\n",
      "Step: 21, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9767876  0.9767876], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.758322536945343, Step: 21, Episode: 6\n",
      "====================================\n",
      "Step: 22, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.948493  1.        1.      ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 1.2844080924987793, Step: 22, Episode: 6\n",
      "====================================\n",
      "Step: 23, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.79992664  0.79992664], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.42591592669487, Step: 23, Episode: 6\n",
      "====================================\n",
      "Step: 24, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.82797587  1.          1.        ], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 1.401552438735962, Step: 24, Episode: 6\n",
      "====================================\n",
      "Step: 25, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9524857  0.9524857], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.4592486321926117, Step: 25, Episode: 6\n",
      "====================================\n",
      "Step: 26, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9350078  1.         1.       ], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.31284061074256897, Step: 26, Episode: 6\n",
      "====================================\n",
      "Step: 27, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95377755  1.          1.        ], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.22687558829784393, Step: 27, Episode: 6\n",
      "====================================\n",
      "Step: 28, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9120871  0.9120871], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.8238509297370911, Step: 28, Episode: 6\n",
      "====================================\n",
      "Step: 29, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97639036  0.97639036], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.17046822607517242, Step: 29, Episode: 6\n",
      "====================================\n",
      "Step: 30, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9601445  1.         1.       ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.5030218362808228, Step: 30, Episode: 6\n",
      "====================================\n",
      "Step: 31, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8623338  1.         1.       ], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 2.556971311569214, Step: 31, Episode: 6\n",
      "====================================\n",
      "Step: 32, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9808909  1.         1.       ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.22748732566833496, Step: 32, Episode: 6\n",
      "====================================\n",
      "Step: 33, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.81941736  1.          1.        ], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 2.5627284049987793, Step: 33, Episode: 6\n",
      "====================================\n",
      "Step: 34, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9007154  0.9007154], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.20792065560817719, Step: 34, Episode: 6\n",
      "====================================\n",
      "Step: 35, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94587606  0.94587606], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.07569818943738937, Step: 35, Episode: 6\n",
      "====================================\n",
      "Step: 36, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.936483  0.936483], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.7180190086364746, Step: 36, Episode: 6\n",
      "====================================\n",
      "Step: 37, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9362602  0.9362602], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 1.182236909866333, Step: 37, Episode: 6\n",
      "====================================\n",
      "Step: 38, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90149206  0.90149206], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.20461712777614594, Step: 38, Episode: 6\n",
      "====================================\n",
      "Step: 39, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87869567  0.87869567], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 132.13206481933594, Step: 39, Episode: 6\n",
      "====================================\n",
      "Step: 40, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97310466  1.          1.        ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 1.533690333366394, Step: 40, Episode: 6\n",
      "====================================\n",
      "Step: 41, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8634731  1.         1.       ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 47.80601119995117, Step: 41, Episode: 6\n",
      "====================================\n",
      "Step: 42, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8464821  1.         1.       ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 9.826247215270996, Step: 42, Episode: 6\n",
      "====================================\n",
      "Step: 43, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99053335  1.          1.        ], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 1.9113514423370361, Step: 43, Episode: 6\n",
      "====================================\n",
      "Step: 44, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9301566  1.         1.       ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 9.440905570983887, Step: 44, Episode: 6\n",
      "====================================\n",
      "Step: 45, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9808978  0.9808978], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 6.998417854309082, Step: 45, Episode: 6\n",
      "====================================\n",
      "Step: 46, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9765024  0.9765024], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 3.3029727935791016, Step: 46, Episode: 6\n",
      "====================================\n",
      "Step: 47, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88307655  1.          1.        ], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 3.094796895980835, Step: 47, Episode: 6\n",
      "====================================\n",
      "Step: 48, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98505616  1.          1.        ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 5.360105037689209, Step: 48, Episode: 6\n",
      "====================================\n",
      "Step: 49, Episode: 6\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.856806  0.856806], Reward: -4.9, Done: False\n",
      "Critic loss: 0.21382664144039154, Step: 49, Episode: 6\n",
      "====================================\n",
      "Step: 0, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96271265  0.96271265], Reward: 0, Done: False\n",
      "Critic loss: 2.09879994392395, Step: 0, Episode: 7\n",
      "====================================\n",
      "Step: 1, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.886006  1.        1.      ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 4.149844646453857, Step: 1, Episode: 7\n",
      "====================================\n",
      "Step: 2, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93238485  1.          1.        ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.8117942810058594, Step: 2, Episode: 7\n",
      "====================================\n",
      "Step: 3, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.84491634  1.          1.        ], Reward: -0.30000000000000016, Done: False\n",
      "Critic loss: 3.3829174041748047, Step: 3, Episode: 7\n",
      "====================================\n",
      "Step: 4, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99781156  1.          1.        ], Reward: -0.40000000000000013, Done: False\n",
      "Critic loss: 0.7322563529014587, Step: 4, Episode: 7\n",
      "====================================\n",
      "Step: 5, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8448148  0.8448148], Reward: -0.5000000000000001, Done: False\n",
      "Critic loss: 0.2419835776090622, Step: 5, Episode: 7\n",
      "====================================\n",
      "Step: 6, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.977683  1.        1.      ], Reward: -0.6000000000000001, Done: False\n",
      "Critic loss: 1.7851765155792236, Step: 6, Episode: 7\n",
      "====================================\n",
      "Step: 7, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9333383  1.         1.       ], Reward: -0.7000000000000001, Done: False\n",
      "Critic loss: 1.7602993249893188, Step: 7, Episode: 7\n",
      "====================================\n",
      "Step: 8, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.76831686  0.76831686], Reward: -0.8, Done: False\n",
      "Critic loss: 0.3026018738746643, Step: 8, Episode: 7\n",
      "====================================\n",
      "Step: 9, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99256843  0.99256843], Reward: -0.9, Done: False\n",
      "Critic loss: 1.4252866506576538, Step: 9, Episode: 7\n",
      "====================================\n",
      "Step: 10, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9472753  1.         1.       ], Reward: -1.0, Done: False\n",
      "Critic loss: 0.6834539771080017, Step: 10, Episode: 7\n",
      "====================================\n",
      "Step: 11, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9859706  1.         1.       ], Reward: -1.1, Done: False\n",
      "Critic loss: 0.9564237594604492, Step: 11, Episode: 7\n",
      "====================================\n",
      "Step: 12, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9754722  0.9754722], Reward: -1.2000000000000002, Done: False\n",
      "Critic loss: 0.740146279335022, Step: 12, Episode: 7\n",
      "====================================\n",
      "Step: 13, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92190474  0.92190474], Reward: -1.3000000000000003, Done: False\n",
      "Critic loss: 0.34030869603157043, Step: 13, Episode: 7\n",
      "====================================\n",
      "Step: 14, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9382302  0.9382302], Reward: -1.4000000000000004, Done: False\n",
      "Critic loss: 0.21896131336688995, Step: 14, Episode: 7\n",
      "====================================\n",
      "Step: 15, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9617144  1.         1.       ], Reward: -1.5000000000000004, Done: False\n",
      "Critic loss: 0.18659846484661102, Step: 15, Episode: 7\n",
      "====================================\n",
      "Step: 16, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8678297  1.         1.       ], Reward: -1.6000000000000005, Done: False\n",
      "Critic loss: 0.12033472210168839, Step: 16, Episode: 7\n",
      "====================================\n",
      "Step: 17, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.846949  1.        1.      ], Reward: -1.7000000000000006, Done: False\n",
      "Critic loss: 0.350090891122818, Step: 17, Episode: 7\n",
      "====================================\n",
      "Step: 18, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9311036  0.9311036], Reward: -1.8000000000000007, Done: False\n",
      "Critic loss: 0.4165194630622864, Step: 18, Episode: 7\n",
      "====================================\n",
      "Step: 19, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9096361  0.9096361], Reward: -1.9000000000000008, Done: False\n",
      "Critic loss: 0.39728695154190063, Step: 19, Episode: 7\n",
      "====================================\n",
      "Step: 20, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98755825  1.          1.        ], Reward: -2.000000000000001, Done: False\n",
      "Critic loss: 0.18423870205879211, Step: 20, Episode: 7\n",
      "====================================\n",
      "Step: 21, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9512136  0.9512136], Reward: -2.100000000000001, Done: False\n",
      "Critic loss: 0.47526174783706665, Step: 21, Episode: 7\n",
      "====================================\n",
      "Step: 22, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90935796  0.90935796], Reward: -2.200000000000001, Done: False\n",
      "Critic loss: 0.49557194113731384, Step: 22, Episode: 7\n",
      "====================================\n",
      "Step: 23, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9673768  0.9673768], Reward: -2.300000000000001, Done: False\n",
      "Critic loss: 0.22505079209804535, Step: 23, Episode: 7\n",
      "====================================\n",
      "Step: 24, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9615006  1.         1.       ], Reward: -2.4000000000000012, Done: False\n",
      "Critic loss: 0.5065149068832397, Step: 24, Episode: 7\n",
      "====================================\n",
      "Step: 25, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99108416  0.99108416], Reward: -2.5000000000000013, Done: False\n",
      "Critic loss: 0.8317350745201111, Step: 25, Episode: 7\n",
      "====================================\n",
      "Step: 26, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.934992  0.934992], Reward: -2.6000000000000014, Done: False\n",
      "Critic loss: 0.6482446193695068, Step: 26, Episode: 7\n",
      "====================================\n",
      "Step: 27, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92496645  0.92496645], Reward: -2.7000000000000015, Done: False\n",
      "Critic loss: 1.4224618673324585, Step: 27, Episode: 7\n",
      "====================================\n",
      "Step: 28, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.924659  0.924659], Reward: -2.8000000000000016, Done: False\n",
      "Critic loss: 0.3238185942173004, Step: 28, Episode: 7\n",
      "====================================\n",
      "Step: 29, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85538816  0.85538816], Reward: -2.9000000000000017, Done: False\n",
      "Critic loss: 0.4174579083919525, Step: 29, Episode: 7\n",
      "====================================\n",
      "Step: 30, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99326736  0.99326736], Reward: -3.0000000000000018, Done: False\n",
      "Critic loss: 0.5657949447631836, Step: 30, Episode: 7\n",
      "====================================\n",
      "Step: 31, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99369013  0.99369013], Reward: -3.100000000000002, Done: False\n",
      "Critic loss: 23.07111358642578, Step: 31, Episode: 7\n",
      "====================================\n",
      "Step: 32, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9372603  1.         1.       ], Reward: -3.200000000000002, Done: False\n",
      "Critic loss: 0.4964345097541809, Step: 32, Episode: 7\n",
      "====================================\n",
      "Step: 33, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9281577  1.         1.       ], Reward: -3.3000000000000016, Done: False\n",
      "Critic loss: 0.1993081122636795, Step: 33, Episode: 7\n",
      "====================================\n",
      "Step: 34, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96844846  1.          1.        ], Reward: -3.4000000000000017, Done: False\n",
      "Critic loss: 0.22441649436950684, Step: 34, Episode: 7\n",
      "====================================\n",
      "Step: 35, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8923974  1.         1.       ], Reward: -3.5000000000000018, Done: False\n",
      "Critic loss: 0.10282248258590698, Step: 35, Episode: 7\n",
      "====================================\n",
      "Step: 36, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9272132  0.9272132], Reward: -3.600000000000002, Done: False\n",
      "Critic loss: 0.554085910320282, Step: 36, Episode: 7\n",
      "====================================\n",
      "Step: 37, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9874653  1.         1.       ], Reward: -3.700000000000002, Done: False\n",
      "Critic loss: 0.5884177088737488, Step: 37, Episode: 7\n",
      "====================================\n",
      "Step: 38, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97654474  0.97654474], Reward: -3.800000000000002, Done: False\n",
      "Critic loss: 17.71512794494629, Step: 38, Episode: 7\n",
      "====================================\n",
      "Step: 39, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7629541  0.7629541], Reward: -3.900000000000002, Done: False\n",
      "Critic loss: 3.722203016281128, Step: 39, Episode: 7\n",
      "====================================\n",
      "Step: 40, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9425319  0.9425319], Reward: -4.000000000000002, Done: False\n",
      "Critic loss: 0.49889451265335083, Step: 40, Episode: 7\n",
      "====================================\n",
      "Step: 41, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9612968  1.         1.       ], Reward: -4.100000000000001, Done: False\n",
      "Critic loss: 17.35781478881836, Step: 41, Episode: 7\n",
      "====================================\n",
      "Step: 42, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9846659  1.         1.       ], Reward: -4.200000000000001, Done: False\n",
      "Critic loss: 1.1470154523849487, Step: 42, Episode: 7\n",
      "====================================\n",
      "Step: 43, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94515014  0.94515014], Reward: -4.300000000000001, Done: False\n",
      "Critic loss: 0.6026153564453125, Step: 43, Episode: 7\n",
      "====================================\n",
      "Step: 44, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99799836  0.99799836], Reward: -4.4, Done: False\n",
      "Critic loss: 1.2732871770858765, Step: 44, Episode: 7\n",
      "====================================\n",
      "Step: 45, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8763267  1.         1.       ], Reward: -4.5, Done: False\n",
      "Critic loss: 11.709779739379883, Step: 45, Episode: 7\n",
      "====================================\n",
      "Step: 46, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8317222  1.         1.       ], Reward: -4.6, Done: False\n",
      "Critic loss: 0.08913949877023697, Step: 46, Episode: 7\n",
      "====================================\n",
      "Step: 47, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9233517  1.         1.       ], Reward: -4.699999999999999, Done: False\n",
      "Critic loss: 0.24057380855083466, Step: 47, Episode: 7\n",
      "====================================\n",
      "Step: 48, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.915415  1.        1.      ], Reward: -4.799999999999999, Done: False\n",
      "Critic loss: 0.21719157695770264, Step: 48, Episode: 7\n",
      "====================================\n",
      "Step: 49, Episode: 7\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9781823  0.9781823], Reward: -4.899999999999999, Done: False\n",
      "Critic loss: 0.3634583055973053, Step: 49, Episode: 7\n",
      "====================================\n",
      "Step: 0, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95966417  0.95966417], Reward: 0, Done: False\n",
      "Critic loss: 0.35571178793907166, Step: 0, Episode: 8\n",
      "====================================\n",
      "Step: 1, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9585619  0.9585619], Reward: -0.09999999999999998, Done: False\n",
      "Critic loss: 0.27332404255867004, Step: 1, Episode: 8\n",
      "====================================\n",
      "Step: 2, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84250903  0.84250903], Reward: -0.19999999999999996, Done: False\n",
      "Critic loss: 0.2387901097536087, Step: 2, Episode: 8\n",
      "====================================\n",
      "Step: 3, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94795793  1.          1.        ], Reward: -0.29999999999999993, Done: False\n",
      "Critic loss: 0.13728126883506775, Step: 3, Episode: 8\n",
      "====================================\n",
      "Step: 4, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9056566  1.         1.       ], Reward: -0.3999999999999999, Done: False\n",
      "Critic loss: 0.4914260506629944, Step: 4, Episode: 8\n",
      "====================================\n",
      "Step: 5, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.946075  1.        1.      ], Reward: -0.4999999999999999, Done: False\n",
      "Critic loss: 0.0827774703502655, Step: 5, Episode: 8\n",
      "====================================\n",
      "Step: 6, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9620804  1.         1.       ], Reward: -0.5999999999999999, Done: False\n",
      "Critic loss: 4.377058982849121, Step: 6, Episode: 8\n",
      "====================================\n",
      "Step: 7, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96278566  0.96278566], Reward: -0.6999999999999998, Done: False\n",
      "Critic loss: 0.483534574508667, Step: 7, Episode: 8\n",
      "====================================\n",
      "Step: 8, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8601158  0.8601158], Reward: -0.7999999999999998, Done: False\n",
      "Critic loss: 0.5005084872245789, Step: 8, Episode: 8\n",
      "====================================\n",
      "Step: 9, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87233436  0.87233436], Reward: -0.8999999999999998, Done: False\n",
      "Critic loss: 0.22990356385707855, Step: 9, Episode: 8\n",
      "====================================\n",
      "Step: 10, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9547089  0.9547089], Reward: -0.9999999999999998, Done: False\n",
      "Critic loss: 1.5916119813919067, Step: 10, Episode: 8\n",
      "====================================\n",
      "Step: 11, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99429494  1.          1.        ], Reward: -1.0999999999999999, Done: False\n",
      "Critic loss: 0.2311558574438095, Step: 11, Episode: 8\n",
      "====================================\n",
      "Step: 12, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90804654  0.90804654], Reward: -1.2, Done: False\n",
      "Critic loss: 1.2927950620651245, Step: 12, Episode: 8\n",
      "====================================\n",
      "Step: 13, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9321723  0.9321723], Reward: -1.3, Done: False\n",
      "Critic loss: 0.200531005859375, Step: 13, Episode: 8\n",
      "====================================\n",
      "Step: 14, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94649243  0.94649243], Reward: -1.4000000000000001, Done: False\n",
      "Critic loss: 0.4022849500179291, Step: 14, Episode: 8\n",
      "====================================\n",
      "Step: 15, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9146044  1.         1.       ], Reward: -1.5, Done: False\n",
      "Critic loss: 0.07209350913763046, Step: 15, Episode: 8\n",
      "====================================\n",
      "Step: 16, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9393745  0.9393745], Reward: -1.6, Done: False\n",
      "Critic loss: 0.39721253514289856, Step: 16, Episode: 8\n",
      "====================================\n",
      "Step: 17, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8590507  1.         1.       ], Reward: -1.7000000000000002, Done: False\n",
      "Critic loss: 2.435103178024292, Step: 17, Episode: 8\n",
      "====================================\n",
      "Step: 18, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9908356  1.         1.       ], Reward: -1.8000000000000003, Done: False\n",
      "Critic loss: 0.6176870465278625, Step: 18, Episode: 8\n",
      "====================================\n",
      "Step: 19, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9695719  1.         1.       ], Reward: -1.9000000000000004, Done: False\n",
      "Critic loss: 1.710558533668518, Step: 19, Episode: 8\n",
      "====================================\n",
      "Step: 20, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8518671  0.8518671], Reward: -2.0000000000000004, Done: False\n",
      "Critic loss: 0.38972851634025574, Step: 20, Episode: 8\n",
      "====================================\n",
      "Step: 21, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9586758  0.9586758], Reward: -2.1000000000000005, Done: False\n",
      "Critic loss: 0.6563670039176941, Step: 21, Episode: 8\n",
      "====================================\n",
      "Step: 22, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.886379  1.        1.      ], Reward: -2.2000000000000006, Done: False\n",
      "Critic loss: 0.7226331830024719, Step: 22, Episode: 8\n",
      "====================================\n",
      "Step: 23, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94514924  0.94514924], Reward: -2.3000000000000007, Done: False\n",
      "Critic loss: 0.1198495626449585, Step: 23, Episode: 8\n",
      "====================================\n",
      "Step: 24, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9229631  0.9229631], Reward: -2.400000000000001, Done: False\n",
      "Critic loss: 0.8602828979492188, Step: 24, Episode: 8\n",
      "====================================\n",
      "Step: 25, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8276539  1.         1.       ], Reward: -2.500000000000001, Done: False\n",
      "Critic loss: 0.19692140817642212, Step: 25, Episode: 8\n",
      "====================================\n",
      "Step: 26, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9918562  1.         1.       ], Reward: -2.600000000000001, Done: False\n",
      "Critic loss: 0.5923018455505371, Step: 26, Episode: 8\n",
      "====================================\n",
      "Step: 27, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.739249  0.739249], Reward: -2.700000000000001, Done: False\n",
      "Critic loss: 0.4625978469848633, Step: 27, Episode: 8\n",
      "====================================\n",
      "Step: 28, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9031537  0.9031537], Reward: -2.800000000000001, Done: False\n",
      "Critic loss: 0.24612677097320557, Step: 28, Episode: 8\n",
      "====================================\n",
      "Step: 29, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99864703  1.          1.        ], Reward: -2.9000000000000012, Done: False\n",
      "Critic loss: 0.7411943674087524, Step: 29, Episode: 8\n",
      "====================================\n",
      "Step: 30, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9476743  0.9476743], Reward: -3.0000000000000013, Done: False\n",
      "Critic loss: 0.4363485276699066, Step: 30, Episode: 8\n",
      "====================================\n",
      "Step: 31, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.89052624  0.89052624], Reward: -3.1000000000000014, Done: False\n",
      "Critic loss: 0.28926846385002136, Step: 31, Episode: 8\n",
      "====================================\n",
      "Step: 32, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9752314  1.         1.       ], Reward: -3.2000000000000015, Done: False\n",
      "Critic loss: 0.0846804603934288, Step: 32, Episode: 8\n",
      "====================================\n",
      "Step: 33, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9366486  1.         1.       ], Reward: -3.3000000000000016, Done: False\n",
      "Critic loss: 0.8305055499076843, Step: 33, Episode: 8\n",
      "====================================\n",
      "Step: 34, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9918163  1.         1.       ], Reward: -3.4000000000000017, Done: False\n",
      "Critic loss: 0.03781146928668022, Step: 34, Episode: 8\n",
      "====================================\n",
      "Step: 35, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8446485  0.8446485], Reward: -3.5000000000000018, Done: False\n",
      "Critic loss: 0.16789035499095917, Step: 35, Episode: 8\n",
      "====================================\n",
      "Step: 36, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9347658  1.         1.       ], Reward: -3.600000000000002, Done: False\n",
      "Critic loss: 0.3368453085422516, Step: 36, Episode: 8\n",
      "====================================\n",
      "Step: 37, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95829827  0.95829827], Reward: -3.700000000000002, Done: False\n",
      "Critic loss: 0.5258254408836365, Step: 37, Episode: 8\n",
      "====================================\n",
      "Step: 38, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9236464  1.         1.       ], Reward: -3.800000000000002, Done: False\n",
      "Critic loss: 0.14941616356372833, Step: 38, Episode: 8\n",
      "====================================\n",
      "Step: 39, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9898358  1.         1.       ], Reward: -3.900000000000002, Done: False\n",
      "Critic loss: 0.35912710428237915, Step: 39, Episode: 8\n",
      "====================================\n",
      "Step: 40, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9814453  1.         1.       ], Reward: -4.000000000000002, Done: False\n",
      "Critic loss: 0.16358478367328644, Step: 40, Episode: 8\n",
      "====================================\n",
      "Step: 41, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8093264  1.         1.       ], Reward: -4.100000000000001, Done: False\n",
      "Critic loss: 0.14344869554042816, Step: 41, Episode: 8\n",
      "====================================\n",
      "Step: 42, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96370995  0.96370995], Reward: -4.200000000000001, Done: False\n",
      "Critic loss: 0.31666263937950134, Step: 42, Episode: 8\n",
      "====================================\n",
      "Step: 43, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95225775  0.95225775], Reward: -4.300000000000001, Done: False\n",
      "Critic loss: 0.17117153108119965, Step: 43, Episode: 8\n",
      "====================================\n",
      "Step: 44, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97410214  1.          1.        ], Reward: -4.4, Done: False\n",
      "Critic loss: 0.18105709552764893, Step: 44, Episode: 8\n",
      "====================================\n",
      "Step: 45, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9877785  0.9877785], Reward: -4.5, Done: False\n",
      "Critic loss: 0.31308087706565857, Step: 45, Episode: 8\n",
      "====================================\n",
      "Step: 46, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9446452  1.         1.       ], Reward: -4.6, Done: False\n",
      "Critic loss: 0.17775680124759674, Step: 46, Episode: 8\n",
      "====================================\n",
      "Step: 47, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.89860845  0.89860845], Reward: -4.699999999999999, Done: False\n",
      "Critic loss: 0.03238292410969734, Step: 47, Episode: 8\n",
      "====================================\n",
      "Step: 48, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9918857  0.9918857], Reward: -4.799999999999999, Done: False\n",
      "Critic loss: 0.11755354702472687, Step: 48, Episode: 8\n",
      "====================================\n",
      "Step: 49, Episode: 8\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8900614  0.8900614], Reward: -4.899999999999999, Done: False\n",
      "Critic loss: 0.4537554383277893, Step: 49, Episode: 8\n",
      "====================================\n",
      "Step: 0, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9575446  0.9575446], Reward: 0, Done: False\n",
      "Critic loss: 0.5018717050552368, Step: 0, Episode: 9\n",
      "====================================\n",
      "Step: 1, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9336358  0.9336358], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.24797800183296204, Step: 1, Episode: 9\n",
      "====================================\n",
      "Step: 2, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8912488  1.         1.       ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.5096610188484192, Step: 2, Episode: 9\n",
      "====================================\n",
      "Step: 3, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9880216  1.         1.       ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.3389289081096649, Step: 3, Episode: 9\n",
      "====================================\n",
      "Step: 4, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8823182  0.8823182], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.49666833877563477, Step: 4, Episode: 9\n",
      "====================================\n",
      "Step: 5, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.76418585  1.          1.        ], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 3.952401876449585, Step: 5, Episode: 9\n",
      "====================================\n",
      "Step: 6, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9316521  1.         1.       ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.052619416266679764, Step: 6, Episode: 9\n",
      "====================================\n",
      "Step: 7, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95038015  1.          1.        ], Reward: -0.7000000000000005, Done: False\n",
      "Critic loss: 0.6757122874259949, Step: 7, Episode: 9\n",
      "====================================\n",
      "Step: 8, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7718985  0.7718985], Reward: -0.8000000000000005, Done: False\n",
      "Critic loss: 0.7492734789848328, Step: 8, Episode: 9\n",
      "====================================\n",
      "Step: 9, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9255387  0.9255387], Reward: -0.9000000000000005, Done: False\n",
      "Critic loss: 0.5794083476066589, Step: 9, Episode: 9\n",
      "====================================\n",
      "Step: 10, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9598722  1.         1.       ], Reward: -1.0000000000000004, Done: False\n",
      "Critic loss: 1.6318391561508179, Step: 10, Episode: 9\n",
      "====================================\n",
      "Step: 11, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87485135  1.          1.        ], Reward: -1.1000000000000005, Done: False\n",
      "Critic loss: 0.12660136818885803, Step: 11, Episode: 9\n",
      "====================================\n",
      "Step: 12, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9550433  0.9550433], Reward: -1.2000000000000006, Done: False\n",
      "Critic loss: 0.578100323677063, Step: 12, Episode: 9\n",
      "====================================\n",
      "Step: 13, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.800427  0.800427], Reward: -1.3000000000000007, Done: False\n",
      "Critic loss: 0.7488808035850525, Step: 13, Episode: 9\n",
      "====================================\n",
      "Step: 14, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9620394  1.         1.       ], Reward: -1.4000000000000008, Done: False\n",
      "Critic loss: 0.3705030083656311, Step: 14, Episode: 9\n",
      "====================================\n",
      "Step: 15, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9015214  1.         1.       ], Reward: -1.5000000000000009, Done: False\n",
      "Critic loss: 0.3774507939815521, Step: 15, Episode: 9\n",
      "====================================\n",
      "Step: 16, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87112343  1.          1.        ], Reward: -1.600000000000001, Done: False\n",
      "Critic loss: 0.11956863850355148, Step: 16, Episode: 9\n",
      "====================================\n",
      "Step: 17, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87335485  1.          1.        ], Reward: -1.700000000000001, Done: False\n",
      "Critic loss: 0.4990866780281067, Step: 17, Episode: 9\n",
      "====================================\n",
      "Step: 18, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.77954566  1.          1.        ], Reward: -1.8000000000000012, Done: False\n",
      "Critic loss: 0.1650909185409546, Step: 18, Episode: 9\n",
      "====================================\n",
      "Step: 19, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9697274  0.9697274], Reward: -1.9000000000000012, Done: False\n",
      "Critic loss: 0.2308008223772049, Step: 19, Episode: 9\n",
      "====================================\n",
      "Step: 20, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95254654  1.          1.        ], Reward: -2.0000000000000013, Done: False\n",
      "Critic loss: 2.5955657958984375, Step: 20, Episode: 9\n",
      "====================================\n",
      "Step: 21, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8121656  1.         1.       ], Reward: -2.1000000000000014, Done: False\n",
      "Critic loss: 0.05727719888091087, Step: 21, Episode: 9\n",
      "====================================\n",
      "Step: 22, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9164248  0.9164248], Reward: -2.2000000000000015, Done: False\n",
      "Critic loss: 0.2226371318101883, Step: 22, Episode: 9\n",
      "====================================\n",
      "Step: 23, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.86353505  1.          1.        ], Reward: -2.3000000000000016, Done: False\n",
      "Critic loss: 0.1533387005329132, Step: 23, Episode: 9\n",
      "====================================\n",
      "Step: 24, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8791952  1.         1.       ], Reward: -2.4000000000000017, Done: False\n",
      "Critic loss: 0.3440442979335785, Step: 24, Episode: 9\n",
      "====================================\n",
      "Step: 25, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95762634  1.          1.        ], Reward: -2.5000000000000018, Done: False\n",
      "Critic loss: 0.12457606941461563, Step: 25, Episode: 9\n",
      "====================================\n",
      "Step: 26, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.807648  1.        1.      ], Reward: -2.600000000000002, Done: False\n",
      "Critic loss: 0.1386219710111618, Step: 26, Episode: 9\n",
      "====================================\n",
      "Step: 27, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.77535987  1.          1.        ], Reward: -2.700000000000002, Done: False\n",
      "Critic loss: 0.04520497843623161, Step: 27, Episode: 9\n",
      "====================================\n",
      "Step: 28, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87882847  0.87882847], Reward: -2.800000000000002, Done: False\n",
      "Critic loss: 0.14667773246765137, Step: 28, Episode: 9\n",
      "====================================\n",
      "Step: 29, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9613898  1.         1.       ], Reward: -2.900000000000002, Done: False\n",
      "Critic loss: 0.09480606019496918, Step: 29, Episode: 9\n",
      "====================================\n",
      "Step: 30, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9875099  0.9875099], Reward: -3.000000000000002, Done: False\n",
      "Critic loss: 0.31226369738578796, Step: 30, Episode: 9\n",
      "====================================\n",
      "Step: 31, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.927445  0.927445], Reward: -3.1000000000000023, Done: False\n",
      "Critic loss: 0.0811426118016243, Step: 31, Episode: 9\n",
      "====================================\n",
      "Step: 32, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9351118  1.         1.       ], Reward: -3.2000000000000024, Done: False\n",
      "Critic loss: 0.11395438015460968, Step: 32, Episode: 9\n",
      "====================================\n",
      "Step: 33, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9770952  0.9770952], Reward: -3.3000000000000025, Done: False\n",
      "Critic loss: 0.3656174838542938, Step: 33, Episode: 9\n",
      "====================================\n",
      "Step: 34, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.86872894  1.          1.        ], Reward: -3.4000000000000026, Done: False\n",
      "Critic loss: 0.2059554159641266, Step: 34, Episode: 9\n",
      "====================================\n",
      "Step: 35, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8888126  1.         1.       ], Reward: -3.5000000000000027, Done: False\n",
      "Critic loss: 0.4039539396762848, Step: 35, Episode: 9\n",
      "====================================\n",
      "Step: 36, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90778154  1.          1.        ], Reward: -3.6000000000000028, Done: False\n",
      "Critic loss: 0.10030708461999893, Step: 36, Episode: 9\n",
      "====================================\n",
      "Step: 37, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9254207  1.         1.       ], Reward: -3.700000000000003, Done: False\n",
      "Critic loss: 0.18169324100017548, Step: 37, Episode: 9\n",
      "====================================\n",
      "Step: 38, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.92218846  1.          1.        ], Reward: -3.800000000000003, Done: False\n",
      "Critic loss: 0.15324729681015015, Step: 38, Episode: 9\n",
      "====================================\n",
      "Step: 39, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91867375  0.91867375], Reward: -3.900000000000003, Done: False\n",
      "Critic loss: 0.2371993064880371, Step: 39, Episode: 9\n",
      "====================================\n",
      "Step: 40, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8268555  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.3178179860115051, Step: 40, Episode: 9\n",
      "====================================\n",
      "Step: 41, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9376561  0.9376561], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.4721745550632477, Step: 41, Episode: 9\n",
      "====================================\n",
      "Step: 42, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.811665  1.        1.      ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.08687647432088852, Step: 42, Episode: 9\n",
      "====================================\n",
      "Step: 43, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96022004  0.96022004], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.3743487000465393, Step: 43, Episode: 9\n",
      "====================================\n",
      "Step: 44, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99243593  0.99243593], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.37620973587036133, Step: 44, Episode: 9\n",
      "====================================\n",
      "Step: 45, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8172076  1.         1.       ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.2672719657421112, Step: 45, Episode: 9\n",
      "====================================\n",
      "Step: 46, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93139166  1.          1.        ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.9336279034614563, Step: 46, Episode: 9\n",
      "====================================\n",
      "Step: 47, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97734755  0.97734755], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.18717968463897705, Step: 47, Episode: 9\n",
      "====================================\n",
      "Step: 48, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9963162  1.         1.       ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 1.0781199932098389, Step: 48, Episode: 9\n",
      "====================================\n",
      "Step: 49, Episode: 9\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8942933  1.         1.       ], Reward: -4.9, Done: False\n",
      "Critic loss: 0.741296112537384, Step: 49, Episode: 9\n",
      "====================================\n",
      "Step: 0, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9683575  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 0.2939727306365967, Step: 0, Episode: 10\n",
      "====================================\n",
      "Step: 1, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94663036  0.94663036], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.9529817700386047, Step: 1, Episode: 10\n",
      "====================================\n",
      "Step: 2, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.949007  0.949007], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.11998937278985977, Step: 2, Episode: 10\n",
      "====================================\n",
      "Step: 3, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.83030784  1.          1.        ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.6117863059043884, Step: 3, Episode: 10\n",
      "====================================\n",
      "Step: 4, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8930215  0.8930215], Reward: -0.40000000000000024, Done: False\n",
      "Critic loss: 0.04216701537370682, Step: 4, Episode: 10\n",
      "====================================\n",
      "Step: 5, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93880343  0.93880343], Reward: -0.5000000000000002, Done: False\n",
      "Critic loss: 0.1787577122449875, Step: 5, Episode: 10\n",
      "====================================\n",
      "Step: 6, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97911793  0.97911793], Reward: -0.6000000000000002, Done: False\n",
      "Critic loss: 0.3588741421699524, Step: 6, Episode: 10\n",
      "====================================\n",
      "Step: 7, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8908844  1.         1.       ], Reward: -0.7000000000000002, Done: False\n",
      "Critic loss: 0.3837558329105377, Step: 7, Episode: 10\n",
      "====================================\n",
      "Step: 8, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96963346  0.96963346], Reward: -0.8000000000000002, Done: False\n",
      "Critic loss: 0.3012358844280243, Step: 8, Episode: 10\n",
      "====================================\n",
      "Step: 9, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97094095  1.          1.        ], Reward: -0.9000000000000001, Done: False\n",
      "Critic loss: 0.14552903175354004, Step: 9, Episode: 10\n",
      "====================================\n",
      "Step: 10, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84643734  0.84643734], Reward: -1.0, Done: False\n",
      "Critic loss: 0.21774998307228088, Step: 10, Episode: 10\n",
      "====================================\n",
      "Step: 11, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8979622  1.         1.       ], Reward: -1.1, Done: False\n",
      "Critic loss: 0.14522771537303925, Step: 11, Episode: 10\n",
      "====================================\n",
      "Step: 12, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9785864  1.         1.       ], Reward: -1.2000000000000002, Done: False\n",
      "Critic loss: 0.09980586916208267, Step: 12, Episode: 10\n",
      "====================================\n",
      "Step: 13, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87656665  1.          1.        ], Reward: -1.3000000000000003, Done: False\n",
      "Critic loss: 0.2640804052352905, Step: 13, Episode: 10\n",
      "====================================\n",
      "Step: 14, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94894665  1.          1.        ], Reward: -1.4000000000000004, Done: False\n",
      "Critic loss: 0.08522914350032806, Step: 14, Episode: 10\n",
      "====================================\n",
      "Step: 15, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85423577  0.85423577], Reward: -1.5000000000000004, Done: False\n",
      "Critic loss: 2.4352123737335205, Step: 15, Episode: 10\n",
      "====================================\n",
      "Step: 16, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9632448  0.9632448], Reward: -1.6000000000000005, Done: False\n",
      "Critic loss: 0.07423638552427292, Step: 16, Episode: 10\n",
      "====================================\n",
      "Step: 17, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99916387  1.          1.        ], Reward: -1.7000000000000006, Done: False\n",
      "Critic loss: 0.29308149218559265, Step: 17, Episode: 10\n",
      "====================================\n",
      "Step: 18, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9002079  1.         1.       ], Reward: -1.8000000000000007, Done: False\n",
      "Critic loss: 0.08402768522500992, Step: 18, Episode: 10\n",
      "====================================\n",
      "Step: 19, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9491543  0.9491543], Reward: -1.9000000000000008, Done: False\n",
      "Critic loss: 0.2446853220462799, Step: 19, Episode: 10\n",
      "====================================\n",
      "Step: 20, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94376  1.       1.     ], Reward: -2.000000000000001, Done: False\n",
      "Critic loss: 0.1179192066192627, Step: 20, Episode: 10\n",
      "====================================\n",
      "Step: 21, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.957613  1.        1.      ], Reward: -2.100000000000001, Done: False\n",
      "Critic loss: 0.32523682713508606, Step: 21, Episode: 10\n",
      "====================================\n",
      "Step: 22, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8467502  0.8467502], Reward: -2.200000000000001, Done: False\n",
      "Critic loss: 0.30602210760116577, Step: 22, Episode: 10\n",
      "====================================\n",
      "Step: 23, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9146855  0.9146855], Reward: -2.300000000000001, Done: False\n",
      "Critic loss: 0.1411486566066742, Step: 23, Episode: 10\n",
      "====================================\n",
      "Step: 24, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8504736  0.8504736], Reward: -2.4000000000000012, Done: False\n",
      "Critic loss: 0.23602639138698578, Step: 24, Episode: 10\n",
      "====================================\n",
      "Step: 25, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.80385697  1.          1.        ], Reward: -2.5000000000000013, Done: False\n",
      "Critic loss: 0.25028136372566223, Step: 25, Episode: 10\n",
      "====================================\n",
      "Step: 26, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.68461096  0.68461096], Reward: -2.6000000000000014, Done: False\n",
      "Critic loss: 0.2783878743648529, Step: 26, Episode: 10\n",
      "====================================\n",
      "Step: 27, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90054035  0.90054035], Reward: -2.7000000000000015, Done: False\n",
      "Critic loss: 0.06149016693234444, Step: 27, Episode: 10\n",
      "====================================\n",
      "Step: 28, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9492641  0.9492641], Reward: -2.8000000000000016, Done: False\n",
      "Critic loss: 0.09599150717258453, Step: 28, Episode: 10\n",
      "====================================\n",
      "Step: 29, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91361713  1.          1.        ], Reward: -2.9000000000000017, Done: False\n",
      "Critic loss: 0.09140460938215256, Step: 29, Episode: 10\n",
      "====================================\n",
      "Step: 30, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.990181  0.990181], Reward: -3.0000000000000018, Done: False\n",
      "Critic loss: 0.15361227095127106, Step: 30, Episode: 10\n",
      "====================================\n",
      "Step: 31, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.92842066  1.          1.        ], Reward: -3.100000000000002, Done: False\n",
      "Critic loss: 0.12068217247724533, Step: 31, Episode: 10\n",
      "====================================\n",
      "Step: 32, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96428686  0.96428686], Reward: -3.200000000000002, Done: False\n",
      "Critic loss: 0.09539692848920822, Step: 32, Episode: 10\n",
      "====================================\n",
      "Step: 33, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93187064  0.93187064], Reward: -3.300000000000002, Done: False\n",
      "Critic loss: 0.12513965368270874, Step: 33, Episode: 10\n",
      "====================================\n",
      "Step: 34, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9460279  0.9460279], Reward: -3.400000000000002, Done: False\n",
      "Critic loss: 0.28839442133903503, Step: 34, Episode: 10\n",
      "====================================\n",
      "Step: 35, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9949137  0.9949137], Reward: -3.500000000000002, Done: False\n",
      "Critic loss: 0.07247648388147354, Step: 35, Episode: 10\n",
      "====================================\n",
      "Step: 36, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9743931  1.         1.       ], Reward: -3.6000000000000023, Done: False\n",
      "Critic loss: 0.14929236471652985, Step: 36, Episode: 10\n",
      "====================================\n",
      "Step: 37, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9906191  1.         1.       ], Reward: -3.7000000000000024, Done: False\n",
      "Critic loss: 0.25580117106437683, Step: 37, Episode: 10\n",
      "====================================\n",
      "Step: 38, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9146778  1.         1.       ], Reward: -3.8000000000000025, Done: False\n",
      "Critic loss: 0.15623125433921814, Step: 38, Episode: 10\n",
      "====================================\n",
      "Step: 39, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91570455  0.91570455], Reward: -3.9000000000000026, Done: False\n",
      "Critic loss: 0.3825986981391907, Step: 39, Episode: 10\n",
      "====================================\n",
      "Step: 40, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9829437  1.         1.       ], Reward: -4.000000000000003, Done: False\n",
      "Critic loss: 0.12021919339895248, Step: 40, Episode: 10\n",
      "====================================\n",
      "Step: 41, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9031114  0.9031114], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.2042892426252365, Step: 41, Episode: 10\n",
      "====================================\n",
      "Step: 42, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85162145  0.85162145], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.0794820636510849, Step: 42, Episode: 10\n",
      "====================================\n",
      "Step: 43, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.874867  1.        1.      ], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.06656186282634735, Step: 43, Episode: 10\n",
      "====================================\n",
      "Step: 44, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94183576  1.          1.        ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.3081962764263153, Step: 44, Episode: 10\n",
      "====================================\n",
      "Step: 45, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9175159  0.9175159], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.20677916705608368, Step: 45, Episode: 10\n",
      "====================================\n",
      "Step: 46, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9834241  1.         1.       ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.14787077903747559, Step: 46, Episode: 10\n",
      "====================================\n",
      "Step: 47, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93069863  0.93069863], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.40618401765823364, Step: 47, Episode: 10\n",
      "====================================\n",
      "Step: 48, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8696454  0.8696454], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.4692772924900055, Step: 48, Episode: 10\n",
      "====================================\n",
      "Step: 49, Episode: 10\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.70738804  0.70738804], Reward: -4.9, Done: False\n",
      "Critic loss: 0.04020407423377037, Step: 49, Episode: 10\n",
      "====================================\n",
      "Step: 0, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96438074  0.96438074], Reward: 0, Done: False\n",
      "Critic loss: 0.0860556811094284, Step: 0, Episode: 11\n",
      "====================================\n",
      "Step: 1, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9653839  0.9653839], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.15091846883296967, Step: 1, Episode: 11\n",
      "====================================\n",
      "Step: 2, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8717185  0.8717185], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.20892031490802765, Step: 2, Episode: 11\n",
      "====================================\n",
      "Step: 3, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9809842  1.         1.       ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.19025759398937225, Step: 3, Episode: 11\n",
      "====================================\n",
      "Step: 4, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9807979  1.         1.       ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.4428865611553192, Step: 4, Episode: 11\n",
      "====================================\n",
      "Step: 5, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9456042  1.         1.       ], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.0432998426258564, Step: 5, Episode: 11\n",
      "====================================\n",
      "Step: 6, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9998392  1.         1.       ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.23533017933368683, Step: 6, Episode: 11\n",
      "====================================\n",
      "Step: 7, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.878476  0.878476], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.4543241560459137, Step: 7, Episode: 11\n",
      "====================================\n",
      "Step: 8, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9759957  0.9759957], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.13573764264583588, Step: 8, Episode: 11\n",
      "====================================\n",
      "Step: 9, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97584414  1.          1.        ], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 1.677332878112793, Step: 9, Episode: 11\n",
      "====================================\n",
      "Step: 10, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9268893  0.9268893], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.24016208946704865, Step: 10, Episode: 11\n",
      "====================================\n",
      "Step: 11, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9575842  1.         1.       ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.43261003494262695, Step: 11, Episode: 11\n",
      "====================================\n",
      "Step: 12, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9811662  0.9811662], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.14953289926052094, Step: 12, Episode: 11\n",
      "====================================\n",
      "Step: 13, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98733246  1.          1.        ], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.6160852313041687, Step: 13, Episode: 11\n",
      "====================================\n",
      "Step: 14, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98071057  1.          1.        ], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.28705620765686035, Step: 14, Episode: 11\n",
      "====================================\n",
      "Step: 15, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87337744  0.87337744], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 0.7027860283851624, Step: 15, Episode: 11\n",
      "====================================\n",
      "Step: 16, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96367157  0.96367157], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.2716129720211029, Step: 16, Episode: 11\n",
      "====================================\n",
      "Step: 17, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9259019  1.         1.       ], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.2514210045337677, Step: 17, Episode: 11\n",
      "====================================\n",
      "Step: 18, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9386967  0.9386967], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.11144299805164337, Step: 18, Episode: 11\n",
      "====================================\n",
      "Step: 19, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91774637  0.91774637], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.19503159821033478, Step: 19, Episode: 11\n",
      "====================================\n",
      "Step: 20, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99140614  0.99140614], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.14927653968334198, Step: 20, Episode: 11\n",
      "====================================\n",
      "Step: 21, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97150147  0.97150147], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.630399227142334, Step: 21, Episode: 11\n",
      "====================================\n",
      "Step: 22, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.943297  1.        1.      ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.20814572274684906, Step: 22, Episode: 11\n",
      "====================================\n",
      "Step: 23, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.988856  1.        1.      ], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.7586470246315002, Step: 23, Episode: 11\n",
      "====================================\n",
      "Step: 24, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.961617  0.961617], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.07926950603723526, Step: 24, Episode: 11\n",
      "====================================\n",
      "Step: 25, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97072273  0.97072273], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.1935623735189438, Step: 25, Episode: 11\n",
      "====================================\n",
      "Step: 26, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9820968  1.         1.       ], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 1.1144260168075562, Step: 26, Episode: 11\n",
      "====================================\n",
      "Step: 27, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.78066003  0.78066003], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.5141939520835876, Step: 27, Episode: 11\n",
      "====================================\n",
      "Step: 28, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86234426  0.86234426], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.7309074401855469, Step: 28, Episode: 11\n",
      "====================================\n",
      "Step: 29, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92551833  0.92551833], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.19763825833797455, Step: 29, Episode: 11\n",
      "====================================\n",
      "Step: 30, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95931035  1.          1.        ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.34455591440200806, Step: 30, Episode: 11\n",
      "====================================\n",
      "Step: 31, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9898029  1.         1.       ], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.2707264721393585, Step: 31, Episode: 11\n",
      "====================================\n",
      "Step: 32, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84505767  0.84505767], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 1.5282981395721436, Step: 32, Episode: 11\n",
      "====================================\n",
      "Step: 33, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9433774  0.9433774], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.3668590784072876, Step: 33, Episode: 11\n",
      "====================================\n",
      "Step: 34, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92650706  0.92650706], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.348969429731369, Step: 34, Episode: 11\n",
      "====================================\n",
      "Step: 35, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96148074  1.          1.        ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.9320913553237915, Step: 35, Episode: 11\n",
      "====================================\n",
      "Step: 36, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96744  1.       1.     ], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.13940174877643585, Step: 36, Episode: 11\n",
      "====================================\n",
      "Step: 37, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.935557  0.935557], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.3349892795085907, Step: 37, Episode: 11\n",
      "====================================\n",
      "Step: 38, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91106397  1.          1.        ], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.2190544605255127, Step: 38, Episode: 11\n",
      "====================================\n",
      "Step: 39, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9803194  1.         1.       ], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.09283280372619629, Step: 39, Episode: 11\n",
      "====================================\n",
      "Step: 40, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9145195  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.6853481531143188, Step: 40, Episode: 11\n",
      "====================================\n",
      "Step: 41, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.80432725  1.          1.        ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.6211779117584229, Step: 41, Episode: 11\n",
      "====================================\n",
      "Step: 42, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93362206  0.93362206], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.49254676699638367, Step: 42, Episode: 11\n",
      "====================================\n",
      "Step: 43, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97359246  1.          1.        ], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.07390252500772476, Step: 43, Episode: 11\n",
      "====================================\n",
      "Step: 44, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96894  1.       1.     ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.1942395567893982, Step: 44, Episode: 11\n",
      "====================================\n",
      "Step: 45, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.894055  1.        1.      ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.19250832498073578, Step: 45, Episode: 11\n",
      "====================================\n",
      "Step: 46, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9679067  0.9679067], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.22486554086208344, Step: 46, Episode: 11\n",
      "====================================\n",
      "Step: 47, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9462172  0.9462172], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.5138408541679382, Step: 47, Episode: 11\n",
      "====================================\n",
      "Step: 48, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99908364  1.          1.        ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.21767869591712952, Step: 48, Episode: 11\n",
      "====================================\n",
      "Step: 49, Episode: 11\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91585857  1.          1.        ], Reward: -4.9, Done: False\n",
      "Critic loss: 0.48918619751930237, Step: 49, Episode: 11\n",
      "====================================\n",
      "Step: 0, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9826893  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 0.11002182215452194, Step: 0, Episode: 12\n",
      "====================================\n",
      "Step: 1, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99645543  0.99645543], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.5496295094490051, Step: 1, Episode: 12\n",
      "====================================\n",
      "Step: 2, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95674276  0.95674276], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.18466651439666748, Step: 2, Episode: 12\n",
      "====================================\n",
      "Step: 3, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91782427  0.91782427], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.5431065559387207, Step: 3, Episode: 12\n",
      "====================================\n",
      "Step: 4, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9207644  0.9207644], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.1296360343694687, Step: 4, Episode: 12\n",
      "====================================\n",
      "Step: 5, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97476417  0.97476417], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.4946139454841614, Step: 5, Episode: 12\n",
      "====================================\n",
      "Step: 6, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9830363  1.         1.       ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.08240825682878494, Step: 6, Episode: 12\n",
      "====================================\n",
      "Step: 7, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8999173  0.8999173], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.08251738548278809, Step: 7, Episode: 12\n",
      "====================================\n",
      "Step: 8, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99132836  0.99132836], Reward: -0.8000000000000006, Done: False\n",
      "Critic loss: 0.2633679509162903, Step: 8, Episode: 12\n",
      "====================================\n",
      "Step: 9, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9251542  0.9251542], Reward: -0.9000000000000006, Done: False\n",
      "Critic loss: 0.17092297971248627, Step: 9, Episode: 12\n",
      "====================================\n",
      "Step: 10, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98018336  0.98018336], Reward: -1.0000000000000004, Done: False\n",
      "Critic loss: 0.6283591985702515, Step: 10, Episode: 12\n",
      "====================================\n",
      "Step: 11, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96340233  0.96340233], Reward: -1.1000000000000005, Done: False\n",
      "Critic loss: 0.1374272108078003, Step: 11, Episode: 12\n",
      "====================================\n",
      "Step: 12, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92744315  0.92744315], Reward: -1.2000000000000006, Done: False\n",
      "Critic loss: 0.09261166304349899, Step: 12, Episode: 12\n",
      "====================================\n",
      "Step: 13, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9660141  0.9660141], Reward: -1.3000000000000007, Done: False\n",
      "Critic loss: 0.31633302569389343, Step: 13, Episode: 12\n",
      "====================================\n",
      "Step: 14, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.911937  0.911937], Reward: -1.4000000000000008, Done: False\n",
      "Critic loss: 0.22025810182094574, Step: 14, Episode: 12\n",
      "====================================\n",
      "Step: 15, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.955905  1.        1.      ], Reward: -1.5000000000000009, Done: False\n",
      "Critic loss: 0.4423099160194397, Step: 15, Episode: 12\n",
      "====================================\n",
      "Step: 16, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7631054  0.7631054], Reward: -1.600000000000001, Done: False\n",
      "Critic loss: 0.1665511578321457, Step: 16, Episode: 12\n",
      "====================================\n",
      "Step: 17, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9934452  1.         1.       ], Reward: -1.700000000000001, Done: False\n",
      "Critic loss: 0.4508975148200989, Step: 17, Episode: 12\n",
      "====================================\n",
      "Step: 18, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.88205343  0.88205343], Reward: -1.8000000000000012, Done: False\n",
      "Critic loss: 0.1350785344839096, Step: 18, Episode: 12\n",
      "====================================\n",
      "Step: 19, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99994606  0.99994606], Reward: -1.9000000000000012, Done: False\n",
      "Critic loss: 0.19466492533683777, Step: 19, Episode: 12\n",
      "====================================\n",
      "Step: 20, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98655945  1.          1.        ], Reward: -2.0000000000000013, Done: False\n",
      "Critic loss: 0.4282381236553192, Step: 20, Episode: 12\n",
      "====================================\n",
      "Step: 21, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8480203  1.         1.       ], Reward: -2.1000000000000014, Done: False\n",
      "Critic loss: 0.29283973574638367, Step: 21, Episode: 12\n",
      "====================================\n",
      "Step: 22, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97390026  0.97390026], Reward: -2.2000000000000015, Done: False\n",
      "Critic loss: 0.17929209768772125, Step: 22, Episode: 12\n",
      "====================================\n",
      "Step: 23, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9818898  1.         1.       ], Reward: -2.3000000000000016, Done: False\n",
      "Critic loss: 0.2807929515838623, Step: 23, Episode: 12\n",
      "====================================\n",
      "Step: 24, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8878719  0.8878719], Reward: -2.4000000000000017, Done: False\n",
      "Critic loss: 0.0802573561668396, Step: 24, Episode: 12\n",
      "====================================\n",
      "Step: 25, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8937337  0.8937337], Reward: -2.5000000000000018, Done: False\n",
      "Critic loss: 0.05179513245820999, Step: 25, Episode: 12\n",
      "====================================\n",
      "Step: 26, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9797614  1.         1.       ], Reward: -2.600000000000002, Done: False\n",
      "Critic loss: 0.13477788865566254, Step: 26, Episode: 12\n",
      "====================================\n",
      "Step: 27, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9653247  0.9653247], Reward: -2.700000000000002, Done: False\n",
      "Critic loss: 0.09951116144657135, Step: 27, Episode: 12\n",
      "====================================\n",
      "Step: 28, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94795984  0.94795984], Reward: -2.800000000000002, Done: False\n",
      "Critic loss: 0.07557113468647003, Step: 28, Episode: 12\n",
      "====================================\n",
      "Step: 29, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87997335  1.          1.        ], Reward: -2.900000000000002, Done: False\n",
      "Critic loss: 0.17269527912139893, Step: 29, Episode: 12\n",
      "====================================\n",
      "Step: 30, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.79169023  1.          1.        ], Reward: -3.000000000000002, Done: False\n",
      "Critic loss: 0.182855024933815, Step: 30, Episode: 12\n",
      "====================================\n",
      "Step: 31, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93985176  1.          1.        ], Reward: -3.1000000000000023, Done: False\n",
      "Critic loss: 0.2778373956680298, Step: 31, Episode: 12\n",
      "====================================\n",
      "Step: 32, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8376422  1.         1.       ], Reward: -3.2000000000000024, Done: False\n",
      "Critic loss: 0.15862365067005157, Step: 32, Episode: 12\n",
      "====================================\n",
      "Step: 33, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9673064  1.         1.       ], Reward: -3.3000000000000025, Done: False\n",
      "Critic loss: 0.2660456597805023, Step: 33, Episode: 12\n",
      "====================================\n",
      "Step: 34, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9720371  0.9720371], Reward: -3.4000000000000026, Done: False\n",
      "Critic loss: 0.37213030457496643, Step: 34, Episode: 12\n",
      "====================================\n",
      "Step: 35, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91984767  1.          1.        ], Reward: -3.5000000000000027, Done: False\n",
      "Critic loss: 0.5534189343452454, Step: 35, Episode: 12\n",
      "====================================\n",
      "Step: 36, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8668785  0.8668785], Reward: -3.6000000000000028, Done: False\n",
      "Critic loss: 0.5884612798690796, Step: 36, Episode: 12\n",
      "====================================\n",
      "Step: 37, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9703166  1.         1.       ], Reward: -3.700000000000003, Done: False\n",
      "Critic loss: 0.8788437247276306, Step: 37, Episode: 12\n",
      "====================================\n",
      "Step: 38, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8777937  0.8777937], Reward: -3.8000000000000025, Done: False\n",
      "Critic loss: 0.09124329686164856, Step: 38, Episode: 12\n",
      "====================================\n",
      "Step: 39, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9644221  1.         1.       ], Reward: -3.9000000000000026, Done: False\n",
      "Critic loss: 1.066080927848816, Step: 39, Episode: 12\n",
      "====================================\n",
      "Step: 40, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9447857  1.         1.       ], Reward: -4.000000000000003, Done: False\n",
      "Critic loss: 0.13908866047859192, Step: 40, Episode: 12\n",
      "====================================\n",
      "Step: 41, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9544102  0.9544102], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.683839738368988, Step: 41, Episode: 12\n",
      "====================================\n",
      "Step: 42, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90928066  0.90928066], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.9269117712974548, Step: 42, Episode: 12\n",
      "====================================\n",
      "Step: 43, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8822105  0.8822105], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.46401262283325195, Step: 43, Episode: 12\n",
      "====================================\n",
      "Step: 44, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.73752135  1.          1.        ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 1.0043715238571167, Step: 44, Episode: 12\n",
      "====================================\n",
      "Step: 45, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.81821537  1.          1.        ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.054013121873140335, Step: 45, Episode: 12\n",
      "====================================\n",
      "Step: 46, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90309685  0.90309685], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 1.3023008108139038, Step: 46, Episode: 12\n",
      "====================================\n",
      "Step: 47, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98339486  1.          1.        ], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.6340617537498474, Step: 47, Episode: 12\n",
      "====================================\n",
      "Step: 48, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96476966  1.          1.        ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 1.3802934885025024, Step: 48, Episode: 12\n",
      "====================================\n",
      "Step: 49, Episode: 12\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.80295825  0.80295825], Reward: -4.9, Done: False\n",
      "Critic loss: 1.521735429763794, Step: 49, Episode: 12\n",
      "====================================\n",
      "Step: 0, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9940775  0.9940775], Reward: 0, Done: False\n",
      "Critic loss: 0.34903308749198914, Step: 0, Episode: 13\n",
      "====================================\n",
      "Step: 1, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90354085  1.          1.        ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 2.0629448890686035, Step: 1, Episode: 13\n",
      "====================================\n",
      "Step: 2, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9525117  1.         1.       ], Reward: -0.20000000000000007, Done: False\n",
      "Critic loss: 0.06995352357625961, Step: 2, Episode: 13\n",
      "====================================\n",
      "Step: 3, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99419665  0.99419665], Reward: -0.30000000000000004, Done: False\n",
      "Critic loss: 0.9520139098167419, Step: 3, Episode: 13\n",
      "====================================\n",
      "Step: 4, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9292269  0.9292269], Reward: -0.4, Done: False\n",
      "Critic loss: 1.2530144453048706, Step: 4, Episode: 13\n",
      "====================================\n",
      "Step: 5, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9531452  0.9531452], Reward: -0.5, Done: False\n",
      "Critic loss: 0.6499350666999817, Step: 5, Episode: 13\n",
      "====================================\n",
      "Step: 6, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8168086  1.         1.       ], Reward: -0.6, Done: False\n",
      "Critic loss: 0.8784889578819275, Step: 6, Episode: 13\n",
      "====================================\n",
      "Step: 7, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.818858  1.        1.      ], Reward: -0.7, Done: False\n",
      "Critic loss: 0.047076012939214706, Step: 7, Episode: 13\n",
      "====================================\n",
      "Step: 8, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.879903  1.        1.      ], Reward: -0.7999999999999999, Done: False\n",
      "Critic loss: 0.29343095421791077, Step: 8, Episode: 13\n",
      "====================================\n",
      "Step: 9, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8914937  1.         1.       ], Reward: -0.8999999999999999, Done: False\n",
      "Critic loss: 0.6430034041404724, Step: 9, Episode: 13\n",
      "====================================\n",
      "Step: 10, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91485125  0.91485125], Reward: -0.9999999999999999, Done: False\n",
      "Critic loss: 0.09738892316818237, Step: 10, Episode: 13\n",
      "====================================\n",
      "Step: 11, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9285856  0.9285856], Reward: -1.0999999999999999, Done: False\n",
      "Critic loss: 1.5040355920791626, Step: 11, Episode: 13\n",
      "====================================\n",
      "Step: 12, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95605344  0.95605344], Reward: -1.2, Done: False\n",
      "Critic loss: 0.0750778466463089, Step: 12, Episode: 13\n",
      "====================================\n",
      "Step: 13, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.89426863  1.          1.        ], Reward: -1.3, Done: False\n",
      "Critic loss: 1.750238060951233, Step: 13, Episode: 13\n",
      "====================================\n",
      "Step: 14, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9897555  0.9897555], Reward: -1.4000000000000001, Done: False\n",
      "Critic loss: 0.33528250455856323, Step: 14, Episode: 13\n",
      "====================================\n",
      "Step: 15, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88819164  1.          1.        ], Reward: -1.5000000000000002, Done: False\n",
      "Critic loss: 1.0903148651123047, Step: 15, Episode: 13\n",
      "====================================\n",
      "Step: 16, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84168553  0.84168553], Reward: -1.6, Done: False\n",
      "Critic loss: 0.9155171513557434, Step: 16, Episode: 13\n",
      "====================================\n",
      "Step: 17, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.       0.74464  0.74464], Reward: -1.7000000000000002, Done: False\n",
      "Critic loss: 0.9519668817520142, Step: 17, Episode: 13\n",
      "====================================\n",
      "Step: 18, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.82309633  1.          1.        ], Reward: -1.8000000000000003, Done: False\n",
      "Critic loss: 0.6325103640556335, Step: 18, Episode: 13\n",
      "====================================\n",
      "Step: 19, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93925196  0.93925196], Reward: -1.9000000000000004, Done: False\n",
      "Critic loss: 0.1698913276195526, Step: 19, Episode: 13\n",
      "====================================\n",
      "Step: 20, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90476584  0.90476584], Reward: -2.0000000000000004, Done: False\n",
      "Critic loss: 2.029083728790283, Step: 20, Episode: 13\n",
      "====================================\n",
      "Step: 21, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9155411  0.9155411], Reward: -2.1000000000000005, Done: False\n",
      "Critic loss: 0.20540295541286469, Step: 21, Episode: 13\n",
      "====================================\n",
      "Step: 22, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.92788005  1.          1.        ], Reward: -2.2000000000000006, Done: False\n",
      "Critic loss: 1.3500455617904663, Step: 22, Episode: 13\n",
      "====================================\n",
      "Step: 23, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9208688  1.         1.       ], Reward: -2.3000000000000007, Done: False\n",
      "Critic loss: 1.4341859817504883, Step: 23, Episode: 13\n",
      "====================================\n",
      "Step: 24, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9130318  1.         1.       ], Reward: -2.400000000000001, Done: False\n",
      "Critic loss: 1.6063991785049438, Step: 24, Episode: 13\n",
      "====================================\n",
      "Step: 25, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94466746  1.          1.        ], Reward: -2.500000000000001, Done: False\n",
      "Critic loss: 1.847575068473816, Step: 25, Episode: 13\n",
      "====================================\n",
      "Step: 26, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93684477  1.          1.        ], Reward: -2.600000000000001, Done: False\n",
      "Critic loss: 0.9997502565383911, Step: 26, Episode: 13\n",
      "====================================\n",
      "Step: 27, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9799387  1.         1.       ], Reward: -2.700000000000001, Done: False\n",
      "Critic loss: 1.0102026462554932, Step: 27, Episode: 13\n",
      "====================================\n",
      "Step: 28, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.81275797  0.81275797], Reward: -2.800000000000001, Done: False\n",
      "Critic loss: 0.02606675587594509, Step: 28, Episode: 13\n",
      "====================================\n",
      "Step: 29, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9886352  1.         1.       ], Reward: -2.9000000000000012, Done: False\n",
      "Critic loss: 1.9105520248413086, Step: 29, Episode: 13\n",
      "====================================\n",
      "Step: 30, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9475837  0.9475837], Reward: -3.0000000000000013, Done: False\n",
      "Critic loss: 0.22711634635925293, Step: 30, Episode: 13\n",
      "====================================\n",
      "Step: 31, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98631245  0.98631245], Reward: -3.1000000000000014, Done: False\n",
      "Critic loss: 1.1810979843139648, Step: 31, Episode: 13\n",
      "====================================\n",
      "Step: 32, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93952554  0.93952554], Reward: -3.200000000000001, Done: False\n",
      "Critic loss: 0.5606855750083923, Step: 32, Episode: 13\n",
      "====================================\n",
      "Step: 33, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93129003  1.          1.        ], Reward: -3.300000000000001, Done: False\n",
      "Critic loss: 1.2981923818588257, Step: 33, Episode: 13\n",
      "====================================\n",
      "Step: 34, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98704153  0.98704153], Reward: -3.4000000000000012, Done: False\n",
      "Critic loss: 0.06508851051330566, Step: 34, Episode: 13\n",
      "====================================\n",
      "Step: 35, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91337335  0.91337335], Reward: -3.5000000000000013, Done: False\n",
      "Critic loss: 0.598749577999115, Step: 35, Episode: 13\n",
      "====================================\n",
      "Step: 36, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9488795  0.9488795], Reward: -3.6000000000000014, Done: False\n",
      "Critic loss: 0.06461967527866364, Step: 36, Episode: 13\n",
      "====================================\n",
      "Step: 37, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.89606893  1.          1.        ], Reward: -3.7000000000000015, Done: False\n",
      "Critic loss: 0.565141499042511, Step: 37, Episode: 13\n",
      "====================================\n",
      "Step: 38, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8879488  1.         1.       ], Reward: -3.8000000000000016, Done: False\n",
      "Critic loss: 0.12032719701528549, Step: 38, Episode: 13\n",
      "====================================\n",
      "Step: 39, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8577616  1.         1.       ], Reward: -3.9000000000000017, Done: False\n",
      "Critic loss: 0.16743674874305725, Step: 39, Episode: 13\n",
      "====================================\n",
      "Step: 40, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9357938  0.9357938], Reward: -4.000000000000002, Done: False\n",
      "Critic loss: 0.07661088556051254, Step: 40, Episode: 13\n",
      "====================================\n",
      "Step: 41, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9579619  1.         1.       ], Reward: -4.100000000000001, Done: False\n",
      "Critic loss: 0.10605978965759277, Step: 41, Episode: 13\n",
      "====================================\n",
      "Step: 42, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95523214  0.95523214], Reward: -4.200000000000001, Done: False\n",
      "Critic loss: 0.2874394357204437, Step: 42, Episode: 13\n",
      "====================================\n",
      "Step: 43, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9156156  1.         1.       ], Reward: -4.300000000000001, Done: False\n",
      "Critic loss: 0.18438296020030975, Step: 43, Episode: 13\n",
      "====================================\n",
      "Step: 44, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99312764  1.          1.        ], Reward: -4.4, Done: False\n",
      "Critic loss: 0.21056430041790009, Step: 44, Episode: 13\n",
      "====================================\n",
      "Step: 45, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8568384  0.8568384], Reward: -4.5, Done: False\n",
      "Critic loss: 0.11296023428440094, Step: 45, Episode: 13\n",
      "====================================\n",
      "Step: 46, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8653964  1.         1.       ], Reward: -4.6, Done: False\n",
      "Critic loss: 0.1635277271270752, Step: 46, Episode: 13\n",
      "====================================\n",
      "Step: 47, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99887246  0.99887246], Reward: -4.699999999999999, Done: False\n",
      "Critic loss: 0.11606235802173615, Step: 47, Episode: 13\n",
      "====================================\n",
      "Step: 48, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97332996  1.          1.        ], Reward: -4.799999999999999, Done: False\n",
      "Critic loss: 0.2593826949596405, Step: 48, Episode: 13\n",
      "====================================\n",
      "Step: 49, Episode: 13\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97983813  1.          1.        ], Reward: -4.899999999999999, Done: False\n",
      "Critic loss: 0.13687628507614136, Step: 49, Episode: 13\n",
      "====================================\n",
      "Step: 0, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9126518  0.9126518], Reward: 0, Done: False\n",
      "Critic loss: 0.06637322157621384, Step: 0, Episode: 14\n",
      "====================================\n",
      "Step: 1, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9582092  0.9582092], Reward: -0.09999999999999998, Done: False\n",
      "Critic loss: 0.0598234198987484, Step: 1, Episode: 14\n",
      "====================================\n",
      "Step: 2, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7986558  0.7986558], Reward: -0.19999999999999996, Done: False\n",
      "Critic loss: 0.04634004831314087, Step: 2, Episode: 14\n",
      "====================================\n",
      "Step: 3, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86203074  0.86203074], Reward: -0.29999999999999993, Done: False\n",
      "Critic loss: 0.013908162713050842, Step: 3, Episode: 14\n",
      "====================================\n",
      "Step: 4, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7853755  0.7853755], Reward: -0.3999999999999999, Done: False\n",
      "Critic loss: 0.07826069742441177, Step: 4, Episode: 14\n",
      "====================================\n",
      "Step: 5, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96512043  1.          1.        ], Reward: -0.4999999999999999, Done: False\n",
      "Critic loss: 0.16345356404781342, Step: 5, Episode: 14\n",
      "====================================\n",
      "Step: 6, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9841887  1.         1.       ], Reward: -0.5999999999999999, Done: False\n",
      "Critic loss: 0.07173660397529602, Step: 6, Episode: 14\n",
      "====================================\n",
      "Step: 7, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8550974  0.8550974], Reward: -0.6999999999999998, Done: False\n",
      "Critic loss: 0.15688513219356537, Step: 7, Episode: 14\n",
      "====================================\n",
      "Step: 8, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93562055  0.93562055], Reward: -0.7999999999999998, Done: False\n",
      "Critic loss: 0.09906458854675293, Step: 8, Episode: 14\n",
      "====================================\n",
      "Step: 9, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9356654  0.9356654], Reward: -0.8999999999999998, Done: False\n",
      "Critic loss: 0.061491310596466064, Step: 9, Episode: 14\n",
      "====================================\n",
      "Step: 10, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8453147  0.8453147], Reward: -0.9999999999999998, Done: False\n",
      "Critic loss: 0.09057322144508362, Step: 10, Episode: 14\n",
      "====================================\n",
      "Step: 11, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8594136  0.8594136], Reward: -1.0999999999999999, Done: False\n",
      "Critic loss: 0.09903668612241745, Step: 11, Episode: 14\n",
      "====================================\n",
      "Step: 12, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97228646  0.97228646], Reward: -1.2, Done: False\n",
      "Critic loss: 0.1084505096077919, Step: 12, Episode: 14\n",
      "====================================\n",
      "Step: 13, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96509683  1.          1.        ], Reward: -1.3, Done: False\n",
      "Critic loss: 0.09777247160673141, Step: 13, Episode: 14\n",
      "====================================\n",
      "Step: 14, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.970447  1.        1.      ], Reward: -1.4000000000000001, Done: False\n",
      "Critic loss: 0.12163646519184113, Step: 14, Episode: 14\n",
      "====================================\n",
      "Step: 15, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97124696  0.97124696], Reward: -1.5, Done: False\n",
      "Critic loss: 0.2418476641178131, Step: 15, Episode: 14\n",
      "====================================\n",
      "Step: 16, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9618154  1.         1.       ], Reward: -1.6, Done: False\n",
      "Critic loss: 0.10938318073749542, Step: 16, Episode: 14\n",
      "====================================\n",
      "Step: 17, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93225455  1.          1.        ], Reward: -1.7000000000000002, Done: False\n",
      "Critic loss: 0.08453577756881714, Step: 17, Episode: 14\n",
      "====================================\n",
      "Step: 18, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9730004  1.         1.       ], Reward: -1.8000000000000003, Done: False\n",
      "Critic loss: 0.1025853157043457, Step: 18, Episode: 14\n",
      "====================================\n",
      "Step: 19, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.83753717  0.83753717], Reward: -1.9000000000000004, Done: False\n",
      "Critic loss: 0.09464086592197418, Step: 19, Episode: 14\n",
      "====================================\n",
      "Step: 20, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.89072734  0.89072734], Reward: -2.0000000000000004, Done: False\n",
      "Critic loss: 0.05798361450433731, Step: 20, Episode: 14\n",
      "====================================\n",
      "Step: 21, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9051656  1.         1.       ], Reward: -2.1000000000000005, Done: False\n",
      "Critic loss: 0.1272628754377365, Step: 21, Episode: 14\n",
      "====================================\n",
      "Step: 22, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9674384  1.         1.       ], Reward: -2.2000000000000006, Done: False\n",
      "Critic loss: 0.09172230958938599, Step: 22, Episode: 14\n",
      "====================================\n",
      "Step: 23, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.83897424  1.          1.        ], Reward: -2.3000000000000007, Done: False\n",
      "Critic loss: 0.13489042222499847, Step: 23, Episode: 14\n",
      "====================================\n",
      "Step: 24, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8903909  0.8903909], Reward: -2.400000000000001, Done: False\n",
      "Critic loss: 0.1533219814300537, Step: 24, Episode: 14\n",
      "====================================\n",
      "Step: 25, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98391974  0.98391974], Reward: -2.500000000000001, Done: False\n",
      "Critic loss: 0.10872431844472885, Step: 25, Episode: 14\n",
      "====================================\n",
      "Step: 26, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88397914  1.          1.        ], Reward: -2.600000000000001, Done: False\n",
      "Critic loss: 0.09382462501525879, Step: 26, Episode: 14\n",
      "====================================\n",
      "Step: 27, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9082714  0.9082714], Reward: -2.700000000000001, Done: False\n",
      "Critic loss: 0.06962303072214127, Step: 27, Episode: 14\n",
      "====================================\n",
      "Step: 28, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98433137  0.98433137], Reward: -2.800000000000001, Done: False\n",
      "Critic loss: 0.3737339675426483, Step: 28, Episode: 14\n",
      "====================================\n",
      "Step: 29, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9742886  0.9742886], Reward: -2.9000000000000012, Done: False\n",
      "Critic loss: 0.05582408979535103, Step: 29, Episode: 14\n",
      "====================================\n",
      "Step: 30, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9083636  1.         1.       ], Reward: -3.0000000000000013, Done: False\n",
      "Critic loss: 0.09061487764120102, Step: 30, Episode: 14\n",
      "====================================\n",
      "Step: 31, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.92459327  1.          1.        ], Reward: -3.1000000000000014, Done: False\n",
      "Critic loss: 0.2070261538028717, Step: 31, Episode: 14\n",
      "====================================\n",
      "Step: 32, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95572895  1.          1.        ], Reward: -3.2000000000000015, Done: False\n",
      "Critic loss: 0.016987895593047142, Step: 32, Episode: 14\n",
      "====================================\n",
      "Step: 33, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9362422  0.9362422], Reward: -3.3000000000000016, Done: False\n",
      "Critic loss: 0.0803937092423439, Step: 33, Episode: 14\n",
      "====================================\n",
      "Step: 34, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9831956  1.         1.       ], Reward: -3.4000000000000017, Done: False\n",
      "Critic loss: 0.06959559768438339, Step: 34, Episode: 14\n",
      "====================================\n",
      "Step: 35, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8951112  0.8951112], Reward: -3.5000000000000018, Done: False\n",
      "Critic loss: 0.22343948483467102, Step: 35, Episode: 14\n",
      "====================================\n",
      "Step: 36, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9739344  1.         1.       ], Reward: -3.600000000000002, Done: False\n",
      "Critic loss: 0.13798896968364716, Step: 36, Episode: 14\n",
      "====================================\n",
      "Step: 37, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96001524  1.          1.        ], Reward: -3.700000000000002, Done: False\n",
      "Critic loss: 0.11286143213510513, Step: 37, Episode: 14\n",
      "====================================\n",
      "Step: 38, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9485917  1.         1.       ], Reward: -3.800000000000002, Done: False\n",
      "Critic loss: 0.16239212453365326, Step: 38, Episode: 14\n",
      "====================================\n",
      "Step: 39, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9966546  1.         1.       ], Reward: -3.900000000000002, Done: False\n",
      "Critic loss: 0.16680192947387695, Step: 39, Episode: 14\n",
      "====================================\n",
      "Step: 40, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90087205  0.90087205], Reward: -4.000000000000002, Done: False\n",
      "Critic loss: 0.11477656662464142, Step: 40, Episode: 14\n",
      "====================================\n",
      "Step: 41, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8101367  0.8101367], Reward: -4.100000000000001, Done: False\n",
      "Critic loss: 0.08053328841924667, Step: 41, Episode: 14\n",
      "====================================\n",
      "Step: 42, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.88949585  0.88949585], Reward: -4.200000000000001, Done: False\n",
      "Critic loss: 0.2818926274776459, Step: 42, Episode: 14\n",
      "====================================\n",
      "Step: 43, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9306749  1.         1.       ], Reward: -4.300000000000001, Done: False\n",
      "Critic loss: 0.09606324881315231, Step: 43, Episode: 14\n",
      "====================================\n",
      "Step: 44, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8571143  1.         1.       ], Reward: -4.4, Done: False\n",
      "Critic loss: 0.20179907977581024, Step: 44, Episode: 14\n",
      "====================================\n",
      "Step: 45, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9489615  0.9489615], Reward: -4.5, Done: False\n",
      "Critic loss: 0.12736700475215912, Step: 45, Episode: 14\n",
      "====================================\n",
      "Step: 46, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.79197574  0.79197574], Reward: -4.6, Done: False\n",
      "Critic loss: 0.19698886573314667, Step: 46, Episode: 14\n",
      "====================================\n",
      "Step: 47, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9348112  0.9348112], Reward: -4.699999999999999, Done: False\n",
      "Critic loss: 0.26292163133621216, Step: 47, Episode: 14\n",
      "====================================\n",
      "Step: 48, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8413862  1.         1.       ], Reward: -4.799999999999999, Done: False\n",
      "Critic loss: 0.22912172973155975, Step: 48, Episode: 14\n",
      "====================================\n",
      "Step: 49, Episode: 14\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9923723  0.9923723], Reward: -4.899999999999999, Done: False\n",
      "Critic loss: 0.032046642154455185, Step: 49, Episode: 14\n",
      "====================================\n",
      "Step: 0, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8990132  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 0.09338699281215668, Step: 0, Episode: 15\n",
      "====================================\n",
      "Step: 1, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9583653  0.9583653], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.4165366291999817, Step: 1, Episode: 15\n",
      "====================================\n",
      "Step: 2, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99363947  0.99363947], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.09264756739139557, Step: 2, Episode: 15\n",
      "====================================\n",
      "Step: 3, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9535832  0.9535832], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.9149934649467468, Step: 3, Episode: 15\n",
      "====================================\n",
      "Step: 4, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9483297  0.9483297], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.14092236757278442, Step: 4, Episode: 15\n",
      "====================================\n",
      "Step: 5, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9821464  1.         1.       ], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.4663577079772949, Step: 5, Episode: 15\n",
      "====================================\n",
      "Step: 6, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93537503  0.93537503], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.0709558054804802, Step: 6, Episode: 15\n",
      "====================================\n",
      "Step: 7, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8536034  1.         1.       ], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 1.081525444984436, Step: 7, Episode: 15\n",
      "====================================\n",
      "Step: 8, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9872413  0.9872413], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.0600631944835186, Step: 8, Episode: 15\n",
      "====================================\n",
      "Step: 9, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8952668  0.8952668], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 1.449530839920044, Step: 9, Episode: 15\n",
      "====================================\n",
      "Step: 10, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8614734  0.8614734], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.016582340002059937, Step: 10, Episode: 15\n",
      "====================================\n",
      "Step: 11, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.92826205  1.          1.        ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 1.5544157028198242, Step: 11, Episode: 15\n",
      "====================================\n",
      "Step: 12, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96212375  0.96212375], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.06719744950532913, Step: 12, Episode: 15\n",
      "====================================\n",
      "Step: 13, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7692231  0.7692231], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.8146129846572876, Step: 13, Episode: 15\n",
      "====================================\n",
      "Step: 14, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8996703  1.         1.       ], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.18105457723140717, Step: 14, Episode: 15\n",
      "====================================\n",
      "Step: 15, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9468083  0.9468083], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 0.35118189454078674, Step: 15, Episode: 15\n",
      "====================================\n",
      "Step: 16, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87891716  0.87891716], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.03468935564160347, Step: 16, Episode: 15\n",
      "====================================\n",
      "Step: 17, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9129406  0.9129406], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.2171076536178589, Step: 17, Episode: 15\n",
      "====================================\n",
      "Step: 18, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.82221156  0.82221156], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.18545885384082794, Step: 18, Episode: 15\n",
      "====================================\n",
      "Step: 19, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97739524  0.97739524], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.3353559076786041, Step: 19, Episode: 15\n",
      "====================================\n",
      "Step: 20, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8837195  1.         1.       ], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.057820577174425125, Step: 20, Episode: 15\n",
      "====================================\n",
      "Step: 21, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99957204  0.99957204], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.18327537178993225, Step: 21, Episode: 15\n",
      "====================================\n",
      "Step: 22, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9661091  1.         1.       ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.14345155656337738, Step: 22, Episode: 15\n",
      "====================================\n",
      "Step: 23, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8866151  1.         1.       ], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.13469073176383972, Step: 23, Episode: 15\n",
      "====================================\n",
      "Step: 24, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9478657  1.         1.       ], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.08002780377864838, Step: 24, Episode: 15\n",
      "====================================\n",
      "Step: 25, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97437257  1.          1.        ], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.2171921283006668, Step: 25, Episode: 15\n",
      "====================================\n",
      "Step: 26, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9295503  0.9295503], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.20111656188964844, Step: 26, Episode: 15\n",
      "====================================\n",
      "Step: 27, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98478323  0.98478323], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.01839609444141388, Step: 27, Episode: 15\n",
      "====================================\n",
      "Step: 28, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8654722  0.8654722], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.21597209572792053, Step: 28, Episode: 15\n",
      "====================================\n",
      "Step: 29, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.880157  1.        1.      ], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.1221596747636795, Step: 29, Episode: 15\n",
      "====================================\n",
      "Step: 30, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94291025  0.94291025], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.26122936606407166, Step: 30, Episode: 15\n",
      "====================================\n",
      "Step: 31, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9589902  0.9589902], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.48820921778678894, Step: 31, Episode: 15\n",
      "====================================\n",
      "Step: 32, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9999059  1.         1.       ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.5593217611312866, Step: 32, Episode: 15\n",
      "====================================\n",
      "Step: 33, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9886819  0.9886819], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.24734632670879364, Step: 33, Episode: 15\n",
      "====================================\n",
      "Step: 34, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9411853  0.9411853], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.3650360703468323, Step: 34, Episode: 15\n",
      "====================================\n",
      "Step: 35, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87581587  1.          1.        ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.017171207815408707, Step: 35, Episode: 15\n",
      "====================================\n",
      "Step: 36, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96305275  0.96305275], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.12857244908809662, Step: 36, Episode: 15\n",
      "====================================\n",
      "Step: 37, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98912597  0.98912597], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.1188727617263794, Step: 37, Episode: 15\n",
      "====================================\n",
      "Step: 38, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9889457  0.9889457], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.35971829295158386, Step: 38, Episode: 15\n",
      "====================================\n",
      "Step: 39, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.83474094  1.          1.        ], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.12276754528284073, Step: 39, Episode: 15\n",
      "====================================\n",
      "Step: 40, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9128543  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.3533637225627899, Step: 40, Episode: 15\n",
      "====================================\n",
      "Step: 41, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94244236  1.          1.        ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.061632025986909866, Step: 41, Episode: 15\n",
      "====================================\n",
      "Step: 42, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9444772  1.         1.       ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.04950067400932312, Step: 42, Episode: 15\n",
      "====================================\n",
      "Step: 43, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87124884  0.87124884], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.1009426862001419, Step: 43, Episode: 15\n",
      "====================================\n",
      "Step: 44, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.80913204  0.80913204], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.14746204018592834, Step: 44, Episode: 15\n",
      "====================================\n",
      "Step: 45, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8319415  1.         1.       ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.4115242063999176, Step: 45, Episode: 15\n",
      "====================================\n",
      "Step: 46, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9563802  1.         1.       ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.6405920386314392, Step: 46, Episode: 15\n",
      "====================================\n",
      "Step: 47, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9201455  0.9201455], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.5933399200439453, Step: 47, Episode: 15\n",
      "====================================\n",
      "Step: 48, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9973578  1.         1.       ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.6914066672325134, Step: 48, Episode: 15\n",
      "====================================\n",
      "Step: 49, Episode: 15\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90193856  1.          1.        ], Reward: -4.9, Done: False\n",
      "Critic loss: 1.1934118270874023, Step: 49, Episode: 15\n",
      "====================================\n",
      "Step: 0, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9530317  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 1.014676570892334, Step: 0, Episode: 16\n",
      "====================================\n",
      "Step: 1, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86165845  0.86165845], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 1.0526961088180542, Step: 1, Episode: 16\n",
      "====================================\n",
      "Step: 2, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8865008  0.8865008], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.3224799335002899, Step: 2, Episode: 16\n",
      "====================================\n",
      "Step: 3, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8261658  0.8261658], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 1.792816162109375, Step: 3, Episode: 16\n",
      "====================================\n",
      "Step: 4, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9789991  0.9789991], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.07850822061300278, Step: 4, Episode: 16\n",
      "====================================\n",
      "Step: 5, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8456334  1.         1.       ], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 2.075735569000244, Step: 5, Episode: 16\n",
      "====================================\n",
      "Step: 6, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9190588  1.         1.       ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.11088371276855469, Step: 6, Episode: 16\n",
      "====================================\n",
      "Step: 7, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.836674  0.836674], Reward: -0.7000000000000005, Done: False\n",
      "Critic loss: 1.1478614807128906, Step: 7, Episode: 16\n",
      "====================================\n",
      "Step: 8, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8786782  1.         1.       ], Reward: -0.8000000000000005, Done: False\n",
      "Critic loss: 0.44087082147598267, Step: 8, Episode: 16\n",
      "====================================\n",
      "Step: 9, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99062157  1.          1.        ], Reward: -0.9000000000000005, Done: False\n",
      "Critic loss: 1.5036379098892212, Step: 9, Episode: 16\n",
      "====================================\n",
      "Step: 10, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9429479  1.         1.       ], Reward: -1.0000000000000004, Done: False\n",
      "Critic loss: 0.3754986524581909, Step: 10, Episode: 16\n",
      "====================================\n",
      "Step: 11, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9645053  0.9645053], Reward: -1.1000000000000005, Done: False\n",
      "Critic loss: 0.5914525985717773, Step: 11, Episode: 16\n",
      "====================================\n",
      "Step: 12, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84961337  0.84961337], Reward: -1.2000000000000006, Done: False\n",
      "Critic loss: 0.6780280470848083, Step: 12, Episode: 16\n",
      "====================================\n",
      "Step: 13, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9486523  1.         1.       ], Reward: -1.3000000000000007, Done: False\n",
      "Critic loss: 0.21451091766357422, Step: 13, Episode: 16\n",
      "====================================\n",
      "Step: 14, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9891686  0.9891686], Reward: -1.4000000000000008, Done: False\n",
      "Critic loss: 1.113463044166565, Step: 14, Episode: 16\n",
      "====================================\n",
      "Step: 15, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94334257  1.          1.        ], Reward: -1.5000000000000009, Done: False\n",
      "Critic loss: 0.41554880142211914, Step: 15, Episode: 16\n",
      "====================================\n",
      "Step: 16, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9030989  0.9030989], Reward: -1.600000000000001, Done: False\n",
      "Critic loss: 0.7505324482917786, Step: 16, Episode: 16\n",
      "====================================\n",
      "Step: 17, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9960799  0.9960799], Reward: -1.700000000000001, Done: False\n",
      "Critic loss: 0.26269039511680603, Step: 17, Episode: 16\n",
      "====================================\n",
      "Step: 18, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90726197  0.90726197], Reward: -1.8000000000000012, Done: False\n",
      "Critic loss: 0.6812228560447693, Step: 18, Episode: 16\n",
      "====================================\n",
      "Step: 19, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9021205  1.         1.       ], Reward: -1.9000000000000012, Done: False\n",
      "Critic loss: 0.18653109669685364, Step: 19, Episode: 16\n",
      "====================================\n",
      "Step: 20, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91098976  0.91098976], Reward: -2.0000000000000013, Done: False\n",
      "Critic loss: 0.6003119945526123, Step: 20, Episode: 16\n",
      "====================================\n",
      "Step: 21, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99604523  0.99604523], Reward: -2.1000000000000014, Done: False\n",
      "Critic loss: 0.12969224154949188, Step: 21, Episode: 16\n",
      "====================================\n",
      "Step: 22, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8986056  1.         1.       ], Reward: -2.2000000000000015, Done: False\n",
      "Critic loss: 0.13570789992809296, Step: 22, Episode: 16\n",
      "====================================\n",
      "Step: 23, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9963218  1.         1.       ], Reward: -2.3000000000000016, Done: False\n",
      "Critic loss: 0.04292035475373268, Step: 23, Episode: 16\n",
      "====================================\n",
      "Step: 24, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9662179  1.         1.       ], Reward: -2.4000000000000017, Done: False\n",
      "Critic loss: 0.30825814604759216, Step: 24, Episode: 16\n",
      "====================================\n",
      "Step: 25, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9394603  1.         1.       ], Reward: -2.5000000000000018, Done: False\n",
      "Critic loss: 0.0816071555018425, Step: 25, Episode: 16\n",
      "====================================\n",
      "Step: 26, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9227871  1.         1.       ], Reward: -2.600000000000002, Done: False\n",
      "Critic loss: 0.17548775672912598, Step: 26, Episode: 16\n",
      "====================================\n",
      "Step: 27, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9759266  1.         1.       ], Reward: -2.700000000000002, Done: False\n",
      "Critic loss: 0.37882891297340393, Step: 27, Episode: 16\n",
      "====================================\n",
      "Step: 28, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.80049384  1.          1.        ], Reward: -2.800000000000002, Done: False\n",
      "Critic loss: 0.14554762840270996, Step: 28, Episode: 16\n",
      "====================================\n",
      "Step: 29, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9401412  0.9401412], Reward: -2.900000000000002, Done: False\n",
      "Critic loss: 0.7619181871414185, Step: 29, Episode: 16\n",
      "====================================\n",
      "Step: 30, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.78907835  1.          1.        ], Reward: -3.000000000000002, Done: False\n",
      "Critic loss: 0.2271571159362793, Step: 30, Episode: 16\n",
      "====================================\n",
      "Step: 31, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8909402  0.8909402], Reward: -3.1000000000000023, Done: False\n",
      "Critic loss: 0.5066381096839905, Step: 31, Episode: 16\n",
      "====================================\n",
      "Step: 32, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9488409  1.         1.       ], Reward: -3.2000000000000024, Done: False\n",
      "Critic loss: 0.08497116714715958, Step: 32, Episode: 16\n",
      "====================================\n",
      "Step: 33, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85041803  0.85041803], Reward: -3.3000000000000025, Done: False\n",
      "Critic loss: 0.5502822995185852, Step: 33, Episode: 16\n",
      "====================================\n",
      "Step: 34, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.890443  0.890443], Reward: -3.4000000000000026, Done: False\n",
      "Critic loss: 0.3000931441783905, Step: 34, Episode: 16\n",
      "====================================\n",
      "Step: 35, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91918224  0.91918224], Reward: -3.5000000000000027, Done: False\n",
      "Critic loss: 0.7490841746330261, Step: 35, Episode: 16\n",
      "====================================\n",
      "Step: 36, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.6888398  0.6888398], Reward: -3.6000000000000028, Done: False\n",
      "Critic loss: 0.44230642914772034, Step: 36, Episode: 16\n",
      "====================================\n",
      "Step: 37, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8250367  0.8250367], Reward: -3.700000000000003, Done: False\n",
      "Critic loss: 0.8124224543571472, Step: 37, Episode: 16\n",
      "====================================\n",
      "Step: 38, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8976642  0.8976642], Reward: -3.800000000000003, Done: False\n",
      "Critic loss: 0.8465937972068787, Step: 38, Episode: 16\n",
      "====================================\n",
      "Step: 39, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9281877  1.         1.       ], Reward: -3.900000000000003, Done: False\n",
      "Critic loss: 0.47855639457702637, Step: 39, Episode: 16\n",
      "====================================\n",
      "Step: 40, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9885065  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 1.5553158521652222, Step: 40, Episode: 16\n",
      "====================================\n",
      "Step: 41, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9966605  1.         1.       ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.7244243621826172, Step: 41, Episode: 16\n",
      "====================================\n",
      "Step: 42, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.931787  1.        1.      ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.8373861312866211, Step: 42, Episode: 16\n",
      "====================================\n",
      "Step: 43, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9366836  0.9366836], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.19411413371562958, Step: 43, Episode: 16\n",
      "====================================\n",
      "Step: 44, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9217522  0.9217522], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 2.226583957672119, Step: 44, Episode: 16\n",
      "====================================\n",
      "Step: 45, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9828294  1.         1.       ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.2481234073638916, Step: 45, Episode: 16\n",
      "====================================\n",
      "Step: 46, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9934915  1.         1.       ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 1.0701532363891602, Step: 46, Episode: 16\n",
      "====================================\n",
      "Step: 47, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9972059  0.9972059], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.08743148297071457, Step: 47, Episode: 16\n",
      "====================================\n",
      "Step: 48, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8883722  1.         1.       ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 1.5640376806259155, Step: 48, Episode: 16\n",
      "====================================\n",
      "Step: 49, Episode: 16\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95001245  1.          1.        ], Reward: -4.9, Done: False\n",
      "Critic loss: 0.0541972815990448, Step: 49, Episode: 16\n",
      "====================================\n",
      "Step: 0, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99101526  0.99101526], Reward: 0, Done: False\n",
      "Critic loss: 0.8613008856773376, Step: 0, Episode: 17\n",
      "====================================\n",
      "Step: 1, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.978403  1.        1.      ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.08443925529718399, Step: 1, Episode: 17\n",
      "====================================\n",
      "Step: 2, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9221995  1.         1.       ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.5058293342590332, Step: 2, Episode: 17\n",
      "====================================\n",
      "Step: 3, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9413851  1.         1.       ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.22180652618408203, Step: 3, Episode: 17\n",
      "====================================\n",
      "Step: 4, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8571178  1.         1.       ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.38317131996154785, Step: 4, Episode: 17\n",
      "====================================\n",
      "Step: 5, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91987044  1.          1.        ], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.17447210848331451, Step: 5, Episode: 17\n",
      "====================================\n",
      "Step: 6, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91778076  0.91778076], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.12081052362918854, Step: 6, Episode: 17\n",
      "====================================\n",
      "Step: 7, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8853826  0.8853826], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.27121368050575256, Step: 7, Episode: 17\n",
      "====================================\n",
      "Step: 8, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9768673  1.         1.       ], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.05412202700972557, Step: 8, Episode: 17\n",
      "====================================\n",
      "Step: 9, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9994503  0.9994503], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.534498393535614, Step: 9, Episode: 17\n",
      "====================================\n",
      "Step: 10, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9401068  0.9401068], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.17564290761947632, Step: 10, Episode: 17\n",
      "====================================\n",
      "Step: 11, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9306569  0.9306569], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.9997802972793579, Step: 11, Episode: 17\n",
      "====================================\n",
      "Step: 12, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.79556465  1.          1.        ], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.024030154570937157, Step: 12, Episode: 17\n",
      "====================================\n",
      "Step: 13, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9803996  0.9803996], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.5762635469436646, Step: 13, Episode: 17\n",
      "====================================\n",
      "Step: 14, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97397965  0.97397965], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.2612978518009186, Step: 14, Episode: 17\n",
      "====================================\n",
      "Step: 15, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8327668  0.8327668], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 1.275649070739746, Step: 15, Episode: 17\n",
      "====================================\n",
      "Step: 16, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9705378  1.         1.       ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.04683433845639229, Step: 16, Episode: 17\n",
      "====================================\n",
      "Step: 17, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9804672  1.         1.       ], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.8907249569892883, Step: 17, Episode: 17\n",
      "====================================\n",
      "Step: 18, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8501086  1.         1.       ], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.09078249335289001, Step: 18, Episode: 17\n",
      "====================================\n",
      "Step: 19, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.897225  0.897225], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.49520179629325867, Step: 19, Episode: 17\n",
      "====================================\n",
      "Step: 20, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9304013  1.         1.       ], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.23196887969970703, Step: 20, Episode: 17\n",
      "====================================\n",
      "Step: 21, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9000668  1.         1.       ], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 1.2646167278289795, Step: 21, Episode: 17\n",
      "====================================\n",
      "Step: 22, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85504234  0.85504234], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.0336545966565609, Step: 22, Episode: 17\n",
      "====================================\n",
      "Step: 23, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9868997  0.9868997], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.1531277447938919, Step: 23, Episode: 17\n",
      "====================================\n",
      "Step: 24, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90832037  1.          1.        ], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.1876562088727951, Step: 24, Episode: 17\n",
      "====================================\n",
      "Step: 25, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91267085  0.91267085], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.18178556859493256, Step: 25, Episode: 17\n",
      "====================================\n",
      "Step: 26, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9653164  0.9653164], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.09321138262748718, Step: 26, Episode: 17\n",
      "====================================\n",
      "Step: 27, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97019607  1.          1.        ], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.02142554149031639, Step: 27, Episode: 17\n",
      "====================================\n",
      "Step: 28, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9011922  0.9011922], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.26531606912612915, Step: 28, Episode: 17\n",
      "====================================\n",
      "Step: 29, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.81027365  1.          1.        ], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.2699697017669678, Step: 29, Episode: 17\n",
      "====================================\n",
      "Step: 30, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9775985  0.9775985], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.08156229555606842, Step: 30, Episode: 17\n",
      "====================================\n",
      "Step: 31, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9982389  1.         1.       ], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.056701816618442535, Step: 31, Episode: 17\n",
      "====================================\n",
      "Step: 32, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9172678  0.9172678], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.07412119954824448, Step: 32, Episode: 17\n",
      "====================================\n",
      "Step: 33, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9546319  0.9546319], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.07663023471832275, Step: 33, Episode: 17\n",
      "====================================\n",
      "Step: 34, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9630233  0.9630233], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.18521125614643097, Step: 34, Episode: 17\n",
      "====================================\n",
      "Step: 35, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.82696706  1.          1.        ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.03717624023556709, Step: 35, Episode: 17\n",
      "====================================\n",
      "Step: 36, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8254713  1.         1.       ], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.11203043907880783, Step: 36, Episode: 17\n",
      "====================================\n",
      "Step: 37, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7995138  1.         1.       ], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.2533333897590637, Step: 37, Episode: 17\n",
      "====================================\n",
      "Step: 38, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9973996  1.         1.       ], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.6308539509773254, Step: 38, Episode: 17\n",
      "====================================\n",
      "Step: 39, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9687418  0.9687418], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.0807652398943901, Step: 39, Episode: 17\n",
      "====================================\n",
      "Step: 40, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.6888112  0.6888112], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.2948760688304901, Step: 40, Episode: 17\n",
      "====================================\n",
      "Step: 41, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95236415  0.95236415], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.21695928275585175, Step: 41, Episode: 17\n",
      "====================================\n",
      "Step: 42, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9386102  1.         1.       ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.1597222089767456, Step: 42, Episode: 17\n",
      "====================================\n",
      "Step: 43, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8814305  0.8814305], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.09524742513895035, Step: 43, Episode: 17\n",
      "====================================\n",
      "Step: 44, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87748903  1.          1.        ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.1797783225774765, Step: 44, Episode: 17\n",
      "====================================\n",
      "Step: 45, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85495305  0.85495305], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.40385887026786804, Step: 45, Episode: 17\n",
      "====================================\n",
      "Step: 46, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9182043  1.         1.       ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.03676861897110939, Step: 46, Episode: 17\n",
      "====================================\n",
      "Step: 47, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8128575  1.         1.       ], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.11619037389755249, Step: 47, Episode: 17\n",
      "====================================\n",
      "Step: 48, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8734759  0.8734759], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.055908866226673126, Step: 48, Episode: 17\n",
      "====================================\n",
      "Step: 49, Episode: 17\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9230568  1.         1.       ], Reward: -4.9, Done: False\n",
      "Critic loss: 0.23025541007518768, Step: 49, Episode: 17\n",
      "====================================\n",
      "Step: 0, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9504821  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 0.01538203377276659, Step: 0, Episode: 18\n",
      "====================================\n",
      "Step: 1, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.89122725  0.89122725], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.25065624713897705, Step: 1, Episode: 18\n",
      "====================================\n",
      "Step: 2, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8823294  0.8823294], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.14071694016456604, Step: 2, Episode: 18\n",
      "====================================\n",
      "Step: 3, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9742853  0.9742853], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.4412917196750641, Step: 3, Episode: 18\n",
      "====================================\n",
      "Step: 4, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8992769  0.8992769], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.26271966099739075, Step: 4, Episode: 18\n",
      "====================================\n",
      "Step: 5, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9893314  0.9893314], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.6375728845596313, Step: 5, Episode: 18\n",
      "====================================\n",
      "Step: 6, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.929625  1.        1.      ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.2386648952960968, Step: 6, Episode: 18\n",
      "====================================\n",
      "Step: 7, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8756925  0.8756925], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.8694619536399841, Step: 7, Episode: 18\n",
      "====================================\n",
      "Step: 8, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96057117  0.96057117], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.15754029154777527, Step: 8, Episode: 18\n",
      "====================================\n",
      "Step: 9, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8765356  0.8765356], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.722298264503479, Step: 9, Episode: 18\n",
      "====================================\n",
      "Step: 10, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90139425  0.90139425], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.0893782451748848, Step: 10, Episode: 18\n",
      "====================================\n",
      "Step: 11, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.949506  1.        1.      ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 1.1791231632232666, Step: 11, Episode: 18\n",
      "====================================\n",
      "Step: 12, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9747771  1.         1.       ], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.1557193547487259, Step: 12, Episode: 18\n",
      "====================================\n",
      "Step: 13, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9071748  0.9071748], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.459010511636734, Step: 13, Episode: 18\n",
      "====================================\n",
      "Step: 14, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9033141  1.         1.       ], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.1261064112186432, Step: 14, Episode: 18\n",
      "====================================\n",
      "Step: 15, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9374685  1.         1.       ], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 0.9320971369743347, Step: 15, Episode: 18\n",
      "====================================\n",
      "Step: 16, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99570876  1.          1.        ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.11698124557733536, Step: 16, Episode: 18\n",
      "====================================\n",
      "Step: 17, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97411823  1.          1.        ], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.04544178768992424, Step: 17, Episode: 18\n",
      "====================================\n",
      "Step: 18, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86878085  0.86878085], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.13742564618587494, Step: 18, Episode: 18\n",
      "====================================\n",
      "Step: 19, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99939424  0.99939424], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.08002740144729614, Step: 19, Episode: 18\n",
      "====================================\n",
      "Step: 20, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8935348  1.         1.       ], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.2306707352399826, Step: 20, Episode: 18\n",
      "====================================\n",
      "Step: 21, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9413557  0.9413557], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.23866167664527893, Step: 21, Episode: 18\n",
      "====================================\n",
      "Step: 22, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87935966  0.87935966], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.16816134750843048, Step: 22, Episode: 18\n",
      "====================================\n",
      "Step: 23, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9790852  1.         1.       ], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.016673851758241653, Step: 23, Episode: 18\n",
      "====================================\n",
      "Step: 24, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87137264  0.87137264], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.22378754615783691, Step: 24, Episode: 18\n",
      "====================================\n",
      "Step: 25, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9555421  1.         1.       ], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.03066927008330822, Step: 25, Episode: 18\n",
      "====================================\n",
      "Step: 26, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9206018  0.9206018], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.30928435921669006, Step: 26, Episode: 18\n",
      "====================================\n",
      "Step: 27, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.77548105  1.          1.        ], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.058537423610687256, Step: 27, Episode: 18\n",
      "====================================\n",
      "Step: 28, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9726184  0.9726184], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.10967814177274704, Step: 28, Episode: 18\n",
      "====================================\n",
      "Step: 29, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8866484  1.         1.       ], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.16898313164710999, Step: 29, Episode: 18\n",
      "====================================\n",
      "Step: 30, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8917764  1.         1.       ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.11906599253416061, Step: 30, Episode: 18\n",
      "====================================\n",
      "Step: 31, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97348756  1.          1.        ], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.03132440894842148, Step: 31, Episode: 18\n",
      "====================================\n",
      "Step: 32, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.825537  1.        1.      ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.033671069890260696, Step: 32, Episode: 18\n",
      "====================================\n",
      "Step: 33, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8768119  0.8768119], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.07813308387994766, Step: 33, Episode: 18\n",
      "====================================\n",
      "Step: 34, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.86736745  1.          1.        ], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.0865388959646225, Step: 34, Episode: 18\n",
      "====================================\n",
      "Step: 35, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98156464  0.98156464], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.062258899211883545, Step: 35, Episode: 18\n",
      "====================================\n",
      "Step: 36, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9660058  0.9660058], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.1566614955663681, Step: 36, Episode: 18\n",
      "====================================\n",
      "Step: 37, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9349668  0.9349668], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.029739534482359886, Step: 37, Episode: 18\n",
      "====================================\n",
      "Step: 38, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.91985196  1.          1.        ], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.23139548301696777, Step: 38, Episode: 18\n",
      "====================================\n",
      "Step: 39, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9249829  1.         1.       ], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.07724080234766006, Step: 39, Episode: 18\n",
      "====================================\n",
      "Step: 40, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9438352  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.11588647216558456, Step: 40, Episode: 18\n",
      "====================================\n",
      "Step: 41, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.88485783  0.88485783], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.08275554329156876, Step: 41, Episode: 18\n",
      "====================================\n",
      "Step: 42, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9601834  1.         1.       ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.2696191072463989, Step: 42, Episode: 18\n",
      "====================================\n",
      "Step: 43, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88940465  1.          1.        ], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.036639075726270676, Step: 43, Episode: 18\n",
      "====================================\n",
      "Step: 44, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87433237  1.          1.        ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.21879811584949493, Step: 44, Episode: 18\n",
      "====================================\n",
      "Step: 45, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9700412  1.         1.       ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.02574603073298931, Step: 45, Episode: 18\n",
      "====================================\n",
      "Step: 46, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98130786  1.          1.        ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.47223779559135437, Step: 46, Episode: 18\n",
      "====================================\n",
      "Step: 47, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8618762  0.8618762], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.11566641181707382, Step: 47, Episode: 18\n",
      "====================================\n",
      "Step: 48, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91805476  0.91805476], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.2814861834049225, Step: 48, Episode: 18\n",
      "====================================\n",
      "Step: 49, Episode: 18\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.81607246  1.          1.        ], Reward: -4.9, Done: False\n",
      "Critic loss: 0.19526362419128418, Step: 49, Episode: 18\n",
      "====================================\n",
      "Step: 0, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9393346  0.9393346], Reward: 0, Done: False\n",
      "Critic loss: 0.07680432498455048, Step: 0, Episode: 19\n",
      "====================================\n",
      "Step: 1, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8972632  1.         1.       ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.08766015619039536, Step: 1, Episode: 19\n",
      "====================================\n",
      "Step: 2, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8367451  0.8367451], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.5328729748725891, Step: 2, Episode: 19\n",
      "====================================\n",
      "Step: 3, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8125965  0.8125965], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.062475115060806274, Step: 3, Episode: 19\n",
      "====================================\n",
      "Step: 4, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.       0.99943  0.99943], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.03283799812197685, Step: 4, Episode: 19\n",
      "====================================\n",
      "Step: 5, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9039138  0.9039138], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.10110350698232651, Step: 5, Episode: 19\n",
      "====================================\n",
      "Step: 6, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90833664  0.90833664], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.47374024987220764, Step: 6, Episode: 19\n",
      "====================================\n",
      "Step: 7, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9629156  0.9629156], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.056950028985738754, Step: 7, Episode: 19\n",
      "====================================\n",
      "Step: 8, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9521097  0.9521097], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.4350837767124176, Step: 8, Episode: 19\n",
      "====================================\n",
      "Step: 9, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9739089  0.9739089], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.29438892006874084, Step: 9, Episode: 19\n",
      "====================================\n",
      "Step: 10, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9097023  1.         1.       ], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.3230746388435364, Step: 10, Episode: 19\n",
      "====================================\n",
      "Step: 11, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9395061  1.         1.       ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.321776807308197, Step: 11, Episode: 19\n",
      "====================================\n",
      "Step: 12, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.89398086  1.          1.        ], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.10465896129608154, Step: 12, Episode: 19\n",
      "====================================\n",
      "Step: 13, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8494369  1.         1.       ], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.17130914330482483, Step: 13, Episode: 19\n",
      "====================================\n",
      "Step: 14, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92389554  0.92389554], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.2505664527416229, Step: 14, Episode: 19\n",
      "====================================\n",
      "Step: 15, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8931714  0.8931714], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 0.5238751769065857, Step: 15, Episode: 19\n",
      "====================================\n",
      "Step: 16, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9725308  1.         1.       ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.059031110256910324, Step: 16, Episode: 19\n",
      "====================================\n",
      "Step: 17, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90868115  0.90868115], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.6840837597846985, Step: 17, Episode: 19\n",
      "====================================\n",
      "Step: 18, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9651652  1.         1.       ], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.24986949563026428, Step: 18, Episode: 19\n",
      "====================================\n",
      "Step: 19, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9162395  1.         1.       ], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.220628023147583, Step: 19, Episode: 19\n",
      "====================================\n",
      "Step: 20, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9143904  0.9143904], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.1189165711402893, Step: 20, Episode: 19\n",
      "====================================\n",
      "Step: 21, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.982599  0.982599], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.12304580211639404, Step: 21, Episode: 19\n",
      "====================================\n",
      "Step: 22, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.84793735  1.          1.        ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.2812905013561249, Step: 22, Episode: 19\n",
      "====================================\n",
      "Step: 23, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8262737  1.         1.       ], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.01718137040734291, Step: 23, Episode: 19\n",
      "====================================\n",
      "Step: 24, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93761146  0.93761146], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.3080756366252899, Step: 24, Episode: 19\n",
      "====================================\n",
      "Step: 25, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.84759325  1.          1.        ], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.23280607163906097, Step: 25, Episode: 19\n",
      "====================================\n",
      "Step: 26, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.991339  1.        1.      ], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.015766046941280365, Step: 26, Episode: 19\n",
      "====================================\n",
      "Step: 27, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.978569  1.        1.      ], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.17370355129241943, Step: 27, Episode: 19\n",
      "====================================\n",
      "Step: 28, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.89090645  0.89090645], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.17783719301223755, Step: 28, Episode: 19\n",
      "====================================\n",
      "Step: 29, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87533736  0.87533736], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.026395311579108238, Step: 29, Episode: 19\n",
      "====================================\n",
      "Step: 30, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9129769  1.         1.       ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.027040764689445496, Step: 30, Episode: 19\n",
      "====================================\n",
      "Step: 31, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87147593  0.87147593], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.03657571226358414, Step: 31, Episode: 19\n",
      "====================================\n",
      "Step: 32, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.87864345  1.          1.        ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.05269814655184746, Step: 32, Episode: 19\n",
      "====================================\n",
      "Step: 33, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9987862  1.         1.       ], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.0594966821372509, Step: 33, Episode: 19\n",
      "====================================\n",
      "Step: 34, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9136358  1.         1.       ], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.047799330204725266, Step: 34, Episode: 19\n",
      "====================================\n",
      "Step: 35, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.84515005  1.          1.        ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.08945947140455246, Step: 35, Episode: 19\n",
      "====================================\n",
      "Step: 36, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.879153  1.        1.      ], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.019645757973194122, Step: 36, Episode: 19\n",
      "====================================\n",
      "Step: 37, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97623736  0.97623736], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.18895721435546875, Step: 37, Episode: 19\n",
      "====================================\n",
      "Step: 38, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9384016  0.9384016], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.010268134996294975, Step: 38, Episode: 19\n",
      "====================================\n",
      "Step: 39, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9512962  1.         1.       ], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.1811494678258896, Step: 39, Episode: 19\n",
      "====================================\n",
      "Step: 40, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9500226  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.04459737241268158, Step: 40, Episode: 19\n",
      "====================================\n",
      "Step: 41, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.941887  1.        1.      ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.16351357102394104, Step: 41, Episode: 19\n",
      "====================================\n",
      "Step: 42, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9882126  1.         1.       ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.2230214625597, Step: 42, Episode: 19\n",
      "====================================\n",
      "Step: 43, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9457589  0.9457589], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.04430767521262169, Step: 43, Episode: 19\n",
      "====================================\n",
      "Step: 44, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86812913  0.86812913], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.24719439446926117, Step: 44, Episode: 19\n",
      "====================================\n",
      "Step: 45, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8966244  1.         1.       ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.0710369274020195, Step: 45, Episode: 19\n",
      "====================================\n",
      "Step: 46, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96566397  0.96566397], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.05284910276532173, Step: 46, Episode: 19\n",
      "====================================\n",
      "Step: 47, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9665211  1.         1.       ], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.02465044893324375, Step: 47, Episode: 19\n",
      "====================================\n",
      "Step: 48, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.82643765  0.82643765], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.08825208246707916, Step: 48, Episode: 19\n",
      "====================================\n",
      "Step: 49, Episode: 19\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.740759  1.        1.      ], Reward: -4.9, Done: False\n",
      "Critic loss: 0.053942691534757614, Step: 49, Episode: 19\n",
      "====================================\n",
      "Step: 0, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.872317  0.872317], Reward: 0, Done: False\n",
      "Critic loss: 0.36696502566337585, Step: 0, Episode: 20\n",
      "====================================\n",
      "Step: 1, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8926036  0.8926036], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.35599222779273987, Step: 1, Episode: 20\n",
      "====================================\n",
      "Step: 2, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.92749566  1.          1.        ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.10530729591846466, Step: 2, Episode: 20\n",
      "====================================\n",
      "Step: 3, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9383478  0.9383478], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.2647678554058075, Step: 3, Episode: 20\n",
      "====================================\n",
      "Step: 4, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9073825  1.         1.       ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.016788512468338013, Step: 4, Episode: 20\n",
      "====================================\n",
      "Step: 5, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9667627  0.9667627], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.23762761056423187, Step: 5, Episode: 20\n",
      "====================================\n",
      "Step: 6, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9331382  1.         1.       ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.01994490996003151, Step: 6, Episode: 20\n",
      "====================================\n",
      "Step: 7, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9183845  1.         1.       ], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.31489822268486023, Step: 7, Episode: 20\n",
      "====================================\n",
      "Step: 8, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96292007  0.96292007], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.21889129281044006, Step: 8, Episode: 20\n",
      "====================================\n",
      "Step: 9, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9796432  0.9796432], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.10260453075170517, Step: 9, Episode: 20\n",
      "====================================\n",
      "Step: 10, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94656575  1.          1.        ], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.01670505478978157, Step: 10, Episode: 20\n",
      "====================================\n",
      "Step: 11, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8737608  1.         1.       ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.0687926709651947, Step: 11, Episode: 20\n",
      "====================================\n",
      "Step: 12, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.77432865  1.          1.        ], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.035493671894073486, Step: 12, Episode: 20\n",
      "====================================\n",
      "Step: 13, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.89955544  0.89955544], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.18506531417369843, Step: 13, Episode: 20\n",
      "====================================\n",
      "Step: 14, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8703202  0.8703202], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.18313239514827728, Step: 14, Episode: 20\n",
      "====================================\n",
      "Step: 15, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9905307  0.9905307], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 0.046694908291101456, Step: 15, Episode: 20\n",
      "====================================\n",
      "Step: 16, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9936615  0.9936615], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.09355594962835312, Step: 16, Episode: 20\n",
      "====================================\n",
      "Step: 17, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9509766  1.         1.       ], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.17511771619319916, Step: 17, Episode: 20\n",
      "====================================\n",
      "Step: 18, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8822716  1.         1.       ], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.42083740234375, Step: 18, Episode: 20\n",
      "====================================\n",
      "Step: 19, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.72989446  0.72989446], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.07408280670642853, Step: 19, Episode: 20\n",
      "====================================\n",
      "Step: 20, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9996991  1.         1.       ], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.6658337116241455, Step: 20, Episode: 20\n",
      "====================================\n",
      "Step: 21, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9050986  1.         1.       ], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.028031066060066223, Step: 21, Episode: 20\n",
      "====================================\n",
      "Step: 22, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88194823  1.          1.        ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.5672616958618164, Step: 22, Episode: 20\n",
      "====================================\n",
      "Step: 23, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9780614  1.         1.       ], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.11991387605667114, Step: 23, Episode: 20\n",
      "====================================\n",
      "Step: 24, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90941447  1.          1.        ], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.13927900791168213, Step: 24, Episode: 20\n",
      "====================================\n",
      "Step: 25, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93108153  0.93108153], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.08822836726903915, Step: 25, Episode: 20\n",
      "====================================\n",
      "Step: 26, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9122565  1.         1.       ], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.4817270338535309, Step: 26, Episode: 20\n",
      "====================================\n",
      "Step: 27, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9200516  1.         1.       ], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.032782815396785736, Step: 27, Episode: 20\n",
      "====================================\n",
      "Step: 28, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.88271624  0.88271624], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.4246579110622406, Step: 28, Episode: 20\n",
      "====================================\n",
      "Step: 29, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8850508  1.         1.       ], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.07441600412130356, Step: 29, Episode: 20\n",
      "====================================\n",
      "Step: 30, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93947226  1.          1.        ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.27174630761146545, Step: 30, Episode: 20\n",
      "====================================\n",
      "Step: 31, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96488994  0.96488994], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.1315850466489792, Step: 31, Episode: 20\n",
      "====================================\n",
      "Step: 32, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9602243  1.         1.       ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.4775906503200531, Step: 32, Episode: 20\n",
      "====================================\n",
      "Step: 33, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9738615  0.9738615], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.04459547996520996, Step: 33, Episode: 20\n",
      "====================================\n",
      "Step: 34, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84099245  0.84099245], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.6710540056228638, Step: 34, Episode: 20\n",
      "====================================\n",
      "Step: 35, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95474297  0.95474297], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.20123620331287384, Step: 35, Episode: 20\n",
      "====================================\n",
      "Step: 36, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90897036  0.90897036], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.18621592223644257, Step: 36, Episode: 20\n",
      "====================================\n",
      "Step: 37, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9199982  1.         1.       ], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.34795865416526794, Step: 37, Episode: 20\n",
      "====================================\n",
      "Step: 38, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8282796  0.8282796], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.08146544545888901, Step: 38, Episode: 20\n",
      "====================================\n",
      "Step: 39, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.764614  1.        1.      ], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.33328816294670105, Step: 39, Episode: 20\n",
      "====================================\n",
      "Step: 40, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9812993  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.1414097100496292, Step: 40, Episode: 20\n",
      "====================================\n",
      "Step: 41, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99932516  0.99932516], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.41518887877464294, Step: 41, Episode: 20\n",
      "====================================\n",
      "Step: 42, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.89860994  1.          1.        ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 0.011344918981194496, Step: 42, Episode: 20\n",
      "====================================\n",
      "Step: 43, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9811242  1.         1.       ], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.31412065029144287, Step: 43, Episode: 20\n",
      "====================================\n",
      "Step: 44, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98220146  0.98220146], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.22376571595668793, Step: 44, Episode: 20\n",
      "====================================\n",
      "Step: 45, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87721634  0.87721634], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.4420716464519501, Step: 45, Episode: 20\n",
      "====================================\n",
      "Step: 46, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94094706  0.94094706], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.2630416452884674, Step: 46, Episode: 20\n",
      "====================================\n",
      "Step: 47, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9452851  0.9452851], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.12694361805915833, Step: 47, Episode: 20\n",
      "====================================\n",
      "Step: 48, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8965734  1.         1.       ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.6006414294242859, Step: 48, Episode: 20\n",
      "====================================\n",
      "Step: 49, Episode: 20\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.90382093  0.90382093], Reward: -4.9, Done: False\n",
      "Critic loss: 0.11211172491312027, Step: 49, Episode: 20\n",
      "====================================\n",
      "Step: 0, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97632676  1.          1.        ], Reward: 0, Done: False\n",
      "Critic loss: 0.362445205450058, Step: 0, Episode: 21\n",
      "====================================\n",
      "Step: 1, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93128765  0.93128765], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.38397765159606934, Step: 1, Episode: 21\n",
      "====================================\n",
      "Step: 2, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9196374  0.9196374], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.08973456174135208, Step: 2, Episode: 21\n",
      "====================================\n",
      "Step: 3, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9553386  0.9553386], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.04773859307169914, Step: 3, Episode: 21\n",
      "====================================\n",
      "Step: 4, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9111038  0.9111038], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.08571641892194748, Step: 4, Episode: 21\n",
      "====================================\n",
      "Step: 5, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9240627  0.9240627], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.03623661398887634, Step: 5, Episode: 21\n",
      "====================================\n",
      "Step: 6, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9423602  1.         1.       ], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.09506884217262268, Step: 6, Episode: 21\n",
      "====================================\n",
      "Step: 7, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9642389  0.9642389], Reward: -0.7000000000000005, Done: False\n",
      "Critic loss: 0.036757808178663254, Step: 7, Episode: 21\n",
      "====================================\n",
      "Step: 8, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9768762  0.9768762], Reward: -0.8000000000000005, Done: False\n",
      "Critic loss: 0.16646504402160645, Step: 8, Episode: 21\n",
      "====================================\n",
      "Step: 9, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9268771  0.9268771], Reward: -0.9000000000000005, Done: False\n",
      "Critic loss: 0.39120858907699585, Step: 9, Episode: 21\n",
      "====================================\n",
      "Step: 10, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93028325  0.93028325], Reward: -1.0000000000000004, Done: False\n",
      "Critic loss: 0.037072163075208664, Step: 10, Episode: 21\n",
      "====================================\n",
      "Step: 11, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9099614  1.         1.       ], Reward: -1.1000000000000005, Done: False\n",
      "Critic loss: 0.3381226062774658, Step: 11, Episode: 21\n",
      "====================================\n",
      "Step: 12, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9527664  0.9527664], Reward: -1.2000000000000006, Done: False\n",
      "Critic loss: 0.32485446333885193, Step: 12, Episode: 21\n",
      "====================================\n",
      "Step: 13, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8904546  1.         1.       ], Reward: -1.3000000000000007, Done: False\n",
      "Critic loss: 0.11428075283765793, Step: 13, Episode: 21\n",
      "====================================\n",
      "Step: 14, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.99032074  1.          1.        ], Reward: -1.4000000000000008, Done: False\n",
      "Critic loss: 0.05696344003081322, Step: 14, Episode: 21\n",
      "====================================\n",
      "Step: 15, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9139793  0.9139793], Reward: -1.5000000000000009, Done: False\n",
      "Critic loss: 0.07068214565515518, Step: 15, Episode: 21\n",
      "====================================\n",
      "Step: 16, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9976931  1.         1.       ], Reward: -1.600000000000001, Done: False\n",
      "Critic loss: 0.08283510059118271, Step: 16, Episode: 21\n",
      "====================================\n",
      "Step: 17, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9587059  1.         1.       ], Reward: -1.700000000000001, Done: False\n",
      "Critic loss: 0.14507585763931274, Step: 17, Episode: 21\n",
      "====================================\n",
      "Step: 18, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88692915  1.          1.        ], Reward: -1.8000000000000012, Done: False\n",
      "Critic loss: 0.06066018342971802, Step: 18, Episode: 21\n",
      "====================================\n",
      "Step: 19, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.83038914  0.83038914], Reward: -1.9000000000000012, Done: False\n",
      "Critic loss: 0.07968037575483322, Step: 19, Episode: 21\n",
      "====================================\n",
      "Step: 20, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92535836  0.92535836], Reward: -2.0000000000000013, Done: False\n",
      "Critic loss: 0.05828399583697319, Step: 20, Episode: 21\n",
      "====================================\n",
      "Step: 21, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9529486  1.         1.       ], Reward: -2.1000000000000014, Done: False\n",
      "Critic loss: 0.10563621670007706, Step: 21, Episode: 21\n",
      "====================================\n",
      "Step: 22, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.961309  1.        1.      ], Reward: -2.2000000000000015, Done: False\n",
      "Critic loss: 0.1376197338104248, Step: 22, Episode: 21\n",
      "====================================\n",
      "Step: 23, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.879315  1.        1.      ], Reward: -2.3000000000000016, Done: False\n",
      "Critic loss: 0.08437683433294296, Step: 23, Episode: 21\n",
      "====================================\n",
      "Step: 24, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98925364  0.98925364], Reward: -2.4000000000000017, Done: False\n",
      "Critic loss: 0.05420171841979027, Step: 24, Episode: 21\n",
      "====================================\n",
      "Step: 25, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9926386  0.9926386], Reward: -2.5000000000000018, Done: False\n",
      "Critic loss: 0.28029677271842957, Step: 25, Episode: 21\n",
      "====================================\n",
      "Step: 26, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9269976  0.9269976], Reward: -2.600000000000002, Done: False\n",
      "Critic loss: 0.12275628000497818, Step: 26, Episode: 21\n",
      "====================================\n",
      "Step: 27, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94489735  1.          1.        ], Reward: -2.700000000000002, Done: False\n",
      "Critic loss: 0.6806638836860657, Step: 27, Episode: 21\n",
      "====================================\n",
      "Step: 28, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94749314  1.          1.        ], Reward: -2.800000000000002, Done: False\n",
      "Critic loss: 0.05424937233328819, Step: 28, Episode: 21\n",
      "====================================\n",
      "Step: 29, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98116094  1.          1.        ], Reward: -2.900000000000002, Done: False\n",
      "Critic loss: 0.6138339042663574, Step: 29, Episode: 21\n",
      "====================================\n",
      "Step: 30, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94900393  0.94900393], Reward: -3.000000000000002, Done: False\n",
      "Critic loss: 0.1627906709909439, Step: 30, Episode: 21\n",
      "====================================\n",
      "Step: 31, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94017667  1.          1.        ], Reward: -3.1000000000000023, Done: False\n",
      "Critic loss: 1.3158282041549683, Step: 31, Episode: 21\n",
      "====================================\n",
      "Step: 32, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9154056  1.         1.       ], Reward: -3.2000000000000024, Done: False\n",
      "Critic loss: 0.06382381170988083, Step: 32, Episode: 21\n",
      "====================================\n",
      "Step: 33, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9378606  0.9378606], Reward: -3.3000000000000025, Done: False\n",
      "Critic loss: 1.4671860933303833, Step: 33, Episode: 21\n",
      "====================================\n",
      "Step: 34, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9332066  1.         1.       ], Reward: -3.4000000000000026, Done: False\n",
      "Critic loss: 0.41485506296157837, Step: 34, Episode: 21\n",
      "====================================\n",
      "Step: 35, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.906047  1.        1.      ], Reward: -3.5000000000000027, Done: False\n",
      "Critic loss: 0.3335338532924652, Step: 35, Episode: 21\n",
      "====================================\n",
      "Step: 36, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99025315  0.99025315], Reward: -3.6000000000000028, Done: False\n",
      "Critic loss: 0.22785130143165588, Step: 36, Episode: 21\n",
      "====================================\n",
      "Step: 37, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9917205  1.         1.       ], Reward: -3.700000000000003, Done: False\n",
      "Critic loss: 0.5105922818183899, Step: 37, Episode: 21\n",
      "====================================\n",
      "Step: 38, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9059739  0.9059739], Reward: -3.800000000000003, Done: False\n",
      "Critic loss: 0.7556783556938171, Step: 38, Episode: 21\n",
      "====================================\n",
      "Step: 39, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.96427006  0.96427006], Reward: -3.900000000000003, Done: False\n",
      "Critic loss: 0.28044649958610535, Step: 39, Episode: 21\n",
      "====================================\n",
      "Step: 40, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.80882674  1.          1.        ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 1.2776774168014526, Step: 40, Episode: 21\n",
      "====================================\n",
      "Step: 41, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8673442  1.         1.       ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.07646934688091278, Step: 41, Episode: 21\n",
      "====================================\n",
      "Step: 42, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.789997  1.        1.      ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 1.0730007886886597, Step: 42, Episode: 21\n",
      "====================================\n",
      "Step: 43, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97037274  0.97037274], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.6056289076805115, Step: 43, Episode: 21\n",
      "====================================\n",
      "Step: 44, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9711398  0.9711398], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.15153048932552338, Step: 44, Episode: 21\n",
      "====================================\n",
      "Step: 45, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9550984  0.9550984], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.2530629336833954, Step: 45, Episode: 21\n",
      "====================================\n",
      "Step: 46, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9290989  0.9290989], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.08931588381528854, Step: 46, Episode: 21\n",
      "====================================\n",
      "Step: 47, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9005164  1.         1.       ], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.42398887872695923, Step: 47, Episode: 21\n",
      "====================================\n",
      "Step: 48, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9978174  0.9978174], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.07360954582691193, Step: 48, Episode: 21\n",
      "====================================\n",
      "Step: 49, Episode: 21\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97272086  0.97272086], Reward: -4.9, Done: False\n",
      "Critic loss: 0.1669190227985382, Step: 49, Episode: 21\n",
      "====================================\n",
      "Step: 0, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9765097  0.9765097], Reward: 0, Done: False\n",
      "Critic loss: 0.23755858838558197, Step: 0, Episode: 22\n",
      "====================================\n",
      "Step: 1, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97854424  1.          1.        ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.04529104381799698, Step: 1, Episode: 22\n",
      "====================================\n",
      "Step: 2, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9748519  1.         1.       ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.05899995565414429, Step: 2, Episode: 22\n",
      "====================================\n",
      "Step: 3, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9257134  1.         1.       ], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.1540103405714035, Step: 3, Episode: 22\n",
      "====================================\n",
      "Step: 4, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97769815  0.97769815], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.08039277791976929, Step: 4, Episode: 22\n",
      "====================================\n",
      "Step: 5, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9974182  0.9974182], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.206379696726799, Step: 5, Episode: 22\n",
      "====================================\n",
      "Step: 6, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8409648  0.8409648], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 0.27601876854896545, Step: 6, Episode: 22\n",
      "====================================\n",
      "Step: 7, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8693708  1.         1.       ], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 0.031486041843891144, Step: 7, Episode: 22\n",
      "====================================\n",
      "Step: 8, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93827134  0.93827134], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.25236836075782776, Step: 8, Episode: 22\n",
      "====================================\n",
      "Step: 9, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8597971  0.8597971], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.1849050372838974, Step: 9, Episode: 22\n",
      "====================================\n",
      "Step: 10, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98184127  1.          1.        ], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.038089003413915634, Step: 10, Episode: 22\n",
      "====================================\n",
      "Step: 11, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8496262  1.         1.       ], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.018230026587843895, Step: 11, Episode: 22\n",
      "====================================\n",
      "Step: 12, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87548685  0.87548685], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.10296356678009033, Step: 12, Episode: 22\n",
      "====================================\n",
      "Step: 13, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7844947  1.         1.       ], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.022820647805929184, Step: 13, Episode: 22\n",
      "====================================\n",
      "Step: 14, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98617625  0.98617625], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.12444295734167099, Step: 14, Episode: 22\n",
      "====================================\n",
      "Step: 15, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93093836  0.93093836], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 0.19680118560791016, Step: 15, Episode: 22\n",
      "====================================\n",
      "Step: 16, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9192056  1.         1.       ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.017790159210562706, Step: 16, Episode: 22\n",
      "====================================\n",
      "Step: 17, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9907259  1.         1.       ], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.09692593663930893, Step: 17, Episode: 22\n",
      "====================================\n",
      "Step: 18, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9973334  0.9973334], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.061911046504974365, Step: 18, Episode: 22\n",
      "====================================\n",
      "Step: 19, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95807266  1.          1.        ], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.04876643419265747, Step: 19, Episode: 22\n",
      "====================================\n",
      "Step: 20, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94863176  0.94863176], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.06784684211015701, Step: 20, Episode: 22\n",
      "====================================\n",
      "Step: 21, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8256184  0.8256184], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.03936171159148216, Step: 21, Episode: 22\n",
      "====================================\n",
      "Step: 22, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9688928  0.9688928], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.06235074996948242, Step: 22, Episode: 22\n",
      "====================================\n",
      "Step: 23, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.        0.947461  0.947461], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 0.10532965511083603, Step: 23, Episode: 22\n",
      "====================================\n",
      "Step: 24, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9839294  1.         1.       ], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.18087135255336761, Step: 24, Episode: 22\n",
      "====================================\n",
      "Step: 25, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.97886705  1.          1.        ], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.02014116384088993, Step: 25, Episode: 22\n",
      "====================================\n",
      "Step: 26, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.89335513  1.          1.        ], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.2643560469150543, Step: 26, Episode: 22\n",
      "====================================\n",
      "Step: 27, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87274617  0.87274617], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.3682810962200165, Step: 27, Episode: 22\n",
      "====================================\n",
      "Step: 28, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92054677  0.92054677], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.019740035757422447, Step: 28, Episode: 22\n",
      "====================================\n",
      "Step: 29, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9320037  1.         1.       ], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.41854557394981384, Step: 29, Episode: 22\n",
      "====================================\n",
      "Step: 30, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9976349  0.9976349], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.6799177527427673, Step: 30, Episode: 22\n",
      "====================================\n",
      "Step: 31, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8895875  0.8895875], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.06307055801153183, Step: 31, Episode: 22\n",
      "====================================\n",
      "Step: 32, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8653984  1.         1.       ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.5315995812416077, Step: 32, Episode: 22\n",
      "====================================\n",
      "Step: 33, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9869855  0.9869855], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.5228735208511353, Step: 33, Episode: 22\n",
      "====================================\n",
      "Step: 34, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9885457  1.         1.       ], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.08227945864200592, Step: 34, Episode: 22\n",
      "====================================\n",
      "Step: 35, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.999435  1.        1.      ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.625198245048523, Step: 35, Episode: 22\n",
      "====================================\n",
      "Step: 36, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9167973  0.9167973], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.040268559008836746, Step: 36, Episode: 22\n",
      "====================================\n",
      "Step: 37, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8825619  0.8825619], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.4914854168891907, Step: 37, Episode: 22\n",
      "====================================\n",
      "Step: 38, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8257139  0.8257139], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.32769685983657837, Step: 38, Episode: 22\n",
      "====================================\n",
      "Step: 39, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8743838  0.8743838], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.2694903314113617, Step: 39, Episode: 22\n",
      "====================================\n",
      "Step: 40, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9792405  1.         1.       ], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 1.5115050077438354, Step: 40, Episode: 22\n",
      "====================================\n",
      "Step: 41, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9383364  0.9383364], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.047346752136945724, Step: 41, Episode: 22\n",
      "====================================\n",
      "Step: 42, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8936641  0.8936641], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 2.310852527618408, Step: 42, Episode: 22\n",
      "====================================\n",
      "Step: 43, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9253699  0.9253699], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.8533644080162048, Step: 43, Episode: 22\n",
      "====================================\n",
      "Step: 44, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99277526  0.99277526], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 2.117868423461914, Step: 44, Episode: 22\n",
      "====================================\n",
      "Step: 45, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85381407  0.85381407], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 2.330487012863159, Step: 45, Episode: 22\n",
      "====================================\n",
      "Step: 46, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.93298787  1.          1.        ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.6615738272666931, Step: 46, Episode: 22\n",
      "====================================\n",
      "Step: 47, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8226321  0.8226321], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 2.8162992000579834, Step: 47, Episode: 22\n",
      "====================================\n",
      "Step: 48, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9696004  1.         1.       ], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.12289581447839737, Step: 48, Episode: 22\n",
      "====================================\n",
      "Step: 49, Episode: 22\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9907837  0.9907837], Reward: -4.9, Done: False\n",
      "Critic loss: 4.469966888427734, Step: 49, Episode: 22\n",
      "====================================\n",
      "Step: 0, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.98100877  0.98100877], Reward: 0, Done: False\n",
      "Critic loss: 2.351815938949585, Step: 0, Episode: 23\n",
      "====================================\n",
      "Step: 1, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98444784  1.          1.        ], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.2959079444408417, Step: 1, Episode: 23\n",
      "====================================\n",
      "Step: 2, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9986497  0.9986497], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 1.5034606456756592, Step: 2, Episode: 23\n",
      "====================================\n",
      "Step: 3, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.97376215  0.97376215], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.06856916099786758, Step: 3, Episode: 23\n",
      "====================================\n",
      "Step: 4, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9398693  1.         1.       ], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 1.784855842590332, Step: 4, Episode: 23\n",
      "====================================\n",
      "Step: 5, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9987849  0.9987849], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.2912604510784149, Step: 5, Episode: 23\n",
      "====================================\n",
      "Step: 6, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.99954337  0.99954337], Reward: -0.6000000000000005, Done: False\n",
      "Critic loss: 1.3026329278945923, Step: 6, Episode: 23\n",
      "====================================\n",
      "Step: 7, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9019838  1.         1.       ], Reward: -0.7000000000000006, Done: False\n",
      "Critic loss: 1.5244472026824951, Step: 7, Episode: 23\n",
      "====================================\n",
      "Step: 8, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9296129  0.9296129], Reward: -0.8000000000000007, Done: False\n",
      "Critic loss: 0.1124330535531044, Step: 8, Episode: 23\n",
      "====================================\n",
      "Step: 9, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8962927  1.         1.       ], Reward: -0.9000000000000008, Done: False\n",
      "Critic loss: 0.9021770358085632, Step: 9, Episode: 23\n",
      "====================================\n",
      "Step: 10, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8775145  0.8775145], Reward: -1.0000000000000009, Done: False\n",
      "Critic loss: 0.014061546884477139, Step: 10, Episode: 23\n",
      "====================================\n",
      "Step: 11, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.93095165  0.93095165], Reward: -1.100000000000001, Done: False\n",
      "Critic loss: 0.8442214131355286, Step: 11, Episode: 23\n",
      "====================================\n",
      "Step: 12, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9551952  0.9551952], Reward: -1.200000000000001, Done: False\n",
      "Critic loss: 0.2943994104862213, Step: 12, Episode: 23\n",
      "====================================\n",
      "Step: 13, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8108287  1.         1.       ], Reward: -1.3000000000000012, Done: False\n",
      "Critic loss: 0.33661022782325745, Step: 13, Episode: 23\n",
      "====================================\n",
      "Step: 14, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9133425  1.         1.       ], Reward: -1.4000000000000012, Done: False\n",
      "Critic loss: 0.4258720874786377, Step: 14, Episode: 23\n",
      "====================================\n",
      "Step: 15, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.92601585  0.92601585], Reward: -1.5000000000000013, Done: False\n",
      "Critic loss: 0.07740245014429092, Step: 15, Episode: 23\n",
      "====================================\n",
      "Step: 16, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.81433547  1.          1.        ], Reward: -1.6000000000000014, Done: False\n",
      "Critic loss: 0.4009224474430084, Step: 16, Episode: 23\n",
      "====================================\n",
      "Step: 17, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9416953  0.9416953], Reward: -1.7000000000000015, Done: False\n",
      "Critic loss: 0.06705104559659958, Step: 17, Episode: 23\n",
      "====================================\n",
      "Step: 18, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9514253  0.9514253], Reward: -1.8000000000000016, Done: False\n",
      "Critic loss: 0.45059043169021606, Step: 18, Episode: 23\n",
      "====================================\n",
      "Step: 19, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9155703  0.9155703], Reward: -1.9000000000000017, Done: False\n",
      "Critic loss: 0.3008562922477722, Step: 19, Episode: 23\n",
      "====================================\n",
      "Step: 20, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.98208314  1.          1.        ], Reward: -2.0000000000000018, Done: False\n",
      "Critic loss: 0.48363542556762695, Step: 20, Episode: 23\n",
      "====================================\n",
      "Step: 21, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9536811  0.9536811], Reward: -2.100000000000002, Done: False\n",
      "Critic loss: 0.9824663996696472, Step: 21, Episode: 23\n",
      "====================================\n",
      "Step: 22, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.88463426  1.          1.        ], Reward: -2.200000000000002, Done: False\n",
      "Critic loss: 0.06660684198141098, Step: 22, Episode: 23\n",
      "====================================\n",
      "Step: 23, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.75292474  0.75292474], Reward: -2.300000000000002, Done: False\n",
      "Critic loss: 1.282112717628479, Step: 23, Episode: 23\n",
      "====================================\n",
      "Step: 24, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9867318  0.9867318], Reward: -2.400000000000002, Done: False\n",
      "Critic loss: 0.18759113550186157, Step: 24, Episode: 23\n",
      "====================================\n",
      "Step: 25, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96534646  1.          1.        ], Reward: -2.500000000000002, Done: False\n",
      "Critic loss: 0.9959769248962402, Step: 25, Episode: 23\n",
      "====================================\n",
      "Step: 26, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8474512  0.8474512], Reward: -2.6000000000000023, Done: False\n",
      "Critic loss: 0.6430991291999817, Step: 26, Episode: 23\n",
      "====================================\n",
      "Step: 27, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.87288094  0.87288094], Reward: -2.7000000000000024, Done: False\n",
      "Critic loss: 0.2432040423154831, Step: 27, Episode: 23\n",
      "====================================\n",
      "Step: 28, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.91366684  0.91366684], Reward: -2.8000000000000025, Done: False\n",
      "Critic loss: 0.2385050356388092, Step: 28, Episode: 23\n",
      "====================================\n",
      "Step: 29, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9944597  0.9944597], Reward: -2.9000000000000026, Done: False\n",
      "Critic loss: 0.07615916430950165, Step: 29, Episode: 23\n",
      "====================================\n",
      "Step: 30, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.958993  1.        1.      ], Reward: -3.0000000000000027, Done: False\n",
      "Critic loss: 0.04198906943202019, Step: 30, Episode: 23\n",
      "====================================\n",
      "Step: 31, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.78368855  1.          1.        ], Reward: -3.1000000000000028, Done: False\n",
      "Critic loss: 0.17729763686656952, Step: 31, Episode: 23\n",
      "====================================\n",
      "Step: 32, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9938576  1.         1.       ], Reward: -3.200000000000003, Done: False\n",
      "Critic loss: 0.06742869317531586, Step: 32, Episode: 23\n",
      "====================================\n",
      "Step: 33, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.94289875  1.          1.        ], Reward: -3.300000000000003, Done: False\n",
      "Critic loss: 0.24727773666381836, Step: 33, Episode: 23\n",
      "====================================\n",
      "Step: 34, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.84948254  0.84948254], Reward: -3.400000000000003, Done: False\n",
      "Critic loss: 0.023106232285499573, Step: 34, Episode: 23\n",
      "====================================\n",
      "Step: 35, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.83191097  1.          1.        ], Reward: -3.500000000000003, Done: False\n",
      "Critic loss: 0.17813490331172943, Step: 35, Episode: 23\n",
      "====================================\n",
      "Step: 36, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9936685  1.         1.       ], Reward: -3.600000000000003, Done: False\n",
      "Critic loss: 0.06338474899530411, Step: 36, Episode: 23\n",
      "====================================\n",
      "Step: 37, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.995916  1.        1.      ], Reward: -3.7000000000000033, Done: False\n",
      "Critic loss: 0.11826028674840927, Step: 37, Episode: 23\n",
      "====================================\n",
      "Step: 38, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.82133406  0.82133406], Reward: -3.8000000000000034, Done: False\n",
      "Critic loss: 0.0953638106584549, Step: 38, Episode: 23\n",
      "====================================\n",
      "Step: 39, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9816942  1.         1.       ], Reward: -3.9000000000000035, Done: False\n",
      "Critic loss: 0.24451112747192383, Step: 39, Episode: 23\n",
      "====================================\n",
      "Step: 40, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9662698  0.9662698], Reward: -4.0000000000000036, Done: False\n",
      "Critic loss: 0.08866830170154572, Step: 40, Episode: 23\n",
      "====================================\n",
      "Step: 41, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.84365577  1.          1.        ], Reward: -4.100000000000003, Done: False\n",
      "Critic loss: 0.372839093208313, Step: 41, Episode: 23\n",
      "====================================\n",
      "Step: 42, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8538967  1.         1.       ], Reward: -4.200000000000003, Done: False\n",
      "Critic loss: 1.1254172325134277, Step: 42, Episode: 23\n",
      "====================================\n",
      "Step: 43, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9115143  0.9115143], Reward: -4.3000000000000025, Done: False\n",
      "Critic loss: 0.0857987031340599, Step: 43, Episode: 23\n",
      "====================================\n",
      "Step: 44, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.79725784  1.          1.        ], Reward: -4.400000000000002, Done: False\n",
      "Critic loss: 0.3544731140136719, Step: 44, Episode: 23\n",
      "====================================\n",
      "Step: 45, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.95716065  1.          1.        ], Reward: -4.500000000000002, Done: False\n",
      "Critic loss: 0.40586063265800476, Step: 45, Episode: 23\n",
      "====================================\n",
      "Step: 46, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9027082  1.         1.       ], Reward: -4.600000000000001, Done: False\n",
      "Critic loss: 0.03690959885716438, Step: 46, Episode: 23\n",
      "====================================\n",
      "Step: 47, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9760562  0.9760562], Reward: -4.700000000000001, Done: False\n",
      "Critic loss: 0.08523925393819809, Step: 47, Episode: 23\n",
      "====================================\n",
      "Step: 48, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.95748246  0.95748246], Reward: -4.800000000000001, Done: False\n",
      "Critic loss: 0.0840584859251976, Step: 48, Episode: 23\n",
      "====================================\n",
      "Step: 49, Episode: 23\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9317378  0.9317378], Reward: -4.9, Done: False\n",
      "Critic loss: 0.38667088747024536, Step: 49, Episode: 23\n",
      "====================================\n",
      "Step: 0, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9677138  1.         1.       ], Reward: 0, Done: False\n",
      "Critic loss: 0.6891505718231201, Step: 0, Episode: 24\n",
      "====================================\n",
      "Step: 1, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94581515  0.94581515], Reward: -0.10000000000000009, Done: False\n",
      "Critic loss: 0.06164753437042236, Step: 1, Episode: 24\n",
      "====================================\n",
      "Step: 2, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8741031  1.         1.       ], Reward: -0.20000000000000018, Done: False\n",
      "Critic loss: 0.3874715268611908, Step: 2, Episode: 24\n",
      "====================================\n",
      "Step: 3, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.86670923  0.86670923], Reward: -0.30000000000000027, Done: False\n",
      "Critic loss: 0.2681828439235687, Step: 3, Episode: 24\n",
      "====================================\n",
      "Step: 4, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.94820875  0.94820875], Reward: -0.40000000000000036, Done: False\n",
      "Critic loss: 0.5470326542854309, Step: 4, Episode: 24\n",
      "====================================\n",
      "Step: 5, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.9468812  0.9468812], Reward: -0.5000000000000004, Done: False\n",
      "Critic loss: 0.19427907466888428, Step: 5, Episode: 24\n",
      "====================================\n",
      "Step: 6, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8420657  0.8420657], Reward: -0.6000000000000004, Done: False\n",
      "Critic loss: 0.40324077010154724, Step: 6, Episode: 24\n",
      "====================================\n",
      "Step: 7, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8787016  0.8787016], Reward: -0.7000000000000004, Done: False\n",
      "Critic loss: 1.4150217771530151, Step: 7, Episode: 24\n",
      "====================================\n",
      "Step: 8, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.7972619  0.7972619], Reward: -0.8000000000000004, Done: False\n",
      "Critic loss: 0.22710251808166504, Step: 8, Episode: 24\n",
      "====================================\n",
      "Step: 9, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8901025  1.         1.       ], Reward: -0.9000000000000004, Done: False\n",
      "Critic loss: 0.5918957591056824, Step: 9, Episode: 24\n",
      "====================================\n",
      "Step: 10, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9801271  1.         1.       ], Reward: -1.0000000000000004, Done: False\n",
      "Critic loss: 0.11601916700601578, Step: 10, Episode: 24\n",
      "====================================\n",
      "Step: 11, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.          0.85780525  0.85780525], Reward: -1.1000000000000005, Done: False\n",
      "Critic loss: 1.1492035388946533, Step: 11, Episode: 24\n",
      "====================================\n",
      "Step: 12, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8909421  1.         1.       ], Reward: -1.2000000000000006, Done: False\n",
      "Critic loss: 0.09676596522331238, Step: 12, Episode: 24\n",
      "====================================\n",
      "Step: 13, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.90099615  1.          1.        ], Reward: -1.3000000000000007, Done: False\n",
      "Critic loss: 1.3582123517990112, Step: 13, Episode: 24\n",
      "====================================\n",
      "Step: 14, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9220923  1.         1.       ], Reward: -1.4000000000000008, Done: False\n",
      "Critic loss: 0.6334300637245178, Step: 14, Episode: 24\n",
      "====================================\n",
      "Step: 15, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.96047485  1.          1.        ], Reward: -1.5000000000000009, Done: False\n",
      "Critic loss: 0.648695170879364, Step: 15, Episode: 24\n",
      "====================================\n",
      "Step: 16, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.7901386  1.         1.       ], Reward: -1.600000000000001, Done: False\n",
      "Critic loss: 1.5124351978302002, Step: 16, Episode: 24\n",
      "====================================\n",
      "Step: 17, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9360038  1.         1.       ], Reward: -1.700000000000001, Done: False\n",
      "Critic loss: 0.3248915672302246, Step: 17, Episode: 24\n",
      "====================================\n",
      "Step: 18, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.9679322  1.         1.       ], Reward: -1.8000000000000012, Done: False\n",
      "Critic loss: 2.6652722358703613, Step: 18, Episode: 24\n",
      "====================================\n",
      "Step: 19, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.85373837  1.          1.        ], Reward: -1.9000000000000012, Done: False\n",
      "Critic loss: 0.5806862115859985, Step: 19, Episode: 24\n",
      "====================================\n",
      "Step: 20, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-1.         0.8830639  0.8830639], Reward: -2.0000000000000013, Done: False\n",
      "Critic loss: 0.7564289569854736, Step: 20, Episode: 24\n",
      "====================================\n",
      "Step: 21, Episode: 24\n",
      "Original action: tensor([-1.,  1.,  1.], device='cuda:0')\n",
      "Action: [-0.8563101  1.         1.       ], Reward: -2.1000000000000014, Done: False\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    episode_reward = 0\n",
    "\n",
    "    frames = [env.render()]\n",
    "    for step in range(init_step):\n",
    "        env.step([0.,0.,0.])\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        print(\"====================================\")\n",
    "        print(f\"Step: {step}, Episode: {episode}\")\n",
    "\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action = actor(state_tensor).squeeze(0)\n",
    "\n",
    "        print(\"Original action:\", action)\n",
    "        action = action.cpu().numpy()    \n",
    "        action = np.clip(action + np.random.normal(0, 0.1), -action_bound, action_bound)\n",
    "        \n",
    "\n",
    "        step_info = env.step(action)\n",
    "        next_state, reward, done = step_info[0], step_info[1], step_info[2]\n",
    "        frames.append(env.render())\n",
    "\n",
    "        print(f\"Action: {action}, Reward: {episode_reward}, Done: {done}\")\n",
    "\n",
    "        transition = (state, action, next_state, reward, done)\n",
    "        replay_buffer.push(transition)\n",
    "        episode_reward += reward\n",
    "\n",
    "        if len(replay_buffer.memory) > batch_size:\n",
    "            batch = replay_buffer.sample(batch_size)\n",
    "            batch = Transition(*zip(*batch))\n",
    "\n",
    "            state_batch = torch.tensor(batch.state, dtype=torch.float32)\n",
    "            action_batch = torch.tensor(batch.action, dtype=torch.float32)\n",
    "            next_state_batch = torch.tensor(batch.next_state, dtype=torch.float32)\n",
    "            reward_batch = torch.tensor(batch.reward, dtype=torch.float32).unsqueeze(1)\n",
    "            done_batch = torch.tensor(batch.done, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                target_action_next = target_actor(next_state_batch)\n",
    "                target_q_next = target_critic(next_state_batch, target_action_next)\n",
    "                target_q = reward_batch + gamma * (1.0 - done_batch) * target_q_next\n",
    "\n",
    "            critic_loss = F.mse_loss(critic(state_batch, action_batch), target_q)\n",
    "            print(f\"Critic loss: {critic_loss.item()}, Step: {step}, Episode: {episode}\")\n",
    "\n",
    "            critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            predicted_action = actor(state_batch)\n",
    "            actor_loss = -critic(state_batch, predicted_action).mean()\n",
    "\n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_optimizer.step()\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"Done\")\n",
    "            print(f\"Episode: {episode + 1}, Reward: {episode_reward}\")\n",
    "            break\n",
    "\n",
    "# Закрытие среды\n",
    "env.close()\n",
    "\n",
    "torch.save(actor.state_dict(), 'actor_model.pth')\n",
    "torch.save(critic.state_dict(), 'critic_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49mimshow(frames[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m frame \u001b[39min\u001b[39;00m frames:\n\u001b[1;32m      3\u001b[0m     img\u001b[39m.\u001b[39mset_data(frame)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/site-packages/matplotlib/pyplot.py:2903\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[1;32m   2898\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[1;32m   2899\u001b[0m         X, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, aspect\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, interpolation\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2900\u001b[0m         alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, origin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2901\u001b[0m         filternorm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterrad\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m, resample\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2902\u001b[0m         data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2903\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mimshow(\n\u001b[1;32m   2904\u001b[0m         X, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm, aspect\u001b[39m=\u001b[39;49maspect,\n\u001b[1;32m   2905\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation, alpha\u001b[39m=\u001b[39;49malpha, vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[1;32m   2906\u001b[0m         vmax\u001b[39m=\u001b[39;49mvmax, origin\u001b[39m=\u001b[39;49morigin, extent\u001b[39m=\u001b[39;49mextent,\n\u001b[1;32m   2907\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm, filterrad\u001b[39m=\u001b[39;49mfilterrad, resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m   2908\u001b[0m         url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[1;32m   2909\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2910\u001b[0m     sci(__ret)\n\u001b[1;32m   2911\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m/usr/lib64/python3.9/site-packages/matplotlib/__init__.py:1364\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1363\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1364\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1366\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1367\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1368\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/usr/lib64/python3.9/site-packages/matplotlib/axes/_axes.py:5609\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5604\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5605\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap, norm, interpolation, origin, extent,\n\u001b[1;32m   5606\u001b[0m                       filternorm\u001b[39m=\u001b[39mfilternorm, filterrad\u001b[39m=\u001b[39mfilterrad,\n\u001b[1;32m   5607\u001b[0m                       resample\u001b[39m=\u001b[39mresample, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5609\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5610\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5611\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5612\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/site-packages/matplotlib/image.py:700\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39msafe_masked_invalid(A, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    698\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39muint8 \u001b[39mand\u001b[39;00m\n\u001b[1;32m    699\u001b[0m         \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mcan_cast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, \u001b[39mfloat\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msame_kind\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m--> 700\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mImage data of dtype \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m cannot be converted to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m    703\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    704\u001b[0m     \u001b[39m# If just one dimension assume scalar and apply colormap\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imshow(frames[0])\n",
    "for frame in frames:\n",
    "    img.set_data(frame)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "imageio.mimsave('test.gif', frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
